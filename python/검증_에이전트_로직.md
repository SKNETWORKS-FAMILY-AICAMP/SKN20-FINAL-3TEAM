# 건축 법규 검증 에이전트 로직

## 📋 개요

건축 챗봇의 LLM 답변을 자동으로 검증하여 법규 정확성을 보장하는 4단계 파이프라인입니다.

## 🎯 목적

- LLM 답변이 실제 법령 DB와 일치하는지 검증
- 환각(Hallucination) 및 오류 탐지
- 부정확한 답변을 재생성하여 품질 향상

---

## 🏗️ 전체 아키텍처

```
사용자 질문
    ↓
챗봇 답변 생성 (chatbot_service_v2)
    ↓
[검증 파이프라인 시작]
    ├─ STEP 1: 정보 추출 (LLM)
    ├─ STEP 2: Hard Rule 검증 (DB)
    ├─ STEP 3: Semantic 검증 (LLM)
    └─ STEP 4: 최종 점수 산정
    ↓
검증 결과 판단
    ├─ PASS (70점 이상) → 답변 반환
    ├─ RETRY (50-69점) → 피드백으로 재생성
    └─ FAIL (50점 미만) → 피드백으로 재생성
    ↓
최대 3회 재시도
    ↓
최종 답변 반환
```

---

## 📦 주요 데이터 스키마

### ExtractedLawInfo (추출된 법규 정보)
```python
- region: 지역명 (예: 서울특별시 강남구)
- zone_district: 용도지역 (예: 제1종일반주거지역)
- building_coverage_ratio: 건폐율 (%)
- floor_area_ratio: 용적률 (%)
- height_limit: 높이 제한 (m)
- floor_limit: 층수 제한
- land_use_activity: 토지 이용 행위
- permission_category: 허가 구분 (허용/불허/조건부허용)
- cited_laws: 인용된 법률/조례명
- conditions: 조건 및 예외사항
```

### VerificationResult (검증 결과)
```python
- status: PASS / RETRY / FAIL
- score: 검증 점수 (0-100)
- issues: 발견된 문제점 리스트
- warnings: 경고사항 리스트
- details: 상세 검증 정보 (dict)
- recommendation: 개선 권장사항
```

---

## 🔄 4단계 검증 파이프라인

### STEP 1: 정보 추출 (Information Extraction)

**목적**: LLM 답변에서 구조화된 법규 정보 추출

**방법**:
- OpenAI GPT-4o-mini 사용
- JSON 포맷 강제 출력
- Pydantic 스키마로 검증

**프롬프트 예시**:
```
다음 건축 법규 답변에서 구조화된 정보를 추출하세요:
[답변]
...
JSON 형식으로 추출:
{
  "region": "서울특별시 종로구",
  "zone_district": "제1종일반주거지역",
  "building_coverage_ratio": 60,
  "floor_area_ratio": 150,
  ...
}
```

**폴백 (Fallback)**:
- LLM 추출 실패 시 정규식 기반 추출
- 건폐율: `건폐율[:\s]*(\d+(?:\.\d+)?)%`
- 용적률: `용적률[:\s]*(\d+(?:\.\d+)?)%`
- 높이: `높이[:\s]*(\d+(?:\.\d+)?)m`
- 층수: `(\d+)층\s*(?:이하|까지)`

**출력**: `ExtractedLawInfo` 객체

---

### STEP 2: Hard Rule 검증 (Deterministic Verification)

**목적**: DB의 법규 데이터와 답변 수치 비교 (명확한 오류 탐지)

**검증 항목**:

#### 2-1. 용도지역 일치성
```sql
SELECT * FROM law 
WHERE zone_district_name = '제1종일반주거지역'
```
- 답변의 용도지역이 DB와 일치하는지 확인
- 불일치 시 → ⚠️ 경고

#### 2-2. 허가 구분 검증
```python
if 답변 = "허용" and DB = "불허":
    이슈 추가: ❌ 허가 구분 오류
```
- 답변이 "허용"인데 DB에 "불허" 규정 존재 → 심각한 오류
- 조건부허용인데 조건 미명시 → ⚠️ 경고

#### 2-3. 건폐율/용적률 상한선 검증
```python
# DB의 condition_exception에서 상한선 파싱
if 답변_건폐율 > DB_건폐율_상한:
    이슈 추가: ❌ 건폐율 초과

if 답변_용적률 > DB_용적률_상한:
    이슈 추가: ❌ 용적률 초과
```

#### 2-4. 인용 법률 검증
```python
for cited_law in 답변.cited_laws:
    if cited_law not in DB_law_names:
        이슈 추가: ⚠️ 인용 법률 미확인
```

**출력**:
- `hard_rule_passed`: True/False
- `issues`: ["❌ 이슈1", "⚠️ 경고1"]
- `details`: DB 조회 결과 (최대 50건)

**점수**:
- 통과 → 100점
- 실패 → 30점

---

### STEP 3: Semantic 일관성 검증 (LLM Evaluation)

**목적**: 의미적 정확성 및 완전성 검증 (LLM 기반)

**검증 기준**:
1. **Hallucination 체크**: 답변이 DB 참조 데이터의 범위를 벗어나는가?
2. **Completeness 체크**: 질문에서 요청한 항목이 답변에 모두 포함되었는가?
3. **Misinterpretation 체크**: 법령의 의미를 왜곡하거나 잘못 해석했는가?
4. **조례 우선순위**: 건축법과 조례가 충돌하면 조례를 우선시했는가?
5. **조건 명시**: 조건부 허용인 경우 구체적인 조건을 명시했는가?

**프롬프트 구성**:
```
[사용자 질문]
서울 종로구 명륜3가에서 카페 운영 가능해?

[LLM 답변]
네, 카페 운영 가능합니다...

[DB 참조 데이터]
- 제1종일반주거지역, 휴게음식점: 허용 (건축법시행령 별표1)
- 제1종일반주거지역, 음식점: 조건부허용 (4층 이하)

↓ LLM 평가 →

JSON 출력:
{
  "hallucination_detected": false,
  "missing_items": [],
  "misinterpretation": false,
  "ordinance_priority": true,
  "condition_specified": true,
  "consistency_score": 90,
  "issues": [],
  "explanation": "답변은 DB 범위 내에서 정확..."
}
```

**출력**:
- `semantic_passed`: True/False
- `semantic_score`: 0-100
- `issues`: 의미적 문제점 목록

---

### STEP 4: 최종 점수 산정 및 상태 결정

**점수 계산**:
```python
최종 점수 = (Hard Rule 점수 × 0.6) + (Semantic 점수 × 0.4)

# 감점 요소
critical_issue_count = len([i for i in issues if '❌' in i])
최종 점수 -= critical_issue_count × 10
최종 점수 = max(0, min(100, 최종점수))  # 0-100 범위
```

**상태 결정 로직**:
```python
if 최종점수 >= 70 and critical_issue_count == 0:
    status = PASS  # 즉시 반환
    
elif 최종점수 >= 50:
    status = RETRY  # 재생성 필요
    recommendation = "답변을 재작성하세요. 주요 이슈: ..."
    
else:
    status = FAIL  # 전면 재작성
    recommendation = "답변이 법규와 심각하게 불일치..."
```

**검증 임계값**:
- `PASS_THRESHOLD = 70.0`
- `RETRY_THRESHOLD = 50.0`

---

## 🔁 재시도 메커니즘 (main.py)

### 재시도 워크플로우

```python
for attempt in range(1, 4):  # 최대 3회
    # 1. 답변 생성
    if attempt == 1:
        answer = chatbot.ask(question)
    else:
        # 검증 피드백을 질문에 추가
        feedback_question = f"""
        {질문}
        
        [이전 답변 검증 결과]
        - 상태: {status}
        - 점수: {score}/100
        - 문제점: {issues}
        - 권장사항: {recommendation}
        
        위 피드백을 반영하여 정확한 답변을 생성해주세요.
        """
        answer = chatbot.ask(feedback_question)
    
    # 2. 검증 실행
    result = validator.verify(answer, question, context)
    
    # 3. 결과 판단
    if result.status == PASS:
        return answer  # 성공! 즉시 반환
    
    elif attempt == 3:
        # 최대 재시도 도달
        return answer + "⚠️ 검증 안내..."
    
    else:
        continue  # 다시 시도
```

### 재시도 효과
- 1차 실패 → 피드백으로 개선 시도
- 2차 실패 → 다시 피드백으로 개선
- 3차 실패 → 경고 포함하여 반환

---

## 📊 검증 점수 예시

### 케이스 1: 완벽한 답변
```
Hard Rule: 100점 (DB와 완벽 일치)
Semantic: 95점 (완전성, 일관성 우수)

최종 점수 = (100 × 0.6) + (95 × 0.4) = 98점
상태: PASS ✅
```

### 케이스 2: 경미한 누락
```
Hard Rule: 100점 (DB 일치)
Semantic: 75점 (일부 조건 누락)

최종 점수 = (100 × 0.6) + (75 × 0.4) = 90점
상태: PASS ✅ (경고 1건)
```

### 케이스 3: 수치 오류
```
Hard Rule: 30점 (건폐율 초과, 이슈 1건)
Semantic: 80점 (의미는 정확)

최종 점수 = (30 × 0.6) + (80 × 0.4) - 10 = 40점
상태: FAIL ❌
```

### 케이스 4: 조건부 허용 미명시
```
Hard Rule: 100점
Semantic: 70점 (조건 명시 부족)

최종 점수 = (100 × 0.6) + (70 × 0.4) = 88점
상태: PASS ✅ (경고 1건)
```

---

## 🔧 주요 설정

### DB 연결 설정
```python
DB_CONFIG = {
    "host": "localhost",
    "database": "arae",
    "user": "postgres",
    "password": "1234",
    "port": 5432,
}
```

### OpenAI 설정
```python
# RAGConfig에서 자동 로드
config = RAGConfig()  # .env에서 OPENAI_API_KEY 읽기
model = "gpt-4o-mini"
temperature = 0.1
```

### 검증 파라미터
```python
PASS_THRESHOLD = 70.0   # 70점 이상 통과
RETRY_THRESHOLD = 50.0  # 50점 이상 재시도
MAX_ATTEMPTS = 3        # 최대 3회 시도
```

---

## 📈 성능 최적화

### 실행 시간 분석
```
1차 시도 (초기화 포함): ~15-20초
  - 챗봇 로딩: 10초
  - 답변 생성: 3-5초
  - 검증: 3-5초

2차 시도 (캐시 활용): ~10-15초
  - 답변 생성: 5초
  - 검증: 5초

평균 성공 케이스 (1차 PASS): ~15초
평균 재시도 케이스 (2-3차 PASS): ~30-45초
```

### 최적화 포인트
1. **Enum 비교 수정** → 불필요한 재시도 방지
2. **cited_laws None 처리** → Pydantic 검증 실패 방지
3. **DB 쿼리 LIMIT 50** → 과도한 데이터 조회 방지
4. **캐싱** → chatbot_service_v2의 RAG 캐시 활용

---

## 🚨 에러 처리

### 정보 추출 실패
```python
try:
    extracted_info = extract_info_from_answer(llm_answer)
except Exception as e:
    return VerificationResult(
        status=FAIL,
        score=0.0,
        issues=[f"❌ 정보 추출 실패: {e}"]
    )
```

### DB 연결 실패
```python
try:
    cursor.execute(query, params)
except Exception as e:
    issues.append(f"❌ DB 검증 중 오류 발생: {e}")
    return False, issues, details
```

### LLM 검증 실패
```python
try:
    response = openai_client.chat.completions.create(...)
except Exception as e:
    return False, [f"❌ LLM 검증 오류: {e}"], 0.0
```

---

## 📝 로그 분석 예시

### 성공 케이스 (96점 PASS)
```
[Attempt 1] 답변 생성 완료 (길이: 406자)
[Attempt 1] 검증 시작...
=== STEP 1: Information Extraction ===
추출된 정보: {'region': '서울특별시 종로구', ...}
=== STEP 2: Hard Rule 검증 ===
Hard Rule 검증 결과: 통과
=== STEP 3: Semantic Consistency ===
의미적 일관성 검증 결과: {'consistency_score': 90}
최종 검증 결과: PASS (점수: 96.0)
✅ [Attempt 1] 검증 통과! 답변 반환
```

### 재시도 케이스 (수정 전 버그)
```
[Attempt 1] 검증 완료: 96.0/100
❌ [Attempt 1] 검증 실패 (점수: 96.0)  ← 버그!
→ 피드백 반영하여 재생성 시도...
[Attempt 2] 검증 완료: 96.0/100
❌ [Attempt 2] 검증 실패 (점수: 96.0)  ← 버그!
→ 피드백 반영하여 재생성 시도...
```

**버그 원인**: `status == "PASS"` → Enum 비교 오류  
**수정 후**: `status == VerificationStatus.PASS` → 정상 동작

---

## 🎯 핵심 개선사항

### 수정 전 문제점
1. ❌ 문자열 vs Enum 비교 오류 → PASS인데도 계속 재시도
2. ❌ cited_laws None 처리 누락 → Pydantic 검증 실패
3. ❌ 불필요한 3회 재시도 → 시간 낭비 (60초)

### 수정 후
1. ✅ VerificationStatus Enum 올바른 비교
2. ✅ cited_laws None → 빈 리스트 변환
3. ✅ 70점 이상 즉시 PASS → 속도 향상 (15초)

---

## 📚 참엽 코드 위치

### 검증 파이프라인
- `python/services/law_verification.py`
  - `ArchitectureLawValidator` 클래스
  - `extract_info_from_answer()` - STEP 1
  - `verify_against_db()` - STEP 2
  - `verify_semantic_consistency()` - STEP 3
  - `verify()` - STEP 4 (통합)

### 재시도 로직
- `python/main.py`
  - `/ask` 엔드포인트
  - 최대 3회 재시도 루프
  - 피드백 생성 및 챗봇 재호출

### 테스트 코드
- `python/test_law_verification.py`
  - 5가지 테스트 케이스
  - DB 연결 테스트
  - 정보 추출 테스트
  - Hard Rule 검증 테스트
  - 실패 케이스 테스트

---

## 🔮 향후 개선 방향

1. **건폐율/용적률 DB 정규화**
   - 현재: condition_exception 텍스트에서 정규식 파싱
   - 개선: 별도 컬럼으로 분리 (building_coverage_ratio, floor_area_ratio)

2. **캐싱 강화**
   - 동일 질문에 대한 검증 결과 캐싱
   - DB 조회 결과 캐싱

3. **병렬 처리**
   - Hard Rule과 Semantic 검증 병렬 실행

4. **세밀한 가중치 조정**
   - 현재: Hard 60%, Semantic 40%
   - 질문 유형별 가중치 동적 조정

5. **A/B 테스트**
   - 검증 유무에 따른 답변 품질 비교
   - 임계값 최적화 (70점 vs 75점 vs 80점)

---

## ✅ 검증 에이전트 완료!

이 시스템은 법규 챗봇의 답변 품질을 자동으로 보장하며, 환각 및 오류를 최소화합니다.
