# `pipeline.py` 함수 단위 상세 문서

이 문서는 `python/floorplan/pipeline.py`의 `ArchitecturalHybridRAG` 클래스에 정의된 모든 함수를 함수 단위로 설명합니다.

## 파일 개요

- 역할: 사용자 자연어 질의를 해석해 검색 조건으로 변환하고, `FP_Analysis` 테이블에서 하이브리드(벡터+텍스트) 검색 후 대표 도면 설명을 생성.
- 핵심 외부 시스템:
1. OpenAI Chat Completions (`gpt-5.2`) - 질의 해석 및 최종 답변 생성
2. OpenAI Embeddings (`text-embedding-3-small`, 기본) - 벡터 검색용 질의 임베딩 생성
3. PostgreSQL + pgvector - 조건 필터링, 유사도 계산, 정렬, 건수 집계

---

## 1) `__init__(...)`

### (1) 목적
클래스 실행에 필요한 초기 상태를 구성합니다. DB 연결, SQL 보조 함수 준비, OpenAI 클라이언트 생성, 가중치 정규화, 동의어 사전(`word.json`) 로딩을 한 번에 수행합니다.

### (2) 입력 파라미터/타입/의미
1. `db_config` (`dict`): `psycopg2.connect(**db_config)`에 전달할 DB 접속 정보
2. `openai_api_key` (`str`): OpenAI API 키
3. `embedding_model` (`str`, 기본 `"text-embedding-3-small"`): 임베딩 모델명
4. `embedding_dimensions` (`int`, 기본 `1024`): 임베딩 차원
5. `vector_weight` (`float`, 기본 `0.8`): 벡터 유사도 가중치
6. `text_weight` (`float`, 기본 `0.2`): 텍스트 검색 점수 가중치

### (3) 반환값/출력
- 명시적 반환값 없음(`None`)
- 주요 부수효과:
1. `self.conn` DB 연결 생성
2. `ratio_cmp` SQL 함수 준비 시도
3. `self.client` OpenAI 클라이언트 생성
4. `self.vector_weight`, `self.text_weight` 정규화 저장
5. `self.word_dict` 로딩

### (4) 내부 처리 흐름(단계별)
1. 로거 초기화
2. `psycopg2.connect`로 PostgreSQL 연결
3. `_ensure_ratio_cmp_function()` 호출
4. `OpenAI(api_key=...)` 생성
5. `_normalize_hybrid_weights(...)`로 가중치 정규화
6. `data/word.json` 읽어 딕셔너리 로드(실패 시 빈 dict + warning)

### (5) 사용하는 외부 의존성/DB/환경변수
1. `logging`, `json`, `pathlib.Path`
2. `psycopg2`
3. `openai.OpenAI`
4. DB: 연결만 수행(테이블 접근은 다른 함수)
5. 환경변수: 이 함수는 직접 읽지 않음. 보통 `python/floorplan/main.py`에서 `OPENAI_API_KEY`, `POSTGRES_*`를 읽어 인자로 전달

### (6) 예외/에러 케이스
1. DB 연결 실패 시 `psycopg2` 예외 발생 가능
2. OpenAI 클라이언트 생성 자체는 성공해도 이후 호출 시 인증 실패 가능
3. `word.json` 로드 실패는 내부에서 예외를 삼키고 warning만 남김

### (7) 호출 관계
1. 호출자:
   `python/floorplan/main.py`의 `build_rag()`에서 생성자 호출
2. 피호출:
   `_ensure_ratio_cmp_function()`, `_normalize_hybrid_weights()`

### (8) 간단한 사용 예시
```python
rag = ArchitecturalHybridRAG(
    db_config={
        "host": "localhost",
        "port": 5432,
        "database": "arae",
        "user": "postgres",
        "password": "1234",
    },
    openai_api_key="sk-...",
    embedding_model="text-embedding-3-small",
    embedding_dimensions=1024,
    vector_weight=0.8,
    text_weight=0.2,
)
```

---

## 2) `_normalize_hybrid_weights(vector_weight, text_weight) -> tuple[float, float]`

### (1) 목적
벡터/텍스트 가중치를 합계 1.0 비율로 정규화하고 유효성(음수/합계 0)을 검증합니다.

### (2) 입력 파라미터/타입/의미
1. `vector_weight` (`float`)
2. `text_weight` (`float`)

### (3) 반환값/출력
- `(normalized_vector_weight, normalized_text_weight)` 튜플 반환

### (4) 내부 처리 흐름(단계별)
1. 두 값을 `float`로 캐스팅
2. 음수 여부 체크(음수면 `ValueError`)
3. 합계 계산
4. 합계가 0이면 `ValueError`
5. 각 값을 합계로 나눠 정규화 후 반환

### (5) 사용하는 외부 의존성/DB/환경변수
- 외부 의존성/DB/환경변수 없음

### (6) 예외/에러 케이스
1. 입력이 숫자로 변환 불가 시 `ValueError`/`TypeError` 가능
2. 음수 입력 시 `ValueError`
3. 합계 0 시 `ValueError`

### (7) 호출 관계
1. 호출자:
   `__init__`
2. 피호출:
   없음

### (8) 간단한 사용 예시
```python
v, t = rag._normalize_hybrid_weights(0.8, 0.2)
# 결과: (0.8, 0.2)
```

---

## 3) `_analyze_query(query: str) -> dict`

### (1) 목적
사용자 자연어 질의를 LLM으로 구조화해 `filters/documents/raw_query` 형태의 검색 입력으로 변환합니다.

### (2) 입력 파라미터/타입/의미
1. `query` (`str`): 사용자의 원문 질의

### (3) 반환값/출력
- `dict` 반환
1. 성공 시: `{"filters": ..., "documents": ..., "raw_query": ...}`
2. 실패 시 폴백: `{"filters": {}, "documents": query, "raw_query": query}`

### (4) 내부 처리 흐름(단계별)
1. `word_dict`를 포함한 시스템 프롬프트 구성
2. `gpt-5.2`에 `response_format={"type":"json_object"}`로 호출
3. 응답 텍스트 정리(코드블록 제거, JSON 경계 탐색)
4. JSON 파싱 후 `filters`/`documents` 추출
5. `_normalize_filters()`로 필터 정규화
6. `_augment_filters_from_query()`로 규칙 기반 보강
7. `_drop_implicit_ratio_filters()`로 암시적 비율 필터 제거
8. 결과 반환
9. 중간 단계 실패 시 keyword-only 폴백 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. `json`
2. OpenAI Chat Completions (`self.client.chat.completions.create`)
3. DB 직접 접근 없음
4. 환경변수 직접 접근 없음(키는 생성자 인자 기반)

### (6) 예외/에러 케이스
1. OpenAI API 오류(네트워크, 인증, 할당량)
2. 응답이 비어 있거나 JSON 스키마가 맞지 않음
3. JSON 파싱 실패
4. 위 오류는 내부 `except`에서 폴백 처리

### (7) 호출 관계
1. 호출자:
   `run()`
2. 피호출:
   `_normalize_filters()`, `_augment_filters_from_query()`, `_drop_implicit_ratio_filters()`

### (8) 간단한 사용 예시
```python
query_json = rag._analyze_query("3베이 판상형, 환기 우수한 도면")
# 예: {"filters": {"bay_count": 3, "structure_type": "판상형", "ventilation_grade": "우수"}, ...}
```

---

## 4) `_normalize_filters(raw_filters: dict[str, Any]) -> dict[str, Any]`

### (1) 목적
LLM이 생성한 필터를 허용 컬럼 기준으로 정리하고, 타입 변환/alias 반영/ratio split-key 병합을 수행합니다.

### (2) 입력 파라미터/타입/의미
1. `raw_filters` (`dict[str, Any]`): LLM 출력 필터 원본

### (3) 반환값/출력
- `dict[str, Any]`: DB 조건으로 사용할 정규화 필터

### (4) 내부 처리 흐름(단계별)
1. `FILTER_ALIASES` 적용(`ventilation_quality` -> `ventilation_grade`)
2. 허용된 컬럼(`ALLOWED_FILTER_COLUMNS`)만 통과
3. 각 값은 `_coerce_filter_value()`로 타입 정제
4. ratio split-key(`kitchen_ratio_op`, `kitchen_ratio_val` 등)도 보완 파싱
5. 정규화 결과 반환

### (5) 사용하는 외부 의존성/DB/환경변수
- DB/환경변수 접근 없음

### (6) 예외/에러 케이스
- 내부적으로 예외를 적극 발생시키기보다 유효하지 않은 값은 제외하는 방식

### (7) 호출 관계
1. 호출자:
   `_analyze_query()`
2. 피호출:
   `_coerce_filter_value()`

### (8) 간단한 사용 예시
```python
normalized = rag._normalize_filters({
    "ventilation_quality": "우수",
    "bay_count": "3베이",
    "kitchen_ratio_op": "이상",
    "kitchen_ratio_val": "12",
})
```

---

## 5) `_coerce_filter_value(key: str, value: Any) -> Any`

### (1) 목적
필터 키 타입 규칙(INT/FLOAT/BOOL/STRING)에 맞춰 단일 값을 안전하게 변환합니다.

### (2) 입력 파라미터/타입/의미
1. `key` (`str`): 필터 컬럼명
2. `value` (`Any`): 원본 값

### (3) 반환값/출력
- 변환된 값(`int`, `dict`, `bool`, `str`) 또는 변환 실패 시 `None`

### (4) 내부 처리 흐름(단계별)
1. `None` 즉시 반환
2. INT 필터면 숫자/문자열에서 정수 추출
3. FLOAT(비율) 필터면 `_coerce_ratio_filter()` 호출
4. BOOL 필터면 문자열 true/false 계열 해석
5. 기타는 문자열 정리 후 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. `re`(정수 패턴 파싱)
2. DB/환경변수 없음

### (6) 예외/에러 케이스
- 변환 불가 값은 예외 대신 `None` 반환(상위에서 제외됨)

### (7) 호출 관계
1. 호출자:
   `_normalize_filters()`
2. 피호출:
   `_coerce_ratio_filter()`

### (8) 간단한 사용 예시
```python
rag._coerce_filter_value("bay_count", "4베이")          # 4
rag._coerce_filter_value("has_special_space", "true")  # True
```

---

## 6) `_coerce_ratio_filter(value: Any) -> Optional[dict[str, Any]]`

### (1) 목적
비율 조건값을 `{"op": ..., "val": ...}` 형태로 정규화합니다.

### (2) 입력 파라미터/타입/의미
1. `value` (`Any`): 숫자/문자열/딕셔너리 형태 비율 입력

### (3) 반환값/출력
- 성공 시 `{"op": str|None, "val": float|None}`
- 실패 시 `None`

### (4) 내부 처리 흐름(단계별)
1. `None`/`bool`은 무효
2. 숫자 단일 입력은 `"동일"` 연산자로 매핑
3. 문자열 입력은 연산자(`이상/이하/초과/미만/동일`)와 숫자 추출
4. dict 입력은 `op/operator`, `val/value` 키 모두 수용
5. `op`은 `_normalize_ratio_operator()`, 값은 `_parse_float()`로 정제

### (5) 사용하는 외부 의존성/DB/환경변수
1. `re`
2. DB/환경변수 없음

### (6) 예외/에러 케이스
- 예외 발생보다는 `None` 반환 중심
- 연산자가 잘못된 경우 `op=None`으로 남아 SQL에서 무시되도록 설계

### (7) 호출 관계
1. 호출자:
   `_coerce_filter_value()`
2. 피호출:
   `_normalize_ratio_operator()`, `_parse_float()`

### (8) 간단한 사용 예시
```python
rag._coerce_ratio_filter("이상 20")              # {"op": "이상", "val": 20.0}
rag._coerce_ratio_filter({"op": "미만", "val": "5.5"})  # {"op": "미만", "val": 5.5}
```

---

## 7) `_normalize_ratio_operator(op: Any) -> Optional[str]`

### (1) 목적
비율 비교 연산자를 허용 집합으로 제한해 검증합니다.

### (2) 입력 파라미터/타입/의미
1. `op` (`Any`): 후보 연산자

### (3) 반환값/출력
- 허용 연산자면 해당 문자열 반환
- 아니면 `None`

### (4) 내부 처리 흐름(단계별)
1. 문자열 여부 확인
2. 공백 제거
3. `VALID_RATIO_OPERATORS` 포함 여부 검증

### (5) 사용하는 외부 의존성/DB/환경변수
- 없음

### (6) 예외/에러 케이스
- 예외를 던지지 않고 `None` 반환

### (7) 호출 관계
1. 호출자:
   `_coerce_ratio_filter()`
2. 피호출:
   없음

### (8) 간단한 사용 예시
```python
rag._normalize_ratio_operator("이하")   # "이하"
rag._normalize_ratio_operator("gte")    # None
```

---

## 8) `_parse_float(value: Any) -> Optional[float]`

### (1) 목적
숫자/숫자 문자열에서 float를 파싱해 반환합니다.

### (2) 입력 파라미터/타입/의미
1. `value` (`Any`): 파싱 대상

### (3) 반환값/출력
- 파싱 성공 시 `float`
- 실패 시 `None`

### (4) 내부 처리 흐름(단계별)
1. `None`/`bool` 제외
2. 숫자형이면 `float(value)` 반환
3. 문자열이면 정규식으로 첫 번째 실수 패턴 추출
4. 없으면 `None`

### (5) 사용하는 외부 의존성/DB/환경변수
1. `re`
2. DB/환경변수 없음

### (6) 예외/에러 케이스
- 문자열이 숫자 패턴을 포함하지 않으면 `None`

### (7) 호출 관계
1. 호출자:
   `_coerce_ratio_filter()`
2. 피호출:
   없음

### (8) 간단한 사용 예시
```python
rag._parse_float("약 12.5%")   # 12.5
rag._parse_float("abc")        # None
```

---

## 9) `_ensure_ratio_cmp_function() -> None`

### (1) 목적
PostgreSQL에 `ratio_cmp(field_val, op, val)` 함수를 생성/갱신해 비율 조건 비교를 표준화합니다.

### (2) 입력 파라미터/타입/의미
- 없음

### (3) 반환값/출력
- 반환값 없음
- 부수효과: DB에 SQL 함수 생성 시도, 성공 시 commit/실패 시 rollback

### (4) 내부 처리 흐름(단계별)
1. `CREATE OR REPLACE FUNCTION public.ratio_cmp ...` SQL 정의
2. 커서 열어 SQL 실행
3. 성공 시 `commit`
4. 실패 시 `rollback` 후 예외 로그 기록

### (5) 사용하는 외부 의존성/DB/환경변수
1. DB: PostgreSQL 연결(`self.conn`)
2. 의존성: `psycopg2` 커서/트랜잭션
3. 환경변수 직접 접근 없음

### (6) 예외/에러 케이스
1. 권한 부족/DB 연결 오류/SQL 실행 실패
2. 내부에서 예외를 외부로 재전파하지 않고 로그 처리

### (7) 호출 관계
1. 호출자:
   `__init__`
2. 피호출:
   없음

### (8) 간단한 사용 예시
```python
rag._ensure_ratio_cmp_function()
# DB에 ratio_cmp 함수가 생성/갱신됨
```

---

## 10) `_augment_filters_from_query(query: str, filters: dict[str, Any]) -> dict[str, Any]`

### (1) 목적
LLM 필터에 누락된 구조화 조건을 정규식/키워드 규칙으로 보강합니다.

### (2) 입력 파라미터/타입/의미
1. `query` (`str`): 원문 질의
2. `filters` (`dict[str, Any]`): 현재 필터 상태

### (3) 반환값/출력
- 보강된 필터 딕셔너리

### (4) 내부 처리 흐름(단계별)
1. 복사본 `augmented` 생성
2. `structure_type`(판상형/타워형/복도형) 보강
3. `bay_count`, `room_count`, `bathroom_count` 정규식 추출
4. `ventilation_grade`(우수/보통/미흡) 보강
5. 결과 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. `re`
2. DB/환경변수 없음

### (6) 예외/에러 케이스
- 예외 처리 블록은 없으나, 일반 문자열 연산 중심이라 런타임 위험이 낮음

### (7) 호출 관계
1. 호출자:
   `_analyze_query()`
2. 피호출:
   없음

### (8) 간단한 사용 예시
```python
rag._augment_filters_from_query(
    "판상형 4베이, 화장실 2개, 환기 우수",
    {}
)
# {"structure_type":"판상형","bay_count":4,"bathroom_count":2,"ventilation_grade":"우수"}
```

---

## 11) `_drop_implicit_ratio_filters(query: str, filters: dict[str, Any]) -> dict[str, Any]`

### (1) 목적
사용자가 비율 숫자 의도를 명시하지 않았으면 ratio 필터를 제거해 과도한 필터링을 방지합니다.

### (2) 입력 파라미터/타입/의미
1. `query` (`str`)
2. `filters` (`dict[str, Any]`)

### (3) 반환값/출력
- 비율 필터 제거 여부가 반영된 필터 딕셔너리

### (4) 내부 처리 흐름(단계별)
1. 질의에 `%`, `퍼센트`, `비율`, `ratio`, `이상/이하/초과/미만/동일` 포함 여부 검사
2. 포함되면 기존 필터 그대로 반환
3. 미포함이면 `FLOAT_FILTERS` 키 제거 후 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. `re`
2. DB/환경변수 없음

### (6) 예외/에러 케이스
- 특별한 예외 처리 없음

### (7) 호출 관계
1. 호출자:
   `_analyze_query()`
2. 피호출:
   없음

### (8) 간단한 사용 예시
```python
rag._drop_implicit_ratio_filters(
    "환기 좋은 평면",
    {"windowless_ratio": {"op": "이하", "val": 10.0}, "bay_count": 4}
)
# {"bay_count": 4}
```

---

## 12) `_retrieve_hybrid(query_json: dict, top_k: int = 50) -> list`

### (1) 목적
필터 조건 + 임베딩 유사도 + 텍스트 랭킹을 결합해 후보 도면 목록을 DB에서 조회합니다.

### (2) 입력 파라미터/타입/의미
1. `query_json` (`dict`): `_analyze_query()` 결과
2. `top_k` (`int`, 기본 `50`): 최대 반환 개수

### (3) 반환값/출력
- `list`(DB `fetchall()` 결과 튜플 목록)
- 각 행은 `document_id`, `document`, 메타데이터 컬럼들, `similarity` 포함

### (4) 내부 처리 흐름(단계별)
1. `filters/documents/raw_query` 추출 후 `semantic_query` 구성
2. Embedding API 호출로 질의 벡터 생성
3. 필터를 SQL `WHERE` 절로 조립(비율은 `ratio_cmp`, 나머지는 `=` 비교)
4. CTE(`scored`)에서
   - `vector_similarity = 1 - (embedding <=> query_vector)`
   - `text_score = ts_rank_cd(...)`
5. 최종 `similarity = vector_weight * vector_similarity + text_weight * text_score`
6. `ORDER BY similarity DESC LIMIT top_k` 후 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. OpenAI Embeddings API
2. PostgreSQL 테이블: `FP_Analysis`
3. PostgreSQL 함수/기능: `ratio_cmp`, `to_tsvector`, `websearch_to_tsquery`, `ts_rank_cd`, pgvector `<=>`
4. 환경변수 직접 접근 없음

### (6) 예외/에러 케이스
1. OpenAI Embeddings 호출 실패
2. DB 쿼리 실패(테이블/컬럼/함수 미존재, 타입 불일치 등)
3. 이 함수 내 별도 예외 처리 없음(상위로 전파)

### (7) 호출 관계
1. 호출자:
   `run()`
2. 피호출:
   OpenAI Embeddings API, PostgreSQL 쿼리 실행

### (8) 간단한 사용 예시
```python
query_json = {"filters": {"bay_count": 4}, "documents": "채광 좋은 평면", "raw_query": "4베이 채광"}
rows = rag._retrieve_hybrid(query_json, top_k=10)
```

---

## 13) `_count_matches(filters: dict[str, Any]) -> int`

### (1) 목적
필터만 적용했을 때 조건 일치 도면 총 개수(`total_count`)를 계산합니다.

### (2) 입력 파라미터/타입/의미
1. `filters` (`dict[str, Any]`): 필터 딕셔너리

### (3) 반환값/출력
- 조건 일치 건수(`int`)

### (4) 내부 처리 흐름(단계별)
1. 필터를 `WHERE` 절로 변환(`ratio_cmp`/`=` 규칙 동일)
2. `SELECT COUNT(*) FROM FP_Analysis WHERE ...` 실행
3. `fetchone()[0]`를 `int`로 변환 후 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. PostgreSQL 테이블: `FP_Analysis`
2. PostgreSQL 함수: `ratio_cmp`
3. 환경변수 직접 접근 없음

### (6) 예외/에러 케이스
- DB 오류 시 예외 전파

### (7) 호출 관계
1. 호출자:
   `run()`
2. 피호출:
   PostgreSQL 쿼리 실행

### (8) 간단한 사용 예시
```python
count = rag._count_matches({"structure_type": "판상형", "bay_count": 4})
```

---

## 14) `_generate_answer(query: str, query_json: dict, docs: list, total_match_count: int) -> str`

### (1) 목적
조회 결과 중 대표 도면 1건(`docs[0]`)을 기준으로 사용자에게 보여줄 최종 한국어 설명문을 생성합니다.

### (2) 입력 파라미터/타입/의미
1. `query` (`str`): 원문 질의
2. `query_json` (`dict`): 정규화된 검색 조건
3. `docs` (`list`): `_retrieve_hybrid()` 조회 결과
4. `total_match_count` (`int`): `_count_matches()` 결과

### (3) 반환값/출력
- 최종 답변 문자열(`str`)
- 단, `docs`가 비어 있으면 `"Try searching again."` 반환

### (4) 내부 처리 흐름(단계별)
1. 빈 결과면 즉시 안내문 반환
2. `docs[0]`를 대표 도면으로 선택
3. 검색된 전체 도면 ID 목록 생성
4. 대표 도면 메타데이터 dict 구성
5. 강한 출력 형식 제약을 포함한 시스템 프롬프트 작성
6. user 메시지에 `대표 도면 id`, `total_count`, `검색 조건`, `대표 도면 document` 등 주입
7. `gpt-5.2` 호출(temperature=0.0)
8. 생성 텍스트를 `.strip()` 후 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. OpenAI Chat Completions (`gpt-5.2`)
2. `json.dumps` (조건/메타데이터 직렬화)
3. DB 직접 접근 없음
4. 환경변수 직접 접근 없음

### (6) 예외/에러 케이스
1. `docs[0]` 구조가 예상 컬럼 수와 다르면 언패킹 오류 가능
2. OpenAI API 실패 시 예외 전파

### (7) 호출 관계
1. 호출자:
   `run()`
2. 피호출:
   OpenAI Chat Completions API

### (8) 간단한 사용 예시
```python
answer = rag._generate_answer(
    query="4베이 판상형",
    query_json={"filters": {"bay_count": 4, "structure_type": "판상형"}},
    docs=rows,
    total_match_count=48,
)
```

---

## 15) `run(query: str) -> str`

### (1) 목적
클래스의 메인 엔트리포인트입니다. 질의 분석 -> 건수 집계 -> 검색 -> 답변 생성까지 전체 파이프라인을 순차 실행합니다.

### (2) 입력 파라미터/타입/의미
1. `query` (`str`): 사용자 질의

### (3) 반환값/출력
- 최종 답변 문자열(`str`)

### (4) 내부 처리 흐름(단계별)
1. Stage 1: `_analyze_query(query)` 호출
2. Stage 1.5: `_count_matches(filters)`로 총 일치 건수 계산
3. `retrieve_k = min(max(total_match_count, 1), 50)` 산정
4. Stage 2: `_retrieve_hybrid(query_json, top_k=retrieve_k)` 호출
5. Stage 3: `_generate_answer(query, query_json, docs, total_match_count)` 호출
6. 최종 답변 반환

### (5) 사용하는 외부 의존성/DB/환경변수
1. 로그 출력(`logging`)
2. 하위 함수들이 사용하는 OpenAI/DB 의존성 간접 사용
3. 환경변수 직접 접근 없음

### (6) 예외/에러 케이스
- 하위 함수에서 발생한 예외를 별도로 잡지 않고 호출자에게 전파

### (7) 호출 관계
1. 호출자:
   `python/floorplan/main.py`의 `run_once()` 등 외부 실행 코드
2. 피호출:
   `_analyze_query()`, `_count_matches()`, `_retrieve_hybrid()`, `_generate_answer()`

### (8) 간단한 사용 예시
```python
result_text = rag.run("판상형 4베이이면서 환기 우수한 도면 찾아줘")
print(result_text)
```

---

## 전체 호출 흐름 요약

1. 외부 호출: `main.py -> build_rag() -> ArchitecturalHybridRAG(...)`
2. 질의 실행: `main.py -> rag.run(query)`
3. 내부 파이프라인:
   `run -> _analyze_query -> (_normalize_filters -> _coerce_filter_value -> _coerce_ratio_filter -> _normalize_ratio_operator/_parse_float)`
4. 조건 집계:
   `run -> _count_matches`
5. 검색:
   `run -> _retrieve_hybrid`
6. 최종 응답:
   `run -> _generate_answer`

## 참고 사항

1. 이 파일의 비공개 메서드(`_...`)는 내부 호출을 가정한 설계입니다.
2. `FP_Analysis` 테이블 스키마가 코드에서 기대하는 컬럼과 다르면 검색/언패킹 오류가 발생할 수 있습니다.
3. `embedding_dimensions` 기본값(1024)과 DB `embedding` 벡터 차원은 반드시 일치해야 합니다.
