import json
import logging
import re
import time
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Optional
import psycopg2
from openai import OpenAI


@dataclass
class AnswerValidationResult:
    ok: bool
    has_document_id_token: bool
    has_metadata_summary: bool
    has_layout_summary: bool
    missing_fields: list[str] = field(default_factory=list)


class ArchitecturalHybridRAG:
    ALLOWED_FILTER_COLUMNS = [
        "windowless_ratio",
        "balcony_ratio",
        "living_room_ratio",
        "bathroom_ratio",
        "kitchen_ratio",
        "structure_type",
        "bay_count",
        "room_count",
        "bathroom_count",
        "compliance_grade",
        "ventilation_grade",
        "has_special_space",
        "has_etc_space",
    ]

    FILTER_ALIASES = {
        "ventilation_quality": "ventilation_grade",
    }

    INT_FILTERS = {"bay_count", "room_count", "bathroom_count"}
    FLOAT_FILTERS = {
        "windowless_ratio",
        "balcony_ratio",
        "living_room_ratio",
        "bathroom_ratio",
        "kitchen_ratio",
    }
    BOOL_FILTERS = {"has_special_space", "has_etc_space"}
    VALID_RATIO_OPERATORS = {"ì´ìƒ", "ì´í•˜", "ì´ˆê³¼", "ë¯¸ë§Œ", "ë™ì¼"}
    FLOORPLAN_IMAGE_NAME_RE = re.compile(
        r"^[A-Za-z0-9][A-Za-z0-9_.-]*\.(?:png|jpg|jpeg|bmp|tif|tiff|webp)$",
        re.IGNORECASE,
    )
    DOCUMENT_SIGNAL_KEY_ALIASES = {
        "lighting": ("lighting", "ì±„ê´‘"),
        "ventilation": ("ventilation", "í™˜ê¸°"),
        "family_harmony": ("family_harmony", "ê°€ì¡± ìœµí™”", "ê°€ì¡±ìœµí™”"),
        "storage": ("storage", "ìˆ˜ë‚©ê³µê°„", "ìˆ˜ë‚© ê³µê°„"),
    }
    DOCUMENT_SIGNAL_KR_LABELS = {
        "lighting": "ì±„ê´‘",
        "ventilation": "í™˜ê¸°",
        "family_harmony": "ê°€ì¡± ìœµí™”",
        "storage": "ìˆ˜ë‚©ê³µê°„",
    }
    POSITIVE_SIGNAL_WORDS = ("ìš°ìˆ˜", "ì ì •", "ì í•©", "ì–‘í˜¸", "ì¶©ë¶„", "ë„‰ë„‰")
    NEGATIVE_SIGNAL_WORDS = ("ë¯¸í¡", "ë¶€ì¡±", "ë¶€ì í•©", "ë¶ˆí•©ê²©", "ë¯¸ë‹¬", "ì—†ìŒ")
    SIGNAL_POSITIVE_DISPLAY = {
        "lighting": "ì¢‹ìŒ",
        "ventilation": "ì¢‹ìŒ",
        "family_harmony": "ì í•©",
        "storage": "ë„‰ë„‰í•¨",
    }
    SIGNAL_NEGATIVE_DISPLAY = {
        "lighting": "ë¶€ì¡±í•¨",
        "ventilation": "ë¶€ì¡±í•¨",
        "family_harmony": "ë¯¸í¡í•¨",
        "storage": "ë¶€ì¡±í•¨",
    }
    DOCUMENT_ID_LINE_RE = re.compile(r"(?m)^1\.\s*ê²€ìƒ‰ëœ ë„ë©´ id:\s*(.+)\s*$")
    GENERAL_ID_TOKEN_RE = re.compile(r"ê²€ìƒ‰ëœ\s*ë„ë©´\s*id", re.IGNORECASE)
    METADATA_SECTION_TOKEN = "2. ë„ë©´ ê¸°ë³¸ ì •ë³´ ìš”ì•½"
    LAYOUT_SECTION_TOKEN = "3. ë„ë©´ ê³µê°„ êµ¬ì„± ì„¤ëª…"
    NO_MATCH_COUNT_LINE_RE = re.compile(
        r"ì¡°ê±´ì„\s*ë§Œì¡±í•˜ëŠ”\s*ë„ë©´\s*ì´\s*ê°œìˆ˜\s*:\s*0",
        re.IGNORECASE,
    )
    NO_MATCH_ID_LINE_RE = re.compile(
        r"ê²€ìƒ‰ëœ\s*ë„ë©´\s*id\s*:\s*ì—†ìŒ",
        re.IGNORECASE,
    )
    NO_MATCH_MESSAGE_TOKEN = "ìš”ì²­ ì¡°ê±´ê³¼ ì¼ì¹˜í•˜ëŠ” ë„ë©´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    def __init__(
        self,
        db_config,
        openai_api_key,
        embedding_model: str = "text-embedding-3-small",
        embedding_dimensions: int = 512,
        vector_weight: float = 0.8,
        text_weight: float = 0.2,
        answer_validation_enabled: bool = True,
        answer_validation_retry_max: int = 1,
        answer_validation_safe_fallback: bool = True,
    ):
        self.logger = logging.getLogger(self.__class__.__name__)
        if not self.logger.handlers:
            logging.basicConfig(
                level=logging.INFO,
                format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
            )

        self.conn = psycopg2.connect(**db_config)
        self._ensure_ratio_cmp_function()
        self.client = OpenAI(api_key=openai_api_key)
        self.embedding_model = embedding_model
        self.embedding_dimensions = embedding_dimensions
        self.vector_weight, self.text_weight = self._normalize_hybrid_weights(
            vector_weight, text_weight
        )
        self.answer_validation_enabled = bool(answer_validation_enabled)
        self.answer_validation_retry_max = max(0, int(answer_validation_retry_max))
        self.answer_validation_safe_fallback = bool(answer_validation_safe_fallback)
        self.word_dict: dict[str, Any] = {}
        word_path = Path(__file__).resolve().parent / "data" / "word.json"
        try:
            with word_path.open("r", encoding="utf-8") as f:
                loaded = json.load(f)
            self.word_dict = loaded if isinstance(loaded, dict) else {}
        except Exception as exc:  
            self.word_dict = {}
            self.logger.warning("Failed to load word dictionary (%s): %s", word_path, exc)

    def _log_event(self, event: str, level: int = logging.INFO, **fields: Any) -> None:
        try:
            payload = json.dumps(fields, ensure_ascii=False, sort_keys=True, default=str)
        except Exception:
            payload = str(fields)
        self.logger.log(level, "event=%s data=%s", event, payload)

    def _validate_answer_format(
        # LLM ë‹µë³€ í˜•ì‹ì´ ì§€ì¼œì¡ŒëŠ”ê°€ 
        self,
        answer: str,
        mode: str,
        expected_document_id: Optional[str] = None,
    ) -> AnswerValidationResult:
        text = str(answer or "")
        missing_fields: list[str] = []

        is_non_empty = bool(text.strip())
        if not is_non_empty:
            missing_fields.append("non_empty_answer")

        normalized_mode = mode.strip().lower()
        if normalized_mode == "no_match":
            has_metadata_summary = bool(self.NO_MATCH_COUNT_LINE_RE.search(text))
            has_document_id_token = bool(self.NO_MATCH_ID_LINE_RE.search(text))
            has_layout_summary = self.NO_MATCH_MESSAGE_TOKEN in text
            if not has_metadata_summary:
                missing_fields.append("no_match_count")
            if not has_document_id_token:
                missing_fields.append("document_id_none")
            if not has_layout_summary:
                missing_fields.append("no_match_message")
            ok = (
                is_non_empty
                and has_document_id_token
                and has_metadata_summary
                and has_layout_summary
            )
            return AnswerValidationResult(
                ok=ok,
                has_document_id_token=has_document_id_token,
                has_metadata_summary=has_metadata_summary,
                has_layout_summary=has_layout_summary,
                missing_fields=missing_fields,
            )

        has_metadata_summary = self.METADATA_SECTION_TOKEN in text
        if not has_metadata_summary:
            missing_fields.append("metadata_summary")

        has_layout_summary = self.LAYOUT_SECTION_TOKEN in text
        if not has_layout_summary:
            missing_fields.append("layout_summary")

        if normalized_mode == "document_id":
            expected = (expected_document_id or "").strip()
            has_document_id_token = bool(
                re.search(
                    rf"(?m)^1\.\s*ê²€ìƒ‰ëœ ë„ë©´ id:\s*{re.escape(expected)}\s*$",
                    text,
                )
            )
        elif normalized_mode == "general":
            has_document_id_token = bool(self.GENERAL_ID_TOKEN_RE.search(text))
        else:
            raise ValueError(f"Unsupported validation mode: {mode}")

        if not has_document_id_token:
            missing_fields.append("document_id_token")

        ok = (
            is_non_empty
            and has_document_id_token
            and has_metadata_summary
            and has_layout_summary
        )
        return AnswerValidationResult(
            ok=ok,
            has_document_id_token=has_document_id_token,
            has_metadata_summary=has_metadata_summary,
            has_layout_summary=has_layout_summary,
            missing_fields=missing_fields,
        )

    def _build_safe_default_answer(
        self, mode: str, expected_document_id: Optional[str] = None
    ) -> str:
        normalized_mode = mode.strip().lower()
        if normalized_mode == "document_id":
            document_id = (expected_document_id or "ì •ë³´ ìƒì„± ë¶ˆê°€").strip() or "ì •ë³´ ìƒì„± ë¶ˆê°€"
            return (
                f"1. ê²€ìƒ‰ëœ ë„ë©´ id: {document_id}\n\n"
                "2. ë„ë©´ ê¸°ë³¸ ì •ë³´ ìš”ì•½ ğŸ“Š\n"
                "- ì‘ë‹µ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨ë¡œ ìš”ì•½ ìƒì„± ë¶ˆê°€\n\n"
                "3. ë„ë©´ ê³µê°„ êµ¬ì„± ì„¤ëª… ğŸ§©\n"
                "- ì‘ë‹µ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì„¤ëª… ìƒì„± ë¶ˆê°€"
            )
        if normalized_mode == "general":
            return (
                "1. ê²€ìƒ‰ëœ ë„ë©´ id: ì •ë³´ ìƒì„± ë¶ˆê°€\n\n"
                "2. ë„ë©´ ê¸°ë³¸ ì •ë³´ ìš”ì•½ ğŸ“Š\n"
                "- ì‘ë‹µ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨ë¡œ ìš”ì•½ ìƒì„± ë¶ˆê°€\n\n"
                "3. ë„ë©´ ê³µê°„ êµ¬ì„± ì„¤ëª… ğŸ§©\n"
                "- ì‘ë‹µ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì„¤ëª… ìƒì„± ë¶ˆê°€"
            )
        if normalized_mode == "no_match":
            return (
                "ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë„ë©´ ì´ ê°œìˆ˜: 0\n"
                "ê²€ìƒ‰ëœ ë„ë©´ id: ì—†ìŒ\n"
                "ìš”ì²­ ì¡°ê±´ê³¼ ì¼ì¹˜í•˜ëŠ” ë„ë©´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
        raise ValueError(f"Unsupported validation mode: {mode}")

    def _run_validated_generation(
        self,
        mode: str,
        generate_fn: Callable[[], str],
        expected_document_id: Optional[str] = None,
    ) -> str:
        try:
            answer = generate_fn()
        except Exception:
            self.logger.exception("answer_generation_exception mode=%s attempt=0", mode)
            if self.answer_validation_safe_fallback:
                fallback = self._build_safe_default_answer(
                    mode=mode,
                    expected_document_id=expected_document_id,
                )
                self.logger.warning(
                    "answer_validation_fallback mode=%s retries=%d reason=generation_error",
                    mode,
                    self.answer_validation_retry_max,
                )
                return fallback
            raise
        if not self.answer_validation_enabled:
            return answer

        validation_start = time.perf_counter()
        try:
            result = self._validate_answer_format(
                answer=answer,
                mode=mode,
                expected_document_id=expected_document_id,
            )
        except Exception:
            self.logger.exception("answer_validation_exception mode=%s attempt=0", mode)
            return answer
        validation_ms = int((time.perf_counter() - validation_start) * 1000)

        if result.ok:
            self.logger.info(
                "answer_validation_pass mode=%s attempt=0 latency_ms=%d",
                mode,
                validation_ms,
            )
            return answer

        self.logger.warning(
            "answer_validation_fail mode=%s attempt=0 missing_fields=%s latency_ms=%d",
            mode,
            ",".join(result.missing_fields) or "none",
            validation_ms,
        )

        last_answer = answer
        for attempt in range(1, self.answer_validation_retry_max + 1):
            self.logger.warning("answer_validation_retry mode=%s attempt=%d", mode, attempt)
            try:
                last_answer = generate_fn()
            except Exception:
                self.logger.exception("answer_generation_exception mode=%s attempt=%d", mode, attempt)
                continue
            retry_validation_start = time.perf_counter()
            try:
                retry_result = self._validate_answer_format(
                    answer=last_answer,
                    mode=mode,
                    expected_document_id=expected_document_id,
                )
            except Exception:
                self.logger.exception(
                    "answer_validation_exception mode=%s attempt=%d", mode, attempt
                )
                continue
            retry_validation_ms = int((time.perf_counter() - retry_validation_start) * 1000)
            if retry_result.ok:
                self.logger.info(
                    "answer_validation_pass mode=%s attempt=%d latency_ms=%d",
                    mode,
                    attempt,
                    retry_validation_ms,
                )
                return last_answer
            self.logger.warning(
                "answer_validation_fail mode=%s attempt=%d missing_fields=%s latency_ms=%d",
                mode,
                attempt,
                ",".join(retry_result.missing_fields) or "none",
                retry_validation_ms,
            )

        if self.answer_validation_safe_fallback:
            fallback = self._build_safe_default_answer(
                mode=mode,
                expected_document_id=expected_document_id,
            )
            self.logger.warning(
                "answer_validation_fallback mode=%s retries=%d",
                mode,
                self.answer_validation_retry_max,
            )
            return fallback
        return last_answer

    def _normalize_hybrid_weights(
        self, vector_weight: float, text_weight: float
    ) -> tuple[float, float]:
        vector = float(vector_weight)
        text = float(text_weight)
        if vector < 0 or text < 0:
            raise ValueError("vector_weight and text_weight must be non-negative.")
        total = vector + text
        if total == 0:
            raise ValueError("At least one hybrid weight must be greater than zero.")
        return vector / total, text / total

    def _analyze_query(self, query: str) -> dict:
        """ 
        LLM: query -> JSON (filters, documents)
        """
        word_rules_text = json.dumps(self.word_dict, ensure_ascii=False, indent=2)
        system_prompt = (
            "You are a query analyzer for architectural floorplan retrieval.\n"
            "Return ONLY valid JSON in this exact schema:\n"
            "{\n"
            '  "filters": {\n'
            '    "windowless_ratio": {"op": "ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼", "val": "number"} (optional),\n'
            '    "balcony_ratio": {"op": "ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼", "val": "number"} (optional),\n'
            '    "living_room_ratio": {"op": "ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼", "val": "number"} (optional),\n'
            '    "bathroom_ratio": {"op": "ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼", "val": "number"} (optional),\n'
            '    "kitchen_ratio": {"op": "ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼", "val": "number"} (optional),\n'
            '    "structure_type": "string(optional)",\n'
            '    "bay_count": "integer(optional)",\n'
            '    "room_count": "integer(optional)",\n'
            '    "bathroom_count": "integer(optional)",\n'
            '    "compliance_grade": "string(optional)",\n'
            '    "ventilation_grade": "string(optional)",\n'
            '    "has_special_space": "boolean(optional)",\n'
            '    "has_etc_space": "boolean(optional)"\n'
            "  },\n"
            '  "documents": "string(required)"\n'
            "}\n"
            "Map explicit, structured constraints to filters.\n"
            "Put abstract or descriptive intent into documents.\n"
            "If no filter applies, use an empty filters object.\n"
            "Synonym and classification rules (JSON):\n"
            f"{word_rules_text}\n"
            "Prompt rules:\n"
            "1) Normalization Rule: When interpreting the user's query, map terms to standardized space names using normalization_rules.\n"
            "2) Etc. Space Classification: If a mapped/mentioned space is in special_classification['ê¸°íƒ€ê³µê°„'] "
            "(or equivalent category_groups['ê¸°íƒ€ê³µê°„']), include \"has_etc_space\": true in filters.\n"
            "3) Special Space Classification: If a mapped/mentioned space is in special_classification['íŠ¹í™”ê³µê°„'] "
            "(or equivalent category_groups['íŠ¹í™”ê³µê°„']), include \"has_special_space\": true in filters.\n"
            "Only include these boolean fields when the condition is met."
        )

        try:
            response = self.client.chat.completions.create(
                model="gpt-5.2-2025-12-11",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query},
                ],
                temperature=0.0,
                response_format={"type": "json_object"},
            )
            raw_text = (response.choices[0].message.content or "").strip()
            if not raw_text:
                raise ValueError("Analyzer returned empty content")

            cleaned = raw_text.replace("```json", "").replace("```", "").strip()
            start = cleaned.find("{")
            end = cleaned.rfind("}")
            if start == -1 or end == -1 or start > end:
                raise ValueError("Analyzer JSON object not found")
            parsed = json.loads(cleaned[start : end + 1])

            raw_filters = parsed.get("filters", {})
            if not isinstance(raw_filters, dict):
                raise ValueError("Invalid analyzer JSON schema")

            documents = (
                parsed.get("documents")
                or parsed.get("search_text")
                or parsed.get("context")
                or query
            )
            documents = str(documents).strip()
            if not documents:
                documents = query

            filters = self._normalize_filters(raw_filters)
            filters = self._augment_filters_from_query(query, filters)
            filters = self._drop_implicit_ratio_filters(query, filters)
            return {"filters": filters, "documents": documents, "raw_query": query}
        except (json.JSONDecodeError, ValueError, KeyError, TypeError, IndexError):
            self.logger.warning(
                "Analyzer JSON parsing failed. Falling back to keyword-only search."
            )
            return {"filters": {}, "documents": query, "raw_query": query}

    def _normalize_filters(self, raw_filters: dict[str, Any]) -> dict[str, Any]:
        normalized: dict[str, Any] = {}
        for key, value in raw_filters.items():
            canonical_key = self.FILTER_ALIASES.get(key, key)
            if canonical_key not in self.ALLOWED_FILTER_COLUMNS:
                continue
            coerced = self._coerce_filter_value(canonical_key, value)
            if coerced is not None:
                normalized[canonical_key] = coerced

        for ratio_key in self.FLOAT_FILTERS:
            if ratio_key in normalized:
                continue
            op = raw_filters.get(f"{ratio_key}_op", raw_filters.get(f"{ratio_key}_operator"))
            val = raw_filters.get(f"{ratio_key}_val", raw_filters.get(f"{ratio_key}_value"))
            if op is None and val is None:
                continue
            coerced = self._coerce_filter_value(ratio_key, {"op": op, "val": val})
            if coerced is not None:
                normalized[ratio_key] = coerced
        return normalized

    def _coerce_filter_value(self, key: str, value: Any) -> Any:
        if value is None:
            return None

        if key in self.INT_FILTERS:
            if isinstance(value, bool):
                return None
            if isinstance(value, (int, float)):
                return int(value)
            if isinstance(value, str):
                match = re.search(r"-?\d+", value)
                if match:
                    return int(match.group())
            return None

        if key in self.FLOAT_FILTERS:
            ratio_filter = self._coerce_ratio_filter(value)
            if ratio_filter is not None:
                return ratio_filter
            return None

        if key in self.BOOL_FILTERS:
            if isinstance(value, bool):
                return value
            if isinstance(value, str):
                v = value.strip().lower()
                if v in {"true", "1", "yes"}:
                    return True
                if v in {"false", "0", "no"}:
                    return False
            return None

        if isinstance(value, str):
            cleaned = value.strip()
            return cleaned if cleaned else None
        return str(value)

    def _coerce_ratio_filter(self, value: Any) -> Optional[dict[str, Any]]:
        if value is None or isinstance(value, bool):
            return None

        if isinstance(value, (int, float)):
            return {"op": "ë™ì¼", "val": float(value)}

        if isinstance(value, str):
            text = value.strip()
            if not text:
                return None
            op_match = re.search(r"(ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼)", text)
            num_match = re.search(r"-?\d+(\.\d+)?", text)
            if num_match:
                op = self._normalize_ratio_operator(op_match.group(1) if op_match else None)
                return {"op": op or "ë™ì¼", "val": float(num_match.group())}
            return None

        if isinstance(value, dict):
            raw_op = value.get("op", value.get("operator"))
            raw_val = value.get("val", value.get("value"))
            val = self._parse_float(raw_val)
            op = self._normalize_ratio_operator(raw_op)
            if raw_op is None and val is None:
                return None
            return {"op": op, "val": val}

        return None

    def _normalize_ratio_operator(self, op: Any) -> Optional[str]:
        if not isinstance(op, str):
            return None
        cleaned = op.strip()
        return cleaned if cleaned in self.VALID_RATIO_OPERATORS else None

    def _parse_float(self, value: Any) -> Optional[float]:
        if value is None or isinstance(value, bool):
            return None
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            match = re.search(r"-?\d+(\.\d+)?", value)
            if match:
                return float(match.group())
        return None

    def _ensure_ratio_cmp_function(self) -> None:
        sql = """
        CREATE OR REPLACE FUNCTION public.ratio_cmp(
            field_val double precision,
            op text,
            val double precision
        ) RETURNS boolean
        LANGUAGE sql
        IMMUTABLE
        AS $$
        SELECT CASE
            WHEN op IS NULL OR val IS NULL THEN TRUE
            WHEN op = 'ì´ìƒ' THEN field_val >= val
            WHEN op = 'ì´í•˜' THEN field_val <= val
            WHEN op = 'ì´ˆê³¼' THEN field_val > val
            WHEN op = 'ë¯¸ë§Œ' THEN field_val < val
            WHEN op = 'ë™ì¼' THEN field_val = val
            ELSE TRUE
        END
        $$;
        """
        try:
            with self.conn.cursor() as cur:
                cur.execute(sql)
            self.conn.commit()
        except Exception:
            self.conn.rollback()
            self.logger.exception("Failed to create ratio_cmp function.")

    def _augment_filters_from_query(
        self, query: str, filters: dict[str, Any]
    ) -> dict[str, Any]:
        augmented = dict(filters)

        if "structure_type" not in augmented:
            if "íŒìƒí˜•" in query:
                augmented["structure_type"] = "íŒìƒí˜•"
            elif "íƒ€ì›Œí˜•" in query:
                augmented["structure_type"] = "íƒ€ì›Œí˜•"
            elif "ë³µë„í˜•" in query:
                augmented["structure_type"] = "ë³µë„í˜•"

        if "bay_count" not in augmented:
            match = re.search(r"(\d+)\s*ë² ì´", query)
            if match:
                augmented["bay_count"] = int(match.group(1))

        if "room_count" not in augmented:
            match = re.search(r"ë°©\s*(\d+)\s*ê°œ", query) or re.search(
                r"(\d+)\s*ê°œ\s*ë°©", query
            )
            if match:
                augmented["room_count"] = int(match.group(1))

        if "bathroom_count" not in augmented:
            match = re.search(r"(ìš•ì‹¤|í™”ì¥ì‹¤)\s*(\d+)\s*ê°œ", query) or re.search(
                r"(\d+)\s*ê°œ\s*(ìš•ì‹¤|í™”ì¥ì‹¤)", query
            )
            if match:
                numeric = re.search(r"\d+", match.group(0))
                if numeric:
                    augmented["bathroom_count"] = int(numeric.group())

        if "ventilation_grade" not in augmented and "í™˜ê¸°" in query:
            if "ìš°ìˆ˜" in query:
                augmented["ventilation_grade"] = "ìš°ìˆ˜"
            elif "ë³´í†µ" in query:
                augmented["ventilation_grade"] = "ë³´í†µ"
            elif "ë¯¸í¡" in query:
                augmented["ventilation_grade"] = "ë¯¸í¡"

        return augmented

    def _drop_implicit_ratio_filters(
        self, query: str, filters: dict[str, Any]
    ) -> dict[str, Any]:
        
        if re.search(r"(%|í¼ì„¼íŠ¸|ë¹„ìœ¨|ratio|ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ|ë™ì¼)", query, flags=re.IGNORECASE):
            return filters

        sanitized = dict(filters)
        for key in self.FLOAT_FILTERS:
            sanitized.pop(key, None)
        return sanitized

    def _is_floorplan_image_name(self, query: str) -> bool:
        return bool(self.FLOORPLAN_IMAGE_NAME_RE.fullmatch(query.strip()))

    def _extract_document_signals(self, document: str) -> list[dict[str, str]]:
        text = str(document or "")
        if not text.strip():
            return []

        signals: list[dict[str, str]] = []
        for canonical_key, aliases in self.DOCUMENT_SIGNAL_KEY_ALIASES.items():
            match_value: Optional[str] = None
            match_source: Optional[str] = None
            for alias in aliases:
                pattern = rf"{re.escape(alias)}\s*ì€\(ëŠ”\)\s*([^\n.]+)"
                match = re.search(pattern, text, flags=re.IGNORECASE)
                if match:
                    match_value = re.sub(r"\s+", " ", match.group(1)).strip()
                    match_source = re.sub(r"\s+", " ", match.group(0)).strip()
                    break
            if match_value:
                normalized_value = self._normalize_signal_value_for_display(
                    canonical_key, match_value
                )
                signals.append(
                    {
                        "key": canonical_key,
                        "label": self.DOCUMENT_SIGNAL_KR_LABELS[canonical_key],
                        "value": match_value,
                        "display_value": normalized_value,
                        "source": match_source or "",
                    }
                )
        return signals

    def _infer_signal_polarity(self, value: str) -> Optional[str]:
        normalized = re.sub(r"\s+", "", str(value or ""))
        if not normalized:
            return None
        if any(token in normalized for token in self.NEGATIVE_SIGNAL_WORDS):
            return "negative"
        if any(token in normalized for token in self.POSITIVE_SIGNAL_WORDS):
            return "positive"
        return None

    def _normalize_signal_value_for_display(self, key: str, value: str) -> str:
        polarity = self._infer_signal_polarity(value)
        if polarity == "positive":
            return self.SIGNAL_POSITIVE_DISPLAY.get(key, "ì¢‹ìŒ")
        if polarity == "negative":
            return self.SIGNAL_NEGATIVE_DISPLAY.get(key, "ë¶€ì¡±í•¨")
        cleaned = re.sub(r"\s+", " ", str(value or "")).strip()
        return cleaned if cleaned else "í™•ì¸ í•„ìš”"

    def _extract_query_signal_preferences(self, query: str) -> dict[str, str]:
        text = str(query or "")
        if not text.strip():
            return {}

        positive_hint = bool(
            re.search(r"(ì¢‹|ìš°ìˆ˜|ì ì •|ì í•©|ì–‘í˜¸|ì¶©ë¶„|ë„‰ë„‰|ë°)", text, flags=re.IGNORECASE)
        )
        negative_hint = bool(
            re.search(r"(ë‚˜ì˜|ë¶€ì¡±|ë¯¸í¡|ë¶€ì í•©|ë¶ˆí•©ê²©|ì–´ë‘¡|ì—†)", text, flags=re.IGNORECASE)
        )
        if not positive_hint and not negative_hint:
            return {}

        preferred = "positive" if positive_hint and not negative_hint else None
        if negative_hint and not positive_hint:
            preferred = "negative"
        if preferred is None:
            return {}

        preferences: dict[str, str] = {}
        if re.search(r"(ì±„ê´‘|lighting)", text, flags=re.IGNORECASE):
            preferences["lighting"] = preferred
        if re.search(r"(ìˆ˜ë‚©ê³µê°„|ìˆ˜ë‚©|storage)", text, flags=re.IGNORECASE):
            preferences["storage"] = preferred
        if re.search(r"(í™˜ê¸°|ventilation)", text, flags=re.IGNORECASE):
            preferences["ventilation"] = preferred
        if re.search(r"(ê°€ì¡±\s*ìœµí™”|family_harmony)", text, flags=re.IGNORECASE):
            preferences["family_harmony"] = preferred
        return preferences

    def _rerank_by_query_signal_preferences(
        self, docs: list[tuple[Any, ...]], query: str
    ) -> list[tuple[Any, ...]]:
        preferences = self._extract_query_signal_preferences(query)
        if not preferences or not docs:
            return docs

        rescored_docs: list[tuple[float, tuple[Any, ...]]] = []
        for row in docs:
            base_score = float(row[15] if len(row) > 15 and row[15] is not None else 0.0)
            document_text = str(row[1] if len(row) > 1 else "")
            signals = self._extract_document_signals(document_text)
            signal_map = {signal["key"]: signal["value"] for signal in signals}

            bonus = 0.0
            for key, desired in preferences.items():
                value = signal_map.get(key)
                if not value:
                    continue
                polarity = self._infer_signal_polarity(value)
                if polarity == desired:
                    bonus += 0.08
                elif polarity and polarity != desired:
                    bonus -= 0.04

            adjusted_row = (*row[:-1], base_score + bonus) if len(row) > 0 else row
            rescored_docs.append((base_score + bonus, adjusted_row))

        rescored_docs.sort(key=lambda item: item[0], reverse=True)
        return [row for _, row in rescored_docs]

    def _retrieve_by_document_id(self, document_id: str) -> Optional[tuple]:
        sql = """
            SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
            structure_type, bay_count, room_count, bathroom_count,
            compliance_grade, ventilation_grade, has_special_space, has_etc_space,
            1.0::double precision AS similarity
            FROM FP_Analysis
            WHERE LOWER(document_id) = LOWER(%s)
            LIMIT 1
        """
        with self.conn.cursor() as cur:
            cur.execute(sql, (document_id.strip(),))
            return cur.fetchone()

    def _row_to_candidate(self, row: tuple[Any, ...], rank: int) -> dict[str, Any]:
        (
            document_id,
            document,
            windowless_ratio,
            balcony_ratio,
            living_room_ratio,
            bathroom_ratio,
            kitchen_ratio,
            structure_type,
            bay_count,
            room_count,
            bathroom_count,
            compliance_grade,
            ventilation_grade,
            has_special_space,
            has_etc_space,
            similarity,
        ) = row
        return {
            "rank": rank,
            "document_id": document_id,
            "metadata": {
                "room_count": room_count,
                "bathroom_count": bathroom_count,
                "bay_count": bay_count,
                "living_room_ratio": living_room_ratio,
                "kitchen_ratio": kitchen_ratio,
                "bathroom_ratio": bathroom_ratio,
                "balcony_ratio": balcony_ratio,
                "windowless_ratio": windowless_ratio,
                "structure_type": structure_type,
                "ventilation_quality": ventilation_grade,
                "has_special_space": has_special_space,
                "has_etc_space": has_etc_space,
                "compliance_grade": compliance_grade,
            },
            "document": document,
            "document_signals": self._extract_document_signals(document),
            "similarity": similarity,
        }

    def _generate_document_id_answer(self, document_id: str, doc: tuple[Any, ...]) -> str:
        candidate = self._row_to_candidate(doc, rank=1)
        candidate_json = json.dumps(candidate, ensure_ascii=False, indent=2)

        system_prompt = """ You are a **specialized sLLM for architectural floor plan retrieval**.

Your role is to, for each retrieved floor plan:
1. Explain **why this floor plan was selected**,
2. Describe the **metadata of the floor plan in a neutral manner**, and
3. Summarize each floor planâ€™s **document content clearly and concisely**, without interpretation.

You must **never perform judgment, evaluation, recommendation, or interpretation**.

**Absolute Prohibitions**
- Do not judge the suitability, quality, or problems of the floor plan.
- Do not provide design advice or suggestions for improvement.
- Do not interpret legal regulations or permit/approval feasibility.
- Do not repeat evaluation results already present in the metadata within the document summary.

========================
Output Format (Must Be Preserved, Repeated for Each Floor Plan)
- All content must be written in Korean.
========================


1. ê²€ìƒ‰ëœ ë„ë©´ id: {document_id}

2. ë„ë©´ ê¸°ë³¸ ì •ë³´ ìš”ì•½ ğŸ“Š
2-4. ê³µê°„ êµ¬ì„± ì—¬ë¶€ì˜ ê°’ì€ ë‹¤ìŒ í‘œí˜„ìœ¼ë¡œ ê³ ì •í•œë‹¤.
- true â†’ ì¡´ì¬
- false â†’ ì—†ìŒ

ì¶œë ¥ í˜•ì‹(ê³ ì •):
2-1. ê³µê°„ ê°œìˆ˜
    - ë°© ê°œìˆ˜: {room_count}
    - í™”ì¥ì‹¤ ê°œìˆ˜: {bathroom_count}
    - Bay ê°œìˆ˜: {bay_count}
2-2. ì „ì²´ ë©´ì  ëŒ€ë¹„ ê³µê°„ ë¹„ìœ¨ (%)
    - ê±°ì‹¤ ê³µê°„: {living_room_ratio}
    - ì£¼ë°© ê³µê°„: {kitchen_ratio}
    - ìš•ì‹¤ ê³µê°„: {bathroom_ratio}
    - ë°œì½”ë‹ˆ ê³µê°„: {balcony_ratio}
    - ì°½ë¬¸ì´ ì—†ëŠ” ê³µê°„: {windowless_ratio}
2-3. êµ¬ì¡° ë° ì„±ëŠ¥
    - ê±´ë¬¼ êµ¬ì¡° ìœ í˜•: {structure_type}
    - í™˜ê¸°: {ventilation_quality}
2-4. ê³µê°„ êµ¬ì„± ì—¬ë¶€
    - íŠ¹í™” ê³µê°„: {has_special_space}
    - ê¸°íƒ€ ê³µê°„: {has_etc_space}
2-5. ì¢…í•© í‰ê°€
    - í‰ê°€ ê²°ê³¼: {compliance_grade}

3. ë„ë©´ ê³µê°„ êµ¬ì„± ì„¤ëª… ğŸ§©
Since the document is **internal evaluation text**,
it must be restructured into a form that is easy for users to read according to the rules below.

**Organization Rules:**
* Use **only factual information** contained in the original text.
* Remove document-meta expressions such as *â€œis stated,â€ â€œis mentioned,â€* or *â€œis described.â€*
* Remove **only** result-oriented judgment expressions such as internal criteria, suitability determinations, or pass/fail statements.
* Sentences that describe a **state or condition**, such as *â€œinsufficientâ€* or *â€œimprovement is needed,â€* are considered factual descriptions and are **allowed**.
* Merge sentences with the same meaning into one.
* Sentences may be rephrased into natural English **without changing their meaning**.
* Do **not** include advice, criteria comparisons, or design suggestions.
* If the original document contains content related to the following items, that content **must be included in the overall summary sentence*.
  â€¢ storage -> ìˆ˜ë‚©ê³µê°„
  â€¢ lighting -> ì±„ê´‘
  â€¢ family_harmony -> ê°€ì¡± ìœµí™”
* If `document_signals` are provided, all of them must be included in the first overall summary sentence using Korean labels and values.
* Do not drop value polarity. Keep positive/negative wording from `document_signals` (e.g., ìš°ìˆ˜, ì ì •, ë¶€ì¡±, ë¯¸í¡, ë¶€ì í•©, ë¶ˆí•©ê²©).
* Prefer `display_value` for user-facing wording (e.g., ì±„ê´‘: ì¢‹ìŒ, ìˆ˜ë‚©ê³µê°„: ë„‰ë„‰í•¨).
* The first summary sentence must follow this fixed style:
  ë„ë©´ì€ {bay_count}Bay {structure_type} êµ¬ì¡°ì´ë©°, ì±„ê´‘: {display_value}({ê·¼ê±°}), í™˜ê¸°: {display_value}({ê·¼ê±°}), ê°€ì¡± ìœµí™”: {display_value}({ê·¼ê±°}), ìˆ˜ë‚©ê³µê°„: {display_value}({ê·¼ê±°})ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤.
* In each parentheses, write only concise evidence text (e.g., ì•ˆë°© ì™¸ê¸°ì°½ ë¯¸í™•ë³´). Do not include prefixes like "ì í•©:" or "ë¶€ì í•©:".
* Do not repeat the same fact twice. If the same evidence appears in the summary sentence, do not repeat it in later sentences.
* The second summary sentence should include only additional non-duplicate facts that are not already stated in the first summary sentence.

**Output Format:**
* Overall summary: 1â€“2 sentences (describing overall spatial characteristics only)
* Followed by space-by-space descriptions
* One sentence per space

ì¶œë ¥ ì˜ˆì‹œ í˜•ì‹:
ë„ë©´ì€ 3Bay íŒìƒí˜• êµ¬ì¡°ì´ë©°, ì±„ê´‘: ë¶€ì¡±í•¨(ì•ˆë°© ì™¸ê¸°ì°½ ë¯¸í™•ë³´), í™˜ê¸°: ì¢‹ìŒ(ì£¼ë°© í™˜ê¸°ì°½ í™•ë³´), ê°€ì¡± ìœµí™”: ì í•©(ê±°ì‹¤ ì¤‘ì‹¬ ë°°ì¹˜), ìˆ˜ë‚©ê³µê°„: ë¶€ì¡±í•¨(ìˆ˜ë‚©ê³µê°„ ë¹„ìœ¨ 10% ë¯¸ë§Œ)ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤.
ì•ˆë°© ì™¸ê¸°ì°½ì´ ì—†ê³ , ìš•ì‹¤ í™˜ê¸°ì°½ì´ ì—†ìŠµë‹ˆë‹¤.
â–  ê±°ì‹¤: ì¤‘ì•™ì— ìœ„ì¹˜í•˜ì—¬ ê°€ì¡±ì´ ëª¨ì¼ ìˆ˜ ìˆëŠ” ê³µê°„ìœ¼ë¡œ ì í•©í•©ë‹ˆë‹¤.
â–  ì¹¨ì‹¤: ê°œì¸ì ì¸ ê³µê°„ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ì ì ˆí•˜ê²Œ ë°°ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
â–  ì£¼ë°©/ì‹ë‹¹: í™˜ê¸°ì°½ì´ ìˆì–´ í™˜ê¸°ê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤.
â–  í™”ì¥ì‹¤: í™˜ê¸°ì°½ì´ ì—†ì–´ í™˜ê¸° ì¸¡ë©´ì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.
â–  ë°œì½”ë‹ˆ: ì™¸ë¶€ ê³µê°„ìœ¼ë¡œì˜ í™œìš©ë„ê°€ ë†’ìŠµë‹ˆë‹¤.
"""

        user_content = (
            f"ì…ë ¥ document_id:\n{document_id.strip()}\n\n"
            f"ë„ë©´ ë°ì´í„°(JSON):\n{candidate_json}\n\n"
            "JSONì˜ `document_signals` í•­ëª©ì€ 3ë²ˆì˜ ì „ì²´ ìš”ì•½ ë¬¸ì¥ì— ë°˜ë“œì‹œ ëª¨ë‘ ë°˜ì˜í•˜ì„¸ìš”.\n"
            "ì‹ í˜¸ ê°’ì€ `display_value`ë¥¼ ìš°ì„  ì‚¬ìš©í•´ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.\n"
            "ì²« ë¬¸ì¥ì€ `ì±„ê´‘: ê°’(ê·¼ê±°)` í˜•ì‹ì„ í¬í•¨í•œ ê³ ì • í…œí”Œë¦¿ì„ ë”°ë¥´ì„¸ìš”.\n"
            "ì²« ë¬¸ì¥ì—ì„œ ì–¸ê¸‰í•œ ê·¼ê±°ëŠ” ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì¤‘ë³µí•´ì„œ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.\n"
            "ì¶œë ¥ì€ ë°˜ë“œì‹œ 1, 2, 3ë²ˆ ì„¹ì…˜ë§Œ í¬í•¨í•˜ê³  ì¶”ê°€ ë¬¸ì¥ì„ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "ë°˜ë“œì‹œ ë‹¨ì¼ ë„ë©´ ê¸°ì¤€ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ê³ , "
            f"ì²« ì¤„ì€ ì •í™•íˆ `1. ê²€ìƒ‰ëœ ë„ë©´ id: {document_id.strip()}` í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”."
        )

        def _call_llm() -> str:
            response = self.client.chat.completions.create(
                model="gpt-5.2-2025-12-11",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.0,
            )
            return (response.choices[0].message.content or "").strip()

        return self._run_validated_generation(
            mode="document_id",
            generate_fn=_call_llm,
            expected_document_id=document_id.strip(),
        )

    def _build_filter_where_parts(self, filters: dict[str, Any]) -> tuple[str, list[Any]]:
        where_clauses = []
        params: list[Any] = []

        for column in self.ALLOWED_FILTER_COLUMNS:
            value = filters.get(column)
            if value is None:
                continue
            if column in self.FLOAT_FILTERS:
                op = value.get("op") if isinstance(value, dict) else None
                val = value.get("val") if isinstance(value, dict) else None
                where_clauses.append(f"ratio_cmp({column}::double precision, %s, %s)")
                params.extend([op, val])
            else:
                where_clauses.append(f"{column} = %s")
                params.append(value)

        where_sql = " AND ".join(where_clauses) if where_clauses else "TRUE"
        return where_sql, params

    def _retrieve_hybrid(self, query_json: dict, top_k: int = 50) -> list:
        """
        Generate embedding -> build query -> execute DB query -> return results
        """
        filters = query_json.get("filters", {}) or {}
        documents = query_json.get("documents", "") or ""
        raw_query = query_json.get("raw_query", "") or ""
        semantic_query = f"{documents} {raw_query}".strip() or raw_query or documents
        text_query = str(documents).strip() or str(raw_query).strip()

        embedding_resp = self.client.embeddings.create(
            model=self.embedding_model,
            input=semantic_query,
            dimensions=self.embedding_dimensions,
        )
        embedding = embedding_resp.data[0].embedding
        embedding_vector = "[" + ",".join(map(str, embedding)) + "]"

        where_sql, filter_params = self._build_filter_where_parts(filters)
        params = [
            embedding_vector,
            text_query,
            *filter_params,
            self.vector_weight,
            self.text_weight,
            top_k,
        ]

        sql = f"""
            WITH scored AS (
                SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
                structure_type, bay_count, room_count, bathroom_count,
                compliance_grade, ventilation_grade, has_special_space, has_etc_space,
                (1 - (embedding <=> %s::vector)) AS vector_similarity,
                ts_rank_cd(
                    to_tsvector('simple', COALESCE(document, '')),
                    websearch_to_tsquery('simple', %s)
                ) AS text_score
                FROM FP_Analysis
                WHERE {where_sql}
            )
            SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
            structure_type, bay_count, room_count, bathroom_count,
            compliance_grade, ventilation_grade, has_special_space, has_etc_space,
            (%s * vector_similarity + %s * text_score) AS similarity
            FROM scored
            ORDER BY similarity DESC
            LIMIT %s
        """

        try:
            with self.conn.cursor() as cur:
                cur.execute(sql, params)
                return cur.fetchall()
        except Exception as exc:
            if text_query:
                self._log_event(
                    event="retrieve_text_query_fallback",
                    level=logging.WARNING,
                    reason="text_query_parse_or_rank_error",
                    text_query=text_query,
                    filter_count=len(filter_params),
                    error=str(exc),
                )
                fallback_params = [
                    embedding_vector,
                    *filter_params,
                    self.vector_weight,
                    self.text_weight,
                    top_k,
                ]
                fallback_sql = f"""
                    WITH scored AS (
                        SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
                        structure_type, bay_count, room_count, bathroom_count,
                        compliance_grade, ventilation_grade, has_special_space, has_etc_space,
                        (1 - (embedding <=> %s::vector)) AS vector_similarity,
                        0.0::double precision AS text_score
                        FROM FP_Analysis
                        WHERE {where_sql}
                    )
                    SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
                    structure_type, bay_count, room_count, bathroom_count,
                    compliance_grade, ventilation_grade, has_special_space, has_etc_space,
                    (%s * vector_similarity + %s * text_score) AS similarity
                    FROM scored
                    ORDER BY similarity DESC
                    LIMIT %s
                """
                with self.conn.cursor() as cur:
                    cur.execute(fallback_sql, fallback_params)
                    return cur.fetchall()
            raise

    def _count_matches(self, filters: dict[str, Any], documents: str = "") -> int:
        where_sql, params = self._build_filter_where_parts(filters)

        normalized_documents = str(documents or "").strip()
        if normalized_documents:
            where_sql = (
                f"{where_sql} AND "
                "to_tsvector('simple', COALESCE(document, '')) @@ websearch_to_tsquery('simple', %s)"
            )
            params = [*params, normalized_documents]
        sql = f"SELECT COUNT(*) FROM FP_Analysis WHERE {where_sql}"
        try:
            with self.conn.cursor() as cur:
                cur.execute(sql, params)
                return int(cur.fetchone()[0])
        except Exception as exc:
            # If tsquery parsing fails for malformed text, fall back to filter-only count.
            if normalized_documents:
                self._log_event(
                    event="count_matches_text_query_fallback",
                    level=logging.WARNING,
                    reason="text_query_parse_error",
                    text_query=normalized_documents,
                    error=str(exc),
                )
                fallback_where_sql, fallback_params = self._build_filter_where_parts(filters)
                fallback_sql = f"SELECT COUNT(*) FROM FP_Analysis WHERE {fallback_where_sql}"
                with self.conn.cursor() as cur:
                    cur.execute(fallback_sql, fallback_params)
                    return int(cur.fetchone()[0])
            raise

    def _generate_answer(
        self, query: str, query_json: dict, docs: list, total_match_count: int
    ) -> str:
        """
        Format retrieved docs as documents and send to the LLM to generate the answer
        """
        if not docs:
            return self._generate_validated_no_match_answer(
                total_match_count=total_match_count
            )

        filters_json = json.dumps(query_json.get("filters", {}), ensure_ascii=False, indent=2)
        retrieved_ids = [row[0] for row in docs]
        id_list_text = ", ".join(retrieved_ids)
        top_docs = docs[:3]

        representative_ids = [row[0] for row in top_docs]
        representative_title = "ëŒ€í‘œ ë„ë©´ id(ìƒìœ„ 3ê°œ)"
        candidates = [self._row_to_candidate(row, rank) for rank, row in enumerate(top_docs, start=1)]
        candidates_json = json.dumps(candidates, ensure_ascii=False, indent=2)

        system_prompt = """You are a **specialized sLLM for architectural floor plan retrieval**.

Your role is to, for each retrieved floor plan:

1. Explain **why this floor plan was selected**,
2. Describe the **metadata of the floor plan in a neutral manner**, and
3. Summarize each floor planâ€™s **document content clearly and concisely**, without interpretation.

You must **never perform judgment, evaluation, recommendation, or interpretation**.

**Absolute Prohibitions**
- Do not judge the suitability, quality, or problems of the floor plan.
- Do not provide design advice or suggestions for improvement.
- Do not interpret legal regulations or permit/approval feasibility.
- Do not repeat evaluation results already present in the metadata within the document summary.

========================
Output Format (Must Be Preserved, Repeated for Each Floor Plan)
- All content must be written in Korean.
========================


ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë„ë©´ ì´ ê°œìˆ˜: {total_count}
ê²€ìƒ‰ëœ ë„ë©´ id: {id_list}

Repeat the format below **for each representative floor plan**.
[ë„ë©´ #{rank}] {document_id}

1. ë„ë©´ ì„ íƒ ê·¼ê±° ğŸ”
This section outputs **only the correspondence between the userâ€™s search conditions and the floor plan information**.

**[General Rules]**
* All item labels must be written in **Korean**.
* **Internal field names** (e.g., `bay_count`) must **never** be output.
* Do **not** abbreviate or summarize values.
* Do **not** use meta expressions such as â€œrequest,â€ â€œpreference,â€ or â€œtreated as a condition.â€
* Do **not** generate any additional explanatory sentences.

**[Rules for Writing â€œSearch Conditionsâ€]**
* â€œSearch Conditionsâ€ must list the userâ€™s input query, refined while preserving its original meaning.
* Conditions that are not explicitly stated in the userâ€™s query must **never** be added to â€œSearch Conditions.â€

**[Rules for Generating â€œMatched Conditionsâ€]**
* â€œMatched Conditionsâ€ must include each user-specified condition that satisfies **at least one** of the following:
  1. It can be directly verified from the floor plan metadata.
  2. An identical or semantically equivalent expression is explicitly stated in the document description.
* Conditions supported by the document may be included **even if no corresponding metadata field exists**.

* Examples of **document-based conditions**:
  â€¢ "ë°œì½”ë‹ˆ í™œìš© ê°€ëŠ¥" â†” "ì™¸ë¶€ ê³µê°„ìœ¼ë¡œ í™œìš©", "í™œìš©ë„ê°€ ë†’ìŒ"
  â€¢ "ì£¼ë°© í™˜ê¸°ì°½ ì¡´ì¬" â†” "ì£¼ë°©/ì‹ë‹¹ì— í™˜ê¸°ì°½ì´ ìˆìŒ"

ì¶œë ¥ í˜•ì‹(ê³ ì •):
- ì°¾ëŠ” ì¡°ê±´: {ì‚¬ìš©ì ì¡°ê±´ì„ í•œêµ­ì–´ í‘œí˜„ìœ¼ë¡œ ë‚˜ì—´}
- ì¼ì¹˜ ì¡°ê±´: {ë„ë©´ ë©”íƒ€ë°ì´í„° ë° documentì—ì„œ í™•ì¸ëœ ì¼ì¹˜ í•­ëª©ì„ í•œêµ­ì–´ í•­ëª©ëª…=ê°’ í˜•íƒœë¡œ ë‚˜ì—´}

2. ë„ë©´ ê¸°ë³¸ ì •ë³´ ìš”ì•½ ğŸ“Š
2-4. ê³µê°„ êµ¬ì„± ì—¬ë¶€ì˜ ê°’ì€ ë‹¤ìŒ í‘œí˜„ìœ¼ë¡œ ê³ ì •í•œë‹¤.
- true â†’ ì¡´ì¬
- false â†’ ì—†ìŒ

ì¶œë ¥ í˜•ì‹(ê³ ì •):
2-1. ê³µê°„ ê°œìˆ˜
    - ë°© ê°œìˆ˜: {room_count}
    - í™”ì¥ì‹¤ ê°œìˆ˜: {bathroom_count}
    - Bay ê°œìˆ˜: {bay_count}
2-2. ì „ì²´ ë©´ì  ëŒ€ë¹„ ê³µê°„ ë¹„ìœ¨ (%)
    - ê±°ì‹¤ ê³µê°„: {living_room_ratio}
    - ì£¼ë°© ê³µê°„: {kitchen_ratio}
    - ìš•ì‹¤ ê³µê°„: {bathroom_ratio}
    - ë°œì½”ë‹ˆ ê³µê°„: {balcony_ratio}
    - ì°½ë¬¸ì´ ì—†ëŠ” ê³µê°„: {windowless_ratio}
2.3. êµ¬ì¡° ë° ì„±ëŠ¥
    - ê±´ë¬¼ êµ¬ì¡° ìœ í˜•: {structure_type}
    - í™˜ê¸°: {ventilation_quality}
2-4. ê³µê°„ êµ¬ì„± ì—¬ë¶€
    - íŠ¹í™” ê³µê°„: {has_special_space}
    - ê¸°íƒ€ ê³µê°„: {has_etc_space}
2-5. ì¢…í•© í‰ê°€
    - í‰ê°€ ê²°ê³¼: {compliance_grade}

3. ë„ë©´ ê³µê°„ êµ¬ì„± ì„¤ëª… ğŸ§©
Since the document is **internal evaluation text**,
it must be restructured into a form that is easy for users to read according to the rules below.

**Organization Rules:**
* Use **only factual information** contained in the original text.
* Remove document-meta expressions such as *â€œis stated,â€ â€œis mentioned,â€* or *â€œis described.â€*
* Remove **only** result-oriented judgment expressions such as internal criteria, suitability determinations, or pass/fail statements.
* Sentences that describe a **state or condition**, such as *â€œinsufficientâ€* or *â€œimprovement is needed,â€* are considered factual descriptions and are **allowed**.
* Merge sentences with the same meaning into one.
* Sentences may be rephrased into natural English **without changing their meaning**.
* Do **not** include advice, criteria comparisons, or design suggestions.
* If the original document contains content related to the following items, that content **must be included in the overall summary sentence*.
  â€¢ storage -> ìˆ˜ë‚©ê³µê°„
  â€¢ lighting -> ì±„ê´‘
  â€¢ family_harmony -> ê°€ì¡± ìœµí™”
* If `document_signals` exist for each floor plan, include all of them in the first overall summary sentence for that floor plan.
* Do not drop value polarity. Keep positive/negative wording from `document_signals` (e.g., ìš°ìˆ˜, ì ì •, ë¶€ì¡±, ë¯¸í¡, ë¶€ì í•©, ë¶ˆí•©ê²©).
* Prefer `display_value` for user-facing wording (e.g., ì±„ê´‘: ì¢‹ìŒ, ìˆ˜ë‚©ê³µê°„: ë„‰ë„‰í•¨).
* The first summary sentence must follow this fixed style:
  ë„ë©´ì€ {bay_count}Bay {structure_type} êµ¬ì¡°ì´ë©°, ì±„ê´‘: {display_value}({ê·¼ê±°}), í™˜ê¸°: {display_value}({ê·¼ê±°}), ê°€ì¡± ìœµí™”: {display_value}({ê·¼ê±°}), ìˆ˜ë‚©ê³µê°„: {display_value}({ê·¼ê±°})ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤.
* In each parentheses, write only concise evidence text (e.g., ì•ˆë°© ì™¸ê¸°ì°½ ë¯¸í™•ë³´). Do not include prefixes like "ì í•©:" or "ë¶€ì í•©:".
* Do not repeat the same fact twice. If the same evidence appears in the summary sentence, do not repeat it in later sentences.
* The second summary sentence should include only additional non-duplicate facts that are not already stated in the first summary sentence.

**Output Format:**
* Overall summary: 1â€“2 sentences (describing overall spatial characteristics only)
* Followed by space-by-space descriptions
* One sentence per space

ì¶œë ¥ ì˜ˆì‹œ í˜•ì‹:
ë„ë©´ì€ 3Bay íŒìƒí˜• êµ¬ì¡°ì´ë©°, ì±„ê´‘: ë¶€ì¡±í•¨(ì•ˆë°© ì™¸ê¸°ì°½ ë¯¸í™•ë³´), í™˜ê¸°: ì¢‹ìŒ(ì£¼ë°© í™˜ê¸°ì°½ í™•ë³´), ê°€ì¡± ìœµí™”: ì í•©(ê±°ì‹¤ ì¤‘ì‹¬ ë°°ì¹˜), ìˆ˜ë‚©ê³µê°„: ë¶€ì¡±í•¨(ìˆ˜ë‚©ê³µê°„ ë¹„ìœ¨ 10% ë¯¸ë§Œ)ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤.
ì•ˆë°© ì™¸ê¸°ì°½ì´ ì—†ê³ , ìš•ì‹¤ í™˜ê¸°ì°½ì´ ì—†ìŠµë‹ˆë‹¤.
â–  ê±°ì‹¤: ì¤‘ì•™ì— ìœ„ì¹˜í•˜ì—¬ ê°€ì¡±ì´ ëª¨ì¼ ìˆ˜ ìˆëŠ” ê³µê°„ìœ¼ë¡œ ì í•©í•©ë‹ˆë‹¤.
â–  ì¹¨ì‹¤: ê°œì¸ì ì¸ ê³µê°„ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ì ì ˆí•˜ê²Œ ë°°ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
â–  ì£¼ë°©/ì‹ë‹¹: í™˜ê¸°ì°½ì´ ìˆì–´ í™˜ê¸°ê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤.
â–  í™”ì¥ì‹¤: í™˜ê¸°ì°½ì´ ì—†ì–´ í™˜ê¸° ì¸¡ë©´ì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. 
â–  ë°œì½”ë‹ˆ: ì™¸ë¶€ ê³µê°„ìœ¼ë¡œì˜ í™œìš©ë„ê°€ ë†’ìŠµë‹ˆë‹¤.
"""

        user_content = (
            f"ê²€ìƒ‰ëœ ë„ë©´ id(ì¡°íšŒ ê²°ê³¼ ëª©ë¡):\n{id_list_text}\n\n"
            f"{representative_title}:\n{', '.join(representative_ids)}\n\n"
            f"ì¡°ê±´ ì¼ì¹˜ ì „ì²´ ê±´ìˆ˜(total_count):\n{total_match_count}\n\n"
            f"ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê²€ìƒ‰ ì¡°ê±´:\n{filters_json}\n\n"
            f"ëŒ€í‘œ ë„ë©´ ë°ì´í„°(ìˆœìœ„/ë©”íƒ€ë°ì´í„°/document/similarity):\n{candidates_json}\n\n"
            "ê° ë„ë©´ì˜ `document_signals`ëŠ” 3ë²ˆì˜ ì „ì²´ ìš”ì•½ ë¬¸ì¥ì— ë°˜ë“œì‹œ ëª¨ë‘ ë°˜ì˜í•˜ì„¸ìš”.\n\n"
            "ì‹ í˜¸ ê°’ì€ `display_value`ë¥¼ ìš°ì„  ì‚¬ìš©í•´ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.\n\n"
            "ì²« ë¬¸ì¥ì€ `ì±„ê´‘: ê°’(ê·¼ê±°)` í˜•ì‹ì„ í¬í•¨í•œ ê³ ì • í…œí”Œë¦¿ì„ ë”°ë¥´ì„¸ìš”.\n\n"
            "ì²« ë¬¸ì¥ì—ì„œ ì–¸ê¸‰í•œ ê·¼ê±°ëŠ” ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì¤‘ë³µí•´ì„œ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.\n\n"
            f"ì‚¬ìš©ì ì§ˆì˜ ì›ë¬¸:\n{query}"
        )

        def _call_llm() -> str:
            response = self.client.chat.completions.create(
                model="gpt-5.2-2025-12-11",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.0,
            )
            return (response.choices[0].message.content or "").strip()

        return self._run_validated_generation(mode="general", generate_fn=_call_llm)

    def _generate_no_match_answer(self, total_match_count: int = 0) -> str:
        return (
            f"ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë„ë©´ ì´ ê°œìˆ˜: {int(total_match_count)}\n"
            "ê²€ìƒ‰ëœ ë„ë©´ id: ì—†ìŒ\n"
            "ìš”ì²­ ì¡°ê±´ê³¼ ì¼ì¹˜í•˜ëŠ” ë„ë©´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )

    def _generate_validated_no_match_answer(self, total_match_count: int = 0) -> str:
        answer = self._generate_no_match_answer(total_match_count=total_match_count)
        if not self.answer_validation_enabled:
            return answer
        try:
            result = self._validate_answer_format(answer=answer, mode="no_match")
        except Exception:
            self.logger.exception("answer_validation_exception mode=no_match attempt=0")
            return answer
        if result.ok:
            self.logger.info("answer_validation_pass mode=no_match attempt=0 latency_ms=0")
            return answer
        self.logger.warning(
            "answer_validation_fail mode=no_match attempt=0 missing_fields=%s latency_ms=0",
            ",".join(result.missing_fields) or "none",
        )
        if self.answer_validation_safe_fallback:
            fallback = self._build_safe_default_answer(mode="no_match")
            self.logger.warning("answer_validation_fallback mode=no_match retries=0")
            return fallback
        return answer


# ----------------------------------------------------------------------------------------------
    def run(self, query: str) -> str:
        request_start = time.perf_counter()
        query_id = uuid.uuid4().hex[:12]
        normalized_query = query.strip()
        self._log_event(
            event="query_received",
            query_id=query_id,
            query_len=len(normalized_query),
            query_preview=normalized_query[:120],
        )
        if not normalized_query:
            self._log_event(
                event="query_completed",
                query_id=query_id,
                result="empty_query",
                latency_ms=int((time.perf_counter() - request_start) * 1000),
            )
            return "Try searching again."

        try:
            if self._is_floorplan_image_name(normalized_query):
                doc_lookup_start = time.perf_counter()
                doc = self._retrieve_by_document_id(normalized_query)
                self._log_event(
                    event="doc_lookup_complete",
                    query_id=query_id,
                    latency_ms=int((time.perf_counter() - doc_lookup_start) * 1000),
                    found=bool(doc),
                )
                if not doc:
                    answer = f"ìš”ì²­í•œ ë„ë©´ idë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {normalized_query}"
                    self._log_event(
                        event="query_completed",
                        query_id=query_id,
                        mode="document_id",
                        result="not_found",
                        latency_ms=int((time.perf_counter() - request_start) * 1000),
                    )
                    return answer
                generate_start = time.perf_counter()
                answer = self._generate_document_id_answer(normalized_query, doc)
                self._log_event(
                    event="generate_complete",
                    query_id=query_id,
                    mode="document_id",
                    latency_ms=int((time.perf_counter() - generate_start) * 1000),
                )
                self._log_event(
                    event="query_completed",
                    query_id=query_id,
                    mode="document_id",
                    result="ok",
                    latency_ms=int((time.perf_counter() - request_start) * 1000),
                )
                return answer

            analyze_start = time.perf_counter()
            query_json = self._analyze_query(normalized_query)
            self._log_event(
                event="analyze_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - analyze_start) * 1000),
                filter_count=len(query_json.get("filters", {}) or {}),
                documents_len=len(str(query_json.get("documents", "") or "")),
            )

            count_start = time.perf_counter()
            total_match_count = self._count_matches(
                query_json.get("filters", {}) or {},
                query_json.get("documents", "") or "",
            )
            self._log_event(
                event="count_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - count_start) * 1000),
                total_match_count=total_match_count,
            )
            if total_match_count <= 0:
                answer = self._generate_validated_no_match_answer(total_match_count=0)
                self._log_event(
                    event="query_completed",
                    query_id=query_id,
                    mode="general",
                    result="no_match",
                    latency_ms=int((time.perf_counter() - request_start) * 1000),
                )
                return answer
            retrieve_k = min(max(total_match_count, 3), 50)

            retrieve_start = time.perf_counter()
            docs = self._retrieve_hybrid(query_json, top_k=retrieve_k)
            self._log_event(
                event="retrieve_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - retrieve_start) * 1000),
                retrieve_k=retrieve_k,
                retrieved_count=len(docs),
            )

            rerank_start = time.perf_counter()
            docs = self._rerank_by_query_signal_preferences(docs, normalized_query)
            self._log_event(
                event="rerank_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - rerank_start) * 1000),
                reranked_count=len(docs),
            )

            generate_start = time.perf_counter()
            answer = self._generate_answer(
                normalized_query, query_json, docs, total_match_count
            )
            self._log_event(
                event="generate_complete",
                query_id=query_id,
                mode="general",
                latency_ms=int((time.perf_counter() - generate_start) * 1000),
            )
            self._log_event(
                event="query_completed",
                query_id=query_id,
                mode="general",
                result="ok",
                total_match_count=total_match_count,
                latency_ms=int((time.perf_counter() - request_start) * 1000),
            )
            return answer
        except Exception as exc:
            self._log_event(
                event="query_failed",
                level=logging.ERROR,
                query_id=query_id,
                error=str(exc),
                latency_ms=int((time.perf_counter() - request_start) * 1000),
            )
            raise
