import json
import logging
import re
import time
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Optional
import psycopg2
from openai import OpenAI


@dataclass
class AnswerValidationResult:
    ok: bool
    has_document_id_token: bool
    has_metadata_summary: bool
    has_layout_summary: bool
    missing_fields: list[str] = field(default_factory=list)


class ArchitecturalHybridRAG:
    ALLOWED_FILTER_COLUMNS = [
        "windowless_ratio",
        "balcony_ratio",
        "living_room_ratio",
        "bathroom_ratio",
        "kitchen_ratio",
        "structure_type",
        "bay_count",
        "room_count",
        "bathroom_count",
        "compliance_grade",
        "ventilation_grade",
        "has_special_space",
        "has_etc_space",
    ]

    FILTER_ALIASES = {
        "ventilation_quality": "ventilation_grade",
    }

    INT_FILTERS = {"bay_count", "room_count", "bathroom_count"}
    FLOAT_FILTERS = {
        "windowless_ratio",
        "balcony_ratio",
        "living_room_ratio",
        "bathroom_ratio",
        "kitchen_ratio",
    }
    BOOL_FILTERS = {"has_special_space", "has_etc_space"}
    VALID_RATIO_OPERATORS = {"Ïù¥ÏÉÅ", "Ïù¥Ìïò", "Ï¥àÍ≥º", "ÎØ∏Îßå", "ÎèôÏùº"}
    FLOORPLAN_IMAGE_NAME_RE = re.compile(
        r"^[A-Za-z0-9][A-Za-z0-9_.-]*\.(?:png|jpg|jpeg|bmp|tif|tiff|webp)$",
        re.IGNORECASE,
    )
    DOCUMENT_SIGNAL_KEY_ALIASES = {
        "lighting": ("lighting", "Ï±ÑÍ¥ë"),
        "ventilation": ("ventilation", "ÌôòÍ∏∞"),
        "family_harmony": ("family_harmony", "Í∞ÄÏ°± ÏúµÌôî", "Í∞ÄÏ°±ÏúµÌôî"),
        "storage": ("storage", "ÏàòÎÇ©Í≥µÍ∞Ñ", "ÏàòÎÇ© Í≥µÍ∞Ñ"),
    }
    DOCUMENT_SIGNAL_KR_LABELS = {
        "lighting": "Ï±ÑÍ¥ë",
        "ventilation": "ÌôòÍ∏∞",
        "family_harmony": "Í∞ÄÏ°± ÏúµÌôî",
        "storage": "ÏàòÎÇ©Í≥µÍ∞Ñ",
    }
    POSITIVE_SIGNAL_WORDS = ("Ïö∞Ïàò", "Ï†ÅÏ†ï", "Ï†ÅÌï©", "ÏñëÌò∏", "Ï∂©Î∂Ñ", "ÎÑâÎÑâ")
    NEGATIVE_SIGNAL_WORDS = ("ÎØ∏Ìù°", "Î∂ÄÏ°±", "Î∂ÄÏ†ÅÌï©", "Î∂àÌï©Í≤©", "ÎØ∏Îã¨", "ÏóÜÏùå")
    SIGNAL_POSITIVE_DISPLAY = {
        "lighting": "Ï¢ãÏùå",
        "ventilation": "Ï¢ãÏùå",
        "family_harmony": "Ï†ÅÌï©",
        "storage": "ÎÑâÎÑâÌï®",
    }
    SIGNAL_NEGATIVE_DISPLAY = {
        "lighting": "Î∂ÄÏ°±Ìï®",
        "ventilation": "Î∂ÄÏ°±Ìï®",
        "family_harmony": "ÎØ∏Ìù°Ìï®",
        "storage": "Î∂ÄÏ°±Ìï®",
    }
    DOCUMENT_ID_LINE_RE = re.compile(r"(?m)^1\.\s*Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id:\s*(.+)\s*$")
    GENERAL_ID_TOKEN_RE = re.compile(r"Í≤ÄÏÉâÎêú\s*ÎèÑÎ©¥\s*id", re.IGNORECASE)
    METADATA_SECTION_TOKEN = "2. ÎèÑÎ©¥ Í∏∞Î≥∏ Ï†ïÎ≥¥"
    LAYOUT_SECTION_TOKEN = "3. ÎèÑÎ©¥ Í≥µÍ∞Ñ Íµ¨ÏÑ± ÏÑ§Î™Ö"
    NO_MATCH_COUNT_LINE_RE = re.compile(
        r"Ï°∞Í±¥ÏùÑ\s*ÎßåÏ°±ÌïòÎäî\s*ÎèÑÎ©¥\s*Ï¥ù\s*Í∞úÏàò\s*:\s*0",
        re.IGNORECASE,
    )
    NO_MATCH_ID_LINE_RE = re.compile(
        r"Í≤ÄÏÉâÎêú\s*ÎèÑÎ©¥\s*id\s*:\s*ÏóÜÏùå",
        re.IGNORECASE,
    )
    NO_MATCH_MESSAGE_TOKEN = "ÏöîÏ≤≠ Ï°∞Í±¥Í≥º ÏùºÏπòÌïòÎäî ÎèÑÎ©¥Ïù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§."
    BALCONY_POSITIVE_HINT_RE = re.compile(
        r"(ÌôúÏö©ÎèÑ\s*ÎÜí|ÌôúÏö©\s*Í∞ÄÎä•|Ïô∏Î∂Ä\s*Í≥µÍ∞Ñ.*ÌôúÏö©|Ïó∞Í≤∞.*ÏõêÌôú|Ï±ÑÍ¥ë.*Ï¢ã|ÎÑì)",
        re.IGNORECASE,
    )
    BALCONY_NEGATIVE_HINT_RE = re.compile(
        r"(ÌôúÏö©ÎèÑ\s*ÎÇÆ|ÌôúÏö©\s*Ïñ¥Î†§|Ïó∞Í≤∞.*Î∂àÌé∏|Ï±ÑÍ¥ë.*Î∂ÄÏ°±|Ï¢Å|ÏóÜÏùå)",
        re.IGNORECASE,
    )

    def __init__(
        self,
        db_config,
        openai_api_key,
        embedding_model: str = "text-embedding-3-small",
        embedding_dimensions: int = 512,
        vector_weight: float = 0.8,
        text_weight: float = 0.2,
        answer_validation_enabled: bool = True,
        answer_validation_retry_max: int = 1,
        answer_validation_safe_fallback: bool = True,
    ):
        self.logger = logging.getLogger(self.__class__.__name__)
        if not self.logger.handlers:
            logging.basicConfig(
                level=logging.INFO,
                format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
            )

        self.conn = psycopg2.connect(**db_config)
        self._ensure_ratio_cmp_function()
        self.client = OpenAI(api_key=openai_api_key)
        self.embedding_model = embedding_model
        self.embedding_dimensions = embedding_dimensions
        self.vector_weight, self.text_weight = self._normalize_hybrid_weights(
            vector_weight, text_weight
        )
        self.answer_validation_enabled = bool(answer_validation_enabled)
        self.answer_validation_retry_max = max(0, int(answer_validation_retry_max))
        self.answer_validation_safe_fallback = bool(answer_validation_safe_fallback)
        self.word_dict: dict[str, Any] = {}
        word_path = Path(__file__).resolve().parent / "data" / "word.json"
        try:
            with word_path.open("r", encoding="utf-8") as f:
                loaded = json.load(f)
            self.word_dict = loaded if isinstance(loaded, dict) else {}
        except Exception as exc:  
            self.word_dict = {}
            self.logger.warning("Failed to load word dictionary (%s): %s", word_path, exc)

    def _log_event(self, event: str, level: int = logging.INFO, **fields: Any) -> None:
        try:
            payload = json.dumps(fields, ensure_ascii=False, sort_keys=True, default=str)
        except Exception:
            payload = str(fields)
        self.logger.log(level, "event=%s data=%s", event, payload)

    @staticmethod
    def _compress_compound_space_label(label: str) -> str:
        tokens = [token.strip() for token in str(label).split("/") if token.strip()]
        if len(tokens) < 2:
            return label

        first = re.fullmatch(r"(.+?)(\d+)$", tokens[0])
        if not first:
            return label

        base = first.group(1).strip()
        numbers = [first.group(2)]
        if not base:
            return label

        for token in tokens[1:]:
            if token.isdigit():
                numbers.append(token)
                continue
            match = re.fullmatch(r"(.+?)(\d+)$", token)
            if not match or match.group(1).strip() != base:
                return label
            numbers.append(match.group(2))

        return f"{base}{'/'.join(numbers)}"

    def _normalize_space_section_labels(self, answer: str) -> str:
        text = str(answer or "")
        if not text:
            return text

        def _replace(match: re.Match[str]) -> str:
            prefix = match.group("prefix")
            label = match.group("label")
            sep = match.group("sep")
            body = match.group("body")
            compacted = self._compress_compound_space_label(label)
            return f"{prefix}{compacted}{sep}{body}"

        return re.sub(
            r"(?m)^(?P<prefix>\s*‚ñ†\s*)(?P<label>[^:\n]+?)(?P<sep>\s*:\s*)(?P<body>.*)$",
            _replace,
            text,
        )

    def _normalize_summary_signal_sentence(self, answer: str) -> str:
        text = str(answer or "")
        if not text:
            return text

        # Remove low-value placeholder evidence instead of exposing "Í∑ºÍ±∞ ÏóÜÏùå".
        text = re.sub(
            r"\(\s*(?:Í∑ºÍ±∞\s*ÏóÜÏùå|Í∑ºÍ±∞\s*ÎØ∏ÌôïÏù∏|Í∑ºÍ±∞\s*Î∂àÎ™Ö|ÌôïÏù∏\s*ÌïÑÏöî)\s*\)",
            "",
            text,
            flags=re.IGNORECASE,
        )
        text = re.sub(r"[ \t]+,", ",", text)
        text = re.sub(r"[ \t]{2,}", " ", text)

        def _rewrite(match: re.Match[str]) -> str:
            prefix = match.group("prefix") or ""
            bay = match.group("bay").strip()
            structure = re.sub(r"\s+", " ", match.group("structure")).strip()
            rest = re.sub(r"\s+", " ", match.group("rest")).strip()
            return f"{prefix}{bay}Bay {structure} Íµ¨Ï°∞ÏûÖÎãàÎã§.\n{prefix}{rest}"

        return re.sub(
            r"(?m)^(?P<prefix>\s*)ÎèÑÎ©¥ÏùÄ\s*(?P<bay>\d+)\s*Bay\s+(?P<structure>[^,\n]+?)\s*Íµ¨Ï°∞(?:Ïù¥Î©∞|Î°ú),\s*(?P<rest>Ï±ÑÍ¥ë\s*:\s*[^\n]+?ÏúºÎ°ú\s*Ï†ïÎ¶¨Îê©ÎãàÎã§\.)\s*$",
            _rewrite,
            text,
        )

    def _normalize_meta_expressions(self, answer: str) -> str:
        text = str(answer or "")
        if not text:
            return text

        # Example: "Ïô∏Í∏∞Ï∞ΩÏù¥ ÌïÑÏöîÌïòÎã§Í≥† Í∏∞Ïû¨ÎêòÏñ¥ ÏûàÏäµÎãàÎã§." -> "Ïô∏Í∏∞Ï∞ΩÏù¥ ÌïÑÏöîÌï©ÎãàÎã§."
        text = re.sub(
            r"([^\n.,:;]+?)ÌïòÎã§Í≥†\s*(?:Í∏∞Ïû¨|Ïñ∏Í∏â|ÏÑúÏà†|ÌëúÍ∏∞|ÌëúÏãú)ÎêòÏñ¥ ÏûàÏäµÎãàÎã§",
            r"\1Ìï©ÎãàÎã§",
            text,
        )
        # Example: "Ï∞ΩÎ¨∏Ïù¥ ÏóÜÎã§Í≥† Í∏∞Ïû¨ÎêòÏñ¥ ÏûàÏäµÎãàÎã§." -> "Ï∞ΩÎ¨∏Ïù¥ ÏóÜÏäµÎãàÎã§."
        text = re.sub(
            r"([^\n.,:;]+?)Îã§Í≥†\s*(?:Í∏∞Ïû¨|Ïñ∏Í∏â|ÏÑúÏà†|ÌëúÍ∏∞|ÌëúÏãú)ÎêòÏñ¥ ÏûàÏäµÎãàÎã§",
            r"\1ÏûÖÎãàÎã§",
            text,
        )
        text = re.sub(
            r"(?:ÎùºÍ≥†|Îã§Í≥†)\s*(?:Í∏∞Ïû¨|Ïñ∏Í∏â|ÏÑúÏà†|ÌëúÍ∏∞|ÌëúÏãú)ÎêòÏñ¥ ÏûàÏäµÎãàÎã§",
            "",
            text,
        )
        return re.sub(r"[ \t]{2,}", " ", text)

    def _normalize_generated_answer(self, answer: str) -> str:
        return self._normalize_meta_expressions(
            self._normalize_summary_signal_sentence(
                self._normalize_space_section_labels(answer)
            )
        )

    def _validate_answer_format(
        # LLM ÎãµÎ≥Ä ÌòïÏãùÏù¥ ÏßÄÏºúÏ°åÎäîÍ∞Ä 
        self,
        answer: str,
        mode: str,
        expected_document_id: Optional[str] = None,
    ) -> AnswerValidationResult:
        text = str(answer or "")
        missing_fields: list[str] = []

        is_non_empty = bool(text.strip())
        if not is_non_empty:
            missing_fields.append("non_empty_answer")

        normalized_mode = mode.strip().lower()
        if normalized_mode == "no_match":
            has_metadata_summary = bool(self.NO_MATCH_COUNT_LINE_RE.search(text))
            has_document_id_token = bool(self.NO_MATCH_ID_LINE_RE.search(text))
            has_layout_summary = self.NO_MATCH_MESSAGE_TOKEN in text
            if not has_metadata_summary:
                missing_fields.append("no_match_count")
            if not has_document_id_token:
                missing_fields.append("document_id_none")
            if not has_layout_summary:
                missing_fields.append("no_match_message")
            ok = (
                is_non_empty
                and has_document_id_token
                and has_metadata_summary
                and has_layout_summary
            )
            return AnswerValidationResult(
                ok=ok,
                has_document_id_token=has_document_id_token,
                has_metadata_summary=has_metadata_summary,
                has_layout_summary=has_layout_summary,
                missing_fields=missing_fields,
            )

        has_metadata_summary = self.METADATA_SECTION_TOKEN in text
        if not has_metadata_summary:
            missing_fields.append("metadata_summary")

        has_layout_summary = self.LAYOUT_SECTION_TOKEN in text
        if not has_layout_summary:
            missing_fields.append("layout_summary")

        if normalized_mode == "document_id":
            expected = (expected_document_id or "").strip()
            has_document_id_token = bool(
                re.search(
                    rf"(?m)^1\.\s*Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id:\s*{re.escape(expected)}\s*$",
                    text,
                )
            )
        elif normalized_mode == "general":
            has_document_id_token = bool(self.GENERAL_ID_TOKEN_RE.search(text))
        else:
            raise ValueError(f"Unsupported validation mode: {mode}")

        if not has_document_id_token:
            missing_fields.append("document_id_token")

        ok = (
            is_non_empty
            and has_document_id_token
            and has_metadata_summary
            and has_layout_summary
        )
        return AnswerValidationResult(
            ok=ok,
            has_document_id_token=has_document_id_token,
            has_metadata_summary=has_metadata_summary,
            has_layout_summary=has_layout_summary,
            missing_fields=missing_fields,
        )

    def _build_safe_default_answer(
        self, mode: str, expected_document_id: Optional[str] = None
    ) -> str:
        normalized_mode = mode.strip().lower()
        if normalized_mode == "document_id":
            document_id = (expected_document_id or "Ï†ïÎ≥¥ ÏÉùÏÑ± Î∂àÍ∞Ä").strip() or "Ï†ïÎ≥¥ ÏÉùÏÑ± Î∂àÍ∞Ä"
            return (
                f"1. Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: {document_id}\n\n"
                "2. ÎèÑÎ©¥ Í∏∞Î≥∏ Ï†ïÎ≥¥ üìä\n"
                "- ÏùëÎãµ ÌòïÏãù Í≤ÄÏ¶ù Ïã§Ìå®Î°ú ÏöîÏïΩ ÏÉùÏÑ± Î∂àÍ∞Ä\n\n"
                "3. ÎèÑÎ©¥ Í≥µÍ∞Ñ Íµ¨ÏÑ± ÏÑ§Î™Ö üß©\n"
                "- ÏùëÎãµ ÌòïÏãù Í≤ÄÏ¶ù Ïã§Ìå®Î°ú ÏÑ§Î™Ö ÏÉùÏÑ± Î∂àÍ∞Ä"
            )
        if normalized_mode == "general":
            return (
                "1. Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: Ï†ïÎ≥¥ ÏÉùÏÑ± Î∂àÍ∞Ä\n\n"
                "2. ÎèÑÎ©¥ Í∏∞Î≥∏ Ï†ïÎ≥¥ üìä\n"
                "- ÏùëÎãµ ÌòïÏãù Í≤ÄÏ¶ù Ïã§Ìå®Î°ú ÏöîÏïΩ ÏÉùÏÑ± Î∂àÍ∞Ä\n\n"
                "3. ÎèÑÎ©¥ Í≥µÍ∞Ñ Íµ¨ÏÑ± ÏÑ§Î™Ö üß©\n"
                "- ÏùëÎãµ ÌòïÏãù Í≤ÄÏ¶ù Ïã§Ìå®Î°ú ÏÑ§Î™Ö ÏÉùÏÑ± Î∂àÍ∞Ä"
            )
        if normalized_mode == "no_match":
            return (
                "Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî ÎèÑÎ©¥ Ï¥ù Í∞úÏàò: 0\n"
                "Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: ÏóÜÏùå\n"
                "ÏöîÏ≤≠ Ï°∞Í±¥Í≥º ÏùºÏπòÌïòÎäî ÎèÑÎ©¥Ïù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§."
            )
        raise ValueError(f"Unsupported validation mode: {mode}")

    def _run_validated_generation(
        self,
        mode: str,
        generate_fn: Callable[[], str],
        expected_document_id: Optional[str] = None,
    ) -> str:
        try:
            answer = self._normalize_generated_answer(generate_fn())
        except Exception:
            self.logger.exception("answer_generation_exception mode=%s attempt=0", mode)
            if self.answer_validation_safe_fallback:
                fallback = self._build_safe_default_answer(
                    mode=mode,
                    expected_document_id=expected_document_id,
                )
                self.logger.warning(
                    "answer_validation_fallback mode=%s retries=%d reason=generation_error",
                    mode,
                    self.answer_validation_retry_max,
                )
                return fallback
            raise
        if not self.answer_validation_enabled:
            return answer

        validation_start = time.perf_counter()
        try:
            result = self._validate_answer_format(
                answer=answer,
                mode=mode,
                expected_document_id=expected_document_id,
            )
        except Exception:
            self.logger.exception("answer_validation_exception mode=%s attempt=0", mode)
            return answer
        validation_ms = int((time.perf_counter() - validation_start) * 1000)

        if result.ok:
            self.logger.info(
                "answer_validation_pass mode=%s attempt=0 latency_ms=%d",
                mode,
                validation_ms,
            )
            return answer

        self.logger.warning(
            "answer_validation_fail mode=%s attempt=0 missing_fields=%s latency_ms=%d",
            mode,
            ",".join(result.missing_fields) or "none",
            validation_ms,
        )

        last_answer = answer
        for attempt in range(1, self.answer_validation_retry_max + 1):
            self.logger.warning("answer_validation_retry mode=%s attempt=%d", mode, attempt)
            try:
                last_answer = self._normalize_generated_answer(generate_fn())
            except Exception:
                self.logger.exception("answer_generation_exception mode=%s attempt=%d", mode, attempt)
                continue
            retry_validation_start = time.perf_counter()
            try:
                retry_result = self._validate_answer_format(
                    answer=last_answer,
                    mode=mode,
                    expected_document_id=expected_document_id,
                )
            except Exception:
                self.logger.exception(
                    "answer_validation_exception mode=%s attempt=%d", mode, attempt
                )
                continue
            retry_validation_ms = int((time.perf_counter() - retry_validation_start) * 1000)
            if retry_result.ok:
                self.logger.info(
                    "answer_validation_pass mode=%s attempt=%d latency_ms=%d",
                    mode,
                    attempt,
                    retry_validation_ms,
                )
                return last_answer
            self.logger.warning(
                "answer_validation_fail mode=%s attempt=%d missing_fields=%s latency_ms=%d",
                mode,
                attempt,
                ",".join(retry_result.missing_fields) or "none",
                retry_validation_ms,
            )

        if self.answer_validation_safe_fallback:
            fallback = self._build_safe_default_answer(
                mode=mode,
                expected_document_id=expected_document_id,
            )
            self.logger.warning(
                "answer_validation_fallback mode=%s retries=%d",
                mode,
                self.answer_validation_retry_max,
            )
            return fallback
        return last_answer

    def _normalize_hybrid_weights(
        self, vector_weight: float, text_weight: float
    ) -> tuple[float, float]:
        vector = float(vector_weight)
        text = float(text_weight)
        if vector < 0 or text < 0:
            raise ValueError("vector_weight and text_weight must be non-negative.")
        total = vector + text
        if total == 0:
            raise ValueError("At least one hybrid weight must be greater than zero.")
        return vector / total, text / total

    def _analyze_query(self, query: str) -> dict:
        """ 
        LLM: query -> JSON (filters, documents)
        """
        word_rules_text = json.dumps(self.word_dict, ensure_ascii=False, indent=2)
        system_prompt = (
            "You are a query analyzer for architectural floorplan retrieval.\n"
            "Return ONLY valid JSON in this exact schema:\n"
            "{\n"
            '  "filters": {\n'
            '    "windowless_ratio": {"op": "Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº", "val": "number"} (optional),\n'
            '    "balcony_ratio": {"op": "Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº", "val": "number"} (optional),\n'
            '    "living_room_ratio": {"op": "Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº", "val": "number"} (optional),\n'
            '    "bathroom_ratio": {"op": "Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº", "val": "number"} (optional),\n'
            '    "kitchen_ratio": {"op": "Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº", "val": "number"} (optional),\n'
            '    "structure_type": "string(optional)",\n'
            '    "bay_count": "integer(optional)",\n'
            '    "room_count": "integer(optional)",\n'
            '    "bathroom_count": "integer(optional)",\n'
            '    "compliance_grade": "string(optional)",\n'
            '    "ventilation_grade": "string(optional)",\n'
            '    "has_special_space": "boolean(optional)",\n'
            '    "has_etc_space": "boolean(optional)"\n'
            "  },\n"
            '  "documents": "string(required)"\n'
            "}\n"
            "Map explicit, structured constraints to filters.\n"
            "Put abstract or descriptive intent into documents.\n"
            "If no filter applies, use an empty filters object.\n"
            "Synonym and classification rules (JSON):\n"
            f"{word_rules_text}\n"
            "Prompt rules:\n"
            "1) Normalization Rule: When interpreting the user's query, map terms to standardized space names using normalization_rules.\n"
            "2) Etc. Space Classification: If a mapped/mentioned space is in special_classification['Í∏∞ÌÉÄÍ≥µÍ∞Ñ'] "
            "(or equivalent category_groups['Í∏∞ÌÉÄÍ≥µÍ∞Ñ']), include \"has_etc_space\": true in filters.\n"
            "3) Special Space Classification: If a mapped/mentioned space is in special_classification['ÌäπÌôîÍ≥µÍ∞Ñ'] "
            "(or equivalent category_groups['ÌäπÌôîÍ≥µÍ∞Ñ']), include \"has_special_space\": true in filters.\n"
            "Only include these boolean fields when the condition is met."
        )

        try:
            response = self.client.chat.completions.create(
                model="gpt-5.2-2025-12-11",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query},
                ],
                temperature=0.0,
                response_format={"type": "json_object"},
            )
            raw_text = (response.choices[0].message.content or "").strip()
            if not raw_text:
                raise ValueError("Analyzer returned empty content")

            cleaned = raw_text.replace("```json", "").replace("```", "").strip()
            start = cleaned.find("{")
            end = cleaned.rfind("}")
            if start == -1 or end == -1 or start > end:
                raise ValueError("Analyzer JSON object not found")
            parsed = json.loads(cleaned[start : end + 1])

            raw_filters = parsed.get("filters", {})
            if not isinstance(raw_filters, dict):
                raise ValueError("Invalid analyzer JSON schema")

            documents = (
                parsed.get("documents")
                or parsed.get("search_text")
                or parsed.get("context")
                or query
            )
            documents = str(documents).strip()
            if not documents:
                documents = query
            documents = self._augment_documents_from_query(query, documents)

            filters = self._normalize_filters(raw_filters)
            filters = self._augment_filters_from_query(query, filters)
            filters = self._drop_implicit_ratio_filters(query, filters)
            return {"filters": filters, "documents": documents, "raw_query": query}
        except (json.JSONDecodeError, ValueError, KeyError, TypeError, IndexError):
            self.logger.warning(
                "Analyzer JSON parsing failed. Falling back to keyword-only search."
            )
            return {"filters": {}, "documents": query, "raw_query": query}

    def _normalize_filters(self, raw_filters: dict[str, Any]) -> dict[str, Any]:
        normalized: dict[str, Any] = {}
        for key, value in raw_filters.items():
            canonical_key = self.FILTER_ALIASES.get(key, key)
            if canonical_key not in self.ALLOWED_FILTER_COLUMNS:
                continue
            coerced = self._coerce_filter_value(canonical_key, value)
            if coerced is not None:
                normalized[canonical_key] = coerced

        for ratio_key in self.FLOAT_FILTERS:
            if ratio_key in normalized:
                continue
            op = raw_filters.get(f"{ratio_key}_op", raw_filters.get(f"{ratio_key}_operator"))
            val = raw_filters.get(f"{ratio_key}_val", raw_filters.get(f"{ratio_key}_value"))
            if op is None and val is None:
                continue
            coerced = self._coerce_filter_value(ratio_key, {"op": op, "val": val})
            if coerced is not None:
                normalized[ratio_key] = coerced
        return normalized

    def _coerce_filter_value(self, key: str, value: Any) -> Any:
        if value is None:
            return None

        if key in self.INT_FILTERS:
            if isinstance(value, bool):
                return None
            if isinstance(value, (int, float)):
                return int(value)
            if isinstance(value, str):
                match = re.search(r"-?\d+", value)
                if match:
                    return int(match.group())
            return None

        if key in self.FLOAT_FILTERS:
            ratio_filter = self._coerce_ratio_filter(value)
            if ratio_filter is not None:
                return ratio_filter
            return None

        if key in self.BOOL_FILTERS:
            if isinstance(value, bool):
                return value
            if isinstance(value, str):
                v = value.strip().lower()
                if v in {"true", "1", "yes"}:
                    return True
                if v in {"false", "0", "no"}:
                    return False
            return None

        if isinstance(value, str):
            cleaned = value.strip()
            return cleaned if cleaned else None
        return str(value)

    def _coerce_ratio_filter(self, value: Any) -> Optional[dict[str, Any]]:
        if value is None or isinstance(value, bool):
            return None

        if isinstance(value, (int, float)):
            return {"op": "ÎèôÏùº", "val": float(value)}

        if isinstance(value, str):
            text = value.strip()
            if not text:
                return None
            op_match = re.search(r"(Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº)", text)
            num_match = re.search(r"-?\d+(\.\d+)?", text)
            if num_match:
                op = self._normalize_ratio_operator(op_match.group(1) if op_match else None)
                return {"op": op or "ÎèôÏùº", "val": float(num_match.group())}
            return None

        if isinstance(value, dict):
            raw_op = value.get("op", value.get("operator"))
            raw_val = value.get("val", value.get("value"))
            val = self._parse_float(raw_val)
            op = self._normalize_ratio_operator(raw_op)
            if raw_op is None and val is None:
                return None
            return {"op": op, "val": val}

        return None

    def _normalize_ratio_operator(self, op: Any) -> Optional[str]:
        if not isinstance(op, str):
            return None
        cleaned = op.strip()
        return cleaned if cleaned in self.VALID_RATIO_OPERATORS else None

    def _parse_float(self, value: Any) -> Optional[float]:
        if value is None or isinstance(value, bool):
            return None
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            match = re.search(r"-?\d+(\.\d+)?", value)
            if match:
                return float(match.group())
        return None

    def _ensure_ratio_cmp_function(self) -> None:
        sql = """
        CREATE OR REPLACE FUNCTION public.ratio_cmp(
            field_val double precision,
            op text,
            val double precision
        ) RETURNS boolean
        LANGUAGE sql
        IMMUTABLE
        AS $$
        SELECT CASE
            WHEN op IS NULL OR val IS NULL THEN TRUE
            WHEN op = 'Ïù¥ÏÉÅ' THEN field_val >= val
            WHEN op = 'Ïù¥Ìïò' THEN field_val <= val
            WHEN op = 'Ï¥àÍ≥º' THEN field_val > val
            WHEN op = 'ÎØ∏Îßå' THEN field_val < val
            WHEN op = 'ÎèôÏùº' THEN field_val = val
            ELSE TRUE
        END
        $$;
        """
        try:
            with self.conn.cursor() as cur:
                cur.execute(sql)
            self.conn.commit()
        except Exception:
            self.conn.rollback()
            self.logger.exception("Failed to create ratio_cmp function.")

    def _augment_filters_from_query(
        self, query: str, filters: dict[str, Any]
    ) -> dict[str, Any]:
        augmented = dict(filters)

        if "structure_type" not in augmented:
            if "ÌåêÏÉÅÌòï" in query:
                augmented["structure_type"] = "ÌåêÏÉÅÌòï"
            elif "ÌÉÄÏõåÌòï" in query:
                augmented["structure_type"] = "ÌÉÄÏõåÌòï"
            elif "ÌòºÌï©Ìòï" in query:
                augmented["structure_type"] = "ÌòºÌï©Ìòï"
            elif "Î≥µÎèÑÌòï" in query:
                augmented["structure_type"] = "Î≥µÎèÑÌòï"

        if "bay_count" not in augmented:
            match = re.search(r"(\d+)\s*Î≤†Ïù¥", query)
            if match:
                augmented["bay_count"] = int(match.group(1))

        if "room_count" not in augmented:
            match = re.search(r"Î∞©\s*(\d+)\s*Í∞ú", query) or re.search(
                r"(\d+)\s*Í∞ú\s*Î∞©", query
            )
            if match:
                augmented["room_count"] = int(match.group(1))

        if "bathroom_count" not in augmented:
            match = re.search(r"(ÏöïÏã§|ÌôîÏû•Ïã§)\s*(\d+)\s*Í∞ú", query) or re.search(
                r"(\d+)\s*Í∞ú\s*(ÏöïÏã§|ÌôîÏû•Ïã§)", query
            )
            if match:
                numeric = re.search(r"\d+", match.group(0))
                if numeric:
                    augmented["bathroom_count"] = int(numeric.group())

        if "ventilation_grade" not in augmented and "ÌôòÍ∏∞" in query:
            if "Ïö∞Ïàò" in query:
                augmented["ventilation_grade"] = "Ïö∞Ïàò"
            elif "Î≥¥ÌÜµ" in query:
                augmented["ventilation_grade"] = "Î≥¥ÌÜµ"
            elif "ÎØ∏Ìù°" in query:
                augmented["ventilation_grade"] = "ÎØ∏Ìù°"

        return augmented

    def _drop_implicit_ratio_filters(
        self, query: str, filters: dict[str, Any]
    ) -> dict[str, Any]:
        
        if re.search(r"(%|ÌçºÏÑºÌä∏|ÎπÑÏú®|ratio|Ïù¥ÏÉÅ|Ïù¥Ìïò|Ï¥àÍ≥º|ÎØ∏Îßå|ÎèôÏùº)", query, flags=re.IGNORECASE):
            return filters

        sanitized = dict(filters)
        for key in self.FLOAT_FILTERS:
            sanitized.pop(key, None)
        return sanitized

    def _is_floorplan_image_name(self, query: str) -> bool:
        return bool(self.FLOORPLAN_IMAGE_NAME_RE.fullmatch(query.strip()))

    def _augment_documents_from_query(self, query: str, documents: str) -> str:
        base = str(documents or "").strip()
        text = str(query or "")
        if not base:
            return base

        if not re.search(r"(Î∞úÏΩîÎãà|Î≤†ÎûÄÎã§)", text, flags=re.IGNORECASE):
            return base

        if not re.search(
            r"(ÌôúÏö©|ÌôúÏö©ÎèÑ|Ïó∞Í≤∞|Ï±ÑÍ¥ë|Ï¢ã|Ïö∞Ïàò|ÏñëÌò∏|ÎÑì)",
            text,
            flags=re.IGNORECASE,
        ):
            return base

        intent_terms = [
            "Î∞úÏΩîÎãà ÌôúÏö© Í∞ÄÎä•",
            "Î∞úÏΩîÎãà ÌôúÏö©ÎèÑÍ∞Ä ÎÜí",
            "Ïô∏Î∂Ä Í≥µÍ∞ÑÏúºÎ°ú ÌôúÏö©",
            "Ïô∏Î∂Ä Í≥µÍ∞ÑÍ≥ºÏùò Ïó∞Í≤∞Ïù¥ ÏõêÌôú",
            "Î∞úÏΩîÎãà Ï±ÑÍ¥ëÏù¥ Ï¢ã",
            "Î∞úÏΩîÎãàÎäî ÎÑìÍ≥†",
        ]
        joined = " OR ".join(f'"{term}"' for term in intent_terms)
        return f"({base}) OR ({joined})"

    def _extract_document_signals(self, document: str) -> list[dict[str, str]]:
        text = str(document or "")
        if not text.strip():
            return []

        signals: list[dict[str, str]] = []
        for canonical_key, aliases in self.DOCUMENT_SIGNAL_KEY_ALIASES.items():
            match_value: Optional[str] = None
            match_source: Optional[str] = None
            for alias in aliases:
                pattern = rf"{re.escape(alias)}\s*ÏùÄ\(Îäî\)\s*([^\n.]+)"
                match = re.search(pattern, text, flags=re.IGNORECASE)
                if match:
                    match_value = re.sub(r"\s+", " ", match.group(1)).strip()
                    match_source = re.sub(r"\s+", " ", match.group(0)).strip()
                    break
            if match_value:
                normalized_value = self._normalize_signal_value_for_display(
                    canonical_key, match_value
                )
                signals.append(
                    {
                        "key": canonical_key,
                        "label": self.DOCUMENT_SIGNAL_KR_LABELS[canonical_key],
                        "value": match_value,
                        "display_value": normalized_value,
                        "source": match_source or "",
                    }
                )
        return signals

    def _infer_signal_polarity(self, value: str) -> Optional[str]:
        normalized = re.sub(r"\s+", "", str(value or ""))
        if not normalized:
            return None
        if any(token in normalized for token in self.NEGATIVE_SIGNAL_WORDS):
            return "negative"
        if any(token in normalized for token in self.POSITIVE_SIGNAL_WORDS):
            return "positive"
        return None

    def _normalize_signal_value_for_display(self, key: str, value: str) -> str:
        polarity = self._infer_signal_polarity(value)
        if polarity == "positive":
            return self.SIGNAL_POSITIVE_DISPLAY.get(key, "Ï¢ãÏùå")
        if polarity == "negative":
            return self.SIGNAL_NEGATIVE_DISPLAY.get(key, "Î∂ÄÏ°±Ìï®")
        cleaned = re.sub(r"\s+", " ", str(value or "")).strip()
        return cleaned if cleaned else "ÌôïÏù∏ ÌïÑÏöî"

    def _extract_query_signal_preferences(self, query: str) -> dict[str, str]:
        text = str(query or "")
        if not text.strip():
            return {}

        positive_hint = bool(
            re.search(r"(Ï¢ã|Ïö∞Ïàò|Ï†ÅÏ†ï|Ï†ÅÌï©|ÏñëÌò∏|Ï∂©Î∂Ñ|ÎÑâÎÑâ|Î∞ù)", text, flags=re.IGNORECASE)
        )
        negative_hint = bool(
            re.search(r"(ÎÇòÏÅò|Î∂ÄÏ°±|ÎØ∏Ìù°|Î∂ÄÏ†ÅÌï©|Î∂àÌï©Í≤©|Ïñ¥Îë°|ÏóÜ)", text, flags=re.IGNORECASE)
        )
        if not positive_hint and not negative_hint:
            return {}

        preferred = "positive" if positive_hint and not negative_hint else None
        if negative_hint and not positive_hint:
            preferred = "negative"
        if preferred is None:
            return {}

        preferences: dict[str, str] = {}
        if re.search(r"(Ï±ÑÍ¥ë|lighting)", text, flags=re.IGNORECASE):
            preferences["lighting"] = preferred
        if re.search(r"(ÏàòÎÇ©Í≥µÍ∞Ñ|ÏàòÎÇ©|storage)", text, flags=re.IGNORECASE):
            preferences["storage"] = preferred
        if re.search(r"(ÌôòÍ∏∞|ventilation)", text, flags=re.IGNORECASE):
            preferences["ventilation"] = preferred
        if re.search(r"(Í∞ÄÏ°±\s*ÏúµÌôî|family_harmony)", text, flags=re.IGNORECASE):
            preferences["family_harmony"] = preferred
        if re.search(r"(Î∞úÏΩîÎãà|Î≤†ÎûÄÎã§)", text, flags=re.IGNORECASE):
            preferences["balcony_usage"] = preferred
        return preferences

    def _infer_balcony_utilization_polarity(self, document: str) -> Optional[str]:
        text = str(document or "")
        if not text.strip():
            return None

        segments = re.split(r"[.\n]", text)
        balcony_segments = [
            segment for segment in segments if re.search(r"(Î∞úÏΩîÎãà|Î≤†ÎûÄÎã§)", segment, re.IGNORECASE)
        ]
        if not balcony_segments:
            return None

        balcony_text = " ".join(segment.strip() for segment in balcony_segments if segment.strip())
        normalized = re.sub(r"\s+", " ", balcony_text)
        if self.BALCONY_NEGATIVE_HINT_RE.search(normalized):
            return "negative"
        if self.BALCONY_POSITIVE_HINT_RE.search(normalized):
            return "positive"
        return None

    def _rerank_by_query_signal_preferences(
        self, docs: list[tuple[Any, ...]], query: str
    ) -> list[tuple[Any, ...]]:
        preferences = self._extract_query_signal_preferences(query)
        if not preferences or not docs:
            return docs

        rescored_docs: list[tuple[float, tuple[Any, ...]]] = []
        for row in docs:
            base_score = float(row[15] if len(row) > 15 and row[15] is not None else 0.0)
            document_text = str(row[1] if len(row) > 1 else "")
            signals = self._extract_document_signals(document_text)
            signal_map = {signal["key"]: signal["value"] for signal in signals}

            bonus = 0.0
            for key, desired in preferences.items():
                if key == "balcony_usage":
                    polarity = self._infer_balcony_utilization_polarity(document_text)
                    if polarity == desired:
                        bonus += 0.08
                    elif polarity and polarity != desired:
                        bonus -= 0.04
                    continue
                value = signal_map.get(key)
                if not value:
                    continue
                polarity = self._infer_signal_polarity(value)
                if polarity == desired:
                    bonus += 0.08
                elif polarity and polarity != desired:
                    bonus -= 0.04

            adjusted_row = (*row[:-1], base_score + bonus) if len(row) > 0 else row
            rescored_docs.append((base_score + bonus, adjusted_row))

        rescored_docs.sort(key=lambda item: item[0], reverse=True)
        return [row for _, row in rescored_docs]

    def _retrieve_by_document_id(self, document_id: str) -> Optional[tuple]:
        sql = """
            SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
            structure_type, bay_count, room_count, bathroom_count,
            compliance_grade, ventilation_grade, has_special_space, has_etc_space,
            1.0::double precision AS similarity
            FROM FP_Analysis
            WHERE LOWER(document_id) = LOWER(%s)
            LIMIT 1
        """
        with self.conn.cursor() as cur:
            cur.execute(sql, (document_id.strip(),))
            return cur.fetchone()

    def _row_to_candidate(self, row: tuple[Any, ...], rank: int) -> dict[str, Any]:
        (
            document_id,
            document,
            windowless_ratio,
            balcony_ratio,
            living_room_ratio,
            bathroom_ratio,
            kitchen_ratio,
            structure_type,
            bay_count,
            room_count,
            bathroom_count,
            compliance_grade,
            ventilation_grade,
            has_special_space,
            has_etc_space,
            similarity,
        ) = row
        return {
            "rank": rank,
            "document_id": document_id,
            "metadata": {
                "room_count": room_count,
                "bathroom_count": bathroom_count,
                "bay_count": bay_count,
                "living_room_ratio": living_room_ratio,
                "kitchen_ratio": kitchen_ratio,
                "bathroom_ratio": bathroom_ratio,
                "balcony_ratio": balcony_ratio,
                "windowless_ratio": windowless_ratio,
                "structure_type": structure_type,
                "ventilation_quality": ventilation_grade,
                "has_special_space": has_special_space,
                "has_etc_space": has_etc_space,
                "compliance_grade": compliance_grade,
            },
            "document": document,
            "document_signals": self._extract_document_signals(document),
            "similarity": similarity,
        }

    def _generate_document_id_answer(self, document_id: str, doc: tuple[Any, ...]) -> str:
        candidate = self._row_to_candidate(doc, rank=1)
        candidate_json = json.dumps(candidate, ensure_ascii=False, indent=2)

        system_prompt = """ You are a **specialized sLLM for architectural floor plan retrieval**.

Your role is to, for each retrieved floor plan:
1. Explain **why this floor plan was selected**,
2. Describe the **metadata of the floor plan in a neutral manner**, and
3. Summarize each floor plan‚Äôs **document content clearly and concisely**, without interpretation.

You must **never perform judgment, evaluation, recommendation, or interpretation**.

**Absolute Prohibitions**
- Do not judge the suitability, quality, or problems of the floor plan.
- Do not provide design advice or suggestions for improvement.
- Do not interpret legal regulations or permit/approval feasibility.
- Do not repeat evaluation results already present in the metadata within the document summary.

========================
Output Format (Must Be Preserved, Repeated for Each Floor Plan)
- All content must be written in Korean.
========================

1. Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: {document_id}

2. ÎèÑÎ©¥ Í∏∞Î≥∏ Ï†ïÎ≥¥ üìä
‚ñ† Í≥µÍ∞Ñ Íµ¨ÏÑ± Ïó¨Î∂ÄÏùò Í∞íÏùÄ Îã§Ïùå ÌëúÌòÑÏúºÎ°ú Í≥†Ï†ïÌïúÎã§.
- true ‚Üí Ï°¥Ïû¨
- false ‚Üí ÏóÜÏùå

Ï∂úÎ†• ÌòïÏãù(Í≥†Ï†ï):
‚ñ† Í≥µÍ∞Ñ Í∞úÏàò
    - Î∞© Í∞úÏàò: {room_count}
    - ÌôîÏû•Ïã§ Í∞úÏàò: {bathroom_count}
    - Bay Í∞úÏàò: {bay_count}
‚ñ† Ï†ÑÏ≤¥ Î©¥Ï†Å ÎåÄÎπÑ Í≥µÍ∞Ñ ÎπÑÏú® (%)
    - Í±∞Ïã§ Í≥µÍ∞Ñ: {living_room_ratio}
    - Ï£ºÎ∞© Í≥µÍ∞Ñ: {kitchen_ratio}
    - ÏöïÏã§ Í≥µÍ∞Ñ: {bathroom_ratio}
    - Î∞úÏΩîÎãà Í≥µÍ∞Ñ: {balcony_ratio}
    - Ï∞ΩÎ¨∏Ïù¥ ÏóÜÎäî Í≥µÍ∞Ñ: {windowless_ratio}
‚ñ† Íµ¨Ï°∞ Î∞è ÏÑ±Îä•
    - Í±¥Î¨º Íµ¨Ï°∞ Ïú†Ìòï: {structure_type}
    - ÌôòÍ∏∞: {ventilation_quality}
‚ñ† Í≥µÍ∞Ñ Íµ¨ÏÑ± Ïó¨Î∂Ä
    - ÌäπÌôî Í≥µÍ∞Ñ: {has_special_space}
    - Í∏∞ÌÉÄ Í≥µÍ∞Ñ: {has_etc_space}
‚ñ† Ï¢ÖÌï© ÌèâÍ∞Ä
    - ÌèâÍ∞Ä Í≤∞Í≥º: {compliance_grade}

3. ÎèÑÎ©¥ Í≥µÍ∞Ñ Íµ¨ÏÑ± ÏÑ§Î™Ö üß©
Since the document is **internal evaluation text**,
it must be restructured into a form that is easy for users to read according to the rules below.

**Organization Rules:**
* Use **only factual information** contained in the original text.
* Remove document-meta expressions such as *‚Äúis stated,‚Äù ‚Äúis mentioned,‚Äù* or *‚Äúis described.‚Äù*
* Do not use Korean meta expressions like "Í∏∞Ïû¨ÎêòÏñ¥ ÏûàÏäµÎãàÎã§", "Ïñ∏Í∏âÎêòÏñ¥ ÏûàÏäµÎãàÎã§", "ÏÑúÏà†ÎêòÏñ¥ ÏûàÏäµÎãàÎã§".
* Remove **only** result-oriented judgment expressions such as internal criteria, suitability determinations, or pass/fail statements.
* Sentences that describe a **state or condition**, such as *‚Äúinsufficient‚Äù* or *‚Äúimprovement is needed,‚Äù* are considered factual descriptions and are **allowed**.
* Merge sentences with the same meaning into one.
* Sentences may be rephrased into natural English **without changing their meaning**.
* Do **not** include advice, criteria comparisons, or design suggestions.
* If the original document contains content related to the following items, that content **must be included in the overall summary sentence*.
  ‚Ä¢ storage -> ÏàòÎÇ©Í≥µÍ∞Ñ
  ‚Ä¢ lighting -> Ï±ÑÍ¥ë
  ‚Ä¢ family_harmony -> Í∞ÄÏ°± ÏúµÌôî
* If `document_signals` are provided, all of them must be included in the first overall summary sentence using Korean labels and values.
* Do not drop value polarity. Keep positive/negative wording from `document_signals` (e.g., Ïö∞Ïàò, Ï†ÅÏ†ï, Î∂ÄÏ°±, ÎØ∏Ìù°, Î∂ÄÏ†ÅÌï©, Î∂àÌï©Í≤©).
* Prefer `display_value` for user-facing wording (e.g., Ï±ÑÍ¥ë: Ï¢ãÏùå, ÏàòÎÇ©Í≥µÍ∞Ñ: ÎÑâÎÑâÌï®).
* The overall summary must start with these two fixed lines:
  {bay_count}Bay {structure_type} Íµ¨Ï°∞ÏûÖÎãàÎã§.
  Ï±ÑÍ¥ë: {display_value}{(Í∑ºÍ±∞)}, ÌôòÍ∏∞: {display_value}{(Í∑ºÍ±∞)}, Í∞ÄÏ°± ÏúµÌôî: {display_value}, ÏàòÎÇ©Í≥µÍ∞Ñ: {display_value}{(Í∑ºÍ±∞)}ÏúºÎ°ú Ï†ïÎ¶¨Îê©ÎãàÎã§.
* Add evidence parentheses only when explicit evidence exists in the original document. If no explicit evidence exists, omit parentheses.
* Never output placeholder evidence text such as "Í∑ºÍ±∞ ÏóÜÏùå" or "ÌôïÏù∏ ÌïÑÏöî".
* In each evidence parentheses, write only concise evidence text (e.g., ÏïàÎ∞© Ïô∏Í∏∞Ï∞Ω ÎØ∏ÌôïÎ≥¥). Do not include prefixes like "Ï†ÅÌï©:" or "Î∂ÄÏ†ÅÌï©:".
* Do not repeat the same fact twice. If the same evidence appears in the summary sentence, do not repeat it in later sentences.
* The second summary sentence should include only additional non-duplicate facts that are not already stated in the first summary sentence.

**Output Format:**
* Overall summary: 1‚Äì2 sentences (describing overall spatial characteristics only)
* Followed by space-by-space descriptions
* One sentence per space
* If multiple spaces have exactly the same description, merge them into one line using slash-joined labels.
* When merged labels share the same base name, keep the base only once.
  Example: `Ïπ®Ïã§1/Ïπ®Ïã§2` -> `Ïπ®Ïã§1/2`, `Í∏∞ÌÉÄ1/Í∏∞ÌÉÄ2/Í∏∞ÌÉÄ3` -> `Í∏∞ÌÉÄ1/2/3`.
  Example: `Í∏∞ÌÉÄ1/2/3/4/5/6: Í∏∞ÌÉÄ Í≥µÍ∞ÑÏùÄ Í∏∞Îä•Ïù¥ Î™ÖÌôïÌïòÏßÄ ÏïäÏúºÎ©∞, Ï∞ΩÎ¨∏Ïù¥ ÏóÜÏñ¥ Ï±ÑÍ¥ëÏù¥ Î∂ÄÏ°±Ìï©ÎãàÎã§.`

Ï∂úÎ†• ÏòàÏãú ÌòïÏãù:
3Bay ÌåêÏÉÅÌòï Íµ¨Ï°∞ÏûÖÎãàÎã§.
Ï±ÑÍ¥ë: Î∂ÄÏ°±Ìï®(ÏïàÎ∞© Ïô∏Í∏∞Ï∞Ω ÎØ∏ÌôïÎ≥¥), ÌôòÍ∏∞: Ï¢ãÏùå(Ï£ºÎ∞© ÌôòÍ∏∞Ï∞Ω ÌôïÎ≥¥), Í∞ÄÏ°± ÏúµÌôî: Ï†ÅÌï©, ÏàòÎÇ©Í≥µÍ∞Ñ: Î∂ÄÏ°±Ìï®(ÏàòÎÇ©Í≥µÍ∞Ñ ÎπÑÏú® 10% ÎØ∏Îßå)ÏúºÎ°ú Ï†ïÎ¶¨Îê©ÎãàÎã§.
ÏïàÎ∞© Ïô∏Í∏∞Ï∞ΩÏù¥ ÏóÜÍ≥†, ÏöïÏã§ ÌôòÍ∏∞Ï∞ΩÏù¥ ÏóÜÏäµÎãàÎã§.
‚ñ† Í±∞Ïã§: Ï§ëÏïôÏóê ÏúÑÏπòÌïòÏó¨ Í∞ÄÏ°±Ïù¥ Î™®Ïùº Ïàò ÏûàÎäî Í≥µÍ∞ÑÏúºÎ°ú Ï†ÅÌï©Ìï©ÎãàÎã§.
‚ñ† Ïπ®Ïã§: Í∞úÏù∏Ï†ÅÏù∏ Í≥µÍ∞ÑÏúºÎ°ú Î∂ÑÎ¶¨ÎêòÏñ¥ Ï†ÅÏ†àÌïòÍ≤å Î∞∞ÏπòÎêòÏñ¥ ÏûàÏäµÎãàÎã§.
‚ñ† Ï£ºÎ∞©/ÏãùÎãπ: ÌôòÍ∏∞Ï∞ΩÏù¥ ÏûàÏñ¥ ÌôòÍ∏∞Í∞Ä Ïö∞ÏàòÌï©ÎãàÎã§.
‚ñ† ÌôîÏû•Ïã§: ÌôòÍ∏∞Ï∞ΩÏù¥ ÏóÜÏñ¥ ÌôòÍ∏∞ Ï∏°Î©¥ÏóêÏÑú Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.
‚ñ† Î∞úÏΩîÎãà: Ïô∏Î∂Ä Í≥µÍ∞ÑÏúºÎ°úÏùò ÌôúÏö©ÎèÑÍ∞Ä ÎÜíÏäµÎãàÎã§.
"""

        user_content = (
            f"ÏûÖÎ†• document_id:\n{document_id.strip()}\n\n"
            f"ÎèÑÎ©¥ Îç∞Ïù¥ÌÑ∞(JSON):\n{candidate_json}\n\n"
            "JSONÏùò `document_signals` Ìï≠Î™©ÏùÄ 3Î≤àÏùò Ï†ÑÏ≤¥ ÏöîÏïΩ Î¨∏Ïû•Ïóê Î∞òÎìúÏãú Î™®Îëê Î∞òÏòÅÌïòÏÑ∏Ïöî.\n"
            "Ïã†Ìò∏ Í∞íÏùÄ `display_value`Î•º Ïö∞ÏÑ† ÏÇ¨Ïö©Ìï¥ ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏúºÎ°ú ÌëúÌòÑÌïòÏÑ∏Ïöî.\n"
            "ÏöîÏïΩ ÏãúÏûëÏùÄ `NBay Íµ¨Ï°∞ÏûÖÎãàÎã§.` Îã§Ïùå Ï§Ñ `Ï±ÑÍ¥ë/ÌôòÍ∏∞/Í∞ÄÏ°± ÏúµÌôî/ÏàòÎÇ©Í≥µÍ∞Ñ` Í≥†Ï†ï ÌÖúÌîåÎ¶øÏùÑ Îî∞Î•¥ÏÑ∏Ïöî.\n"
            "`Í∑ºÍ±∞ ÏóÜÏùå`, `ÌôïÏù∏ ÌïÑÏöî` Í∞ôÏùÄ ÏûêÎ¶¨ÌëúÏãúÏûê ÌëúÌòÑÏùÄ Ï†àÎåÄ ÏÇ¨Ïö©ÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n"
            "ÏöîÏïΩ 2Î≤àÏß∏ Ï§ÑÏóêÏÑú Ïñ∏Í∏âÌïú Í∑ºÍ±∞Îäî Îã§Ïùå Î¨∏Ïû•ÏóêÏÑú Ï§ëÎ≥µÌï¥ÏÑú Î∞òÎ≥µÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n"
            "Ï∂úÎ†•ÏùÄ Î∞òÎìúÏãú 1, 2, 3Î≤à ÏÑπÏÖòÎßå Ìè¨Ìï®ÌïòÍ≥† Ï∂îÍ∞Ä Î¨∏Ïû•ÏùÑ Ï†àÎåÄ Ï∂úÎ†•ÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n"
            "Î∞òÎìúÏãú Îã®Ïùº ÎèÑÎ©¥ Í∏∞Ï§ÄÏúºÎ°úÎßå Ï∂úÎ†•ÌïòÍ≥†, "
            f"Ï≤´ Ï§ÑÏùÄ Ï†ïÌôïÌûà `1. Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: {document_id.strip()}` ÌòïÏãùÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî."
        )

        def _call_llm() -> str:
            response = self.client.chat.completions.create(
                model="gpt-5.2-2025-12-11",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.0,
            )
            return (response.choices[0].message.content or "").strip()

        return self._run_validated_generation(
            mode="document_id",
            generate_fn=_call_llm,
            expected_document_id=document_id.strip(),
        )

    def _build_filter_where_parts(self, filters: dict[str, Any]) -> tuple[str, list[Any]]:
        where_clauses = []
        params: list[Any] = []

        for column in self.ALLOWED_FILTER_COLUMNS:
            value = filters.get(column)
            if value is None:
                continue
            if column in self.FLOAT_FILTERS:
                op = value.get("op") if isinstance(value, dict) else None
                val = value.get("val") if isinstance(value, dict) else None
                where_clauses.append(f"ratio_cmp({column}::double precision, %s, %s)")
                params.extend([op, val])
            else:
                where_clauses.append(f"{column} = %s")
                params.append(value)

        where_sql = " AND ".join(where_clauses) if where_clauses else "TRUE"
        return where_sql, params

    def _retrieve_hybrid(self, query_json: dict, top_k: int = 50) -> list:
        """
        Generate embedding -> build query -> execute DB query -> return results
        """
        filters = query_json.get("filters", {}) or {}
        documents = query_json.get("documents", "") or ""
        raw_query = query_json.get("raw_query", "") or ""
        semantic_query = f"{documents} {raw_query}".strip() or raw_query or documents
        text_query = str(documents).strip() or str(raw_query).strip()

        embedding_resp = self.client.embeddings.create(
            model=self.embedding_model,
            input=semantic_query,
            dimensions=self.embedding_dimensions,
        )
        embedding = embedding_resp.data[0].embedding
        embedding_vector = "[" + ",".join(map(str, embedding)) + "]"

        where_sql, filter_params = self._build_filter_where_parts(filters)
        params = [
            embedding_vector,
            text_query,
            *filter_params,
            self.vector_weight,
            self.text_weight,
            top_k,
        ]

        sql = f"""
            WITH scored AS (
                SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
                structure_type, bay_count, room_count, bathroom_count,
                compliance_grade, ventilation_grade, has_special_space, has_etc_space,
                (1 - (embedding <=> %s::vector)) AS vector_similarity,
                ts_rank_cd(
                    to_tsvector('simple', COALESCE(document, '')),
                    websearch_to_tsquery('simple', %s)
                ) AS text_score
                FROM FP_Analysis
                WHERE {where_sql}
            )
            SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
            structure_type, bay_count, room_count, bathroom_count,
            compliance_grade, ventilation_grade, has_special_space, has_etc_space,
            (%s * vector_similarity + %s * text_score) AS similarity
            FROM scored
            ORDER BY similarity DESC
            LIMIT %s
        """

        try:
            with self.conn.cursor() as cur:
                cur.execute(sql, params)
                return cur.fetchall()
        except Exception as exc:
            if text_query:
                self._log_event(
                    event="retrieve_text_query_fallback",
                    level=logging.WARNING,
                    reason="text_query_parse_or_rank_error",
                    text_query=text_query,
                    filter_count=len(filter_params),
                    error=str(exc),
                )
                fallback_params = [
                    embedding_vector,
                    *filter_params,
                    self.vector_weight,
                    self.text_weight,
                    top_k,
                ]
                fallback_sql = f"""
                    WITH scored AS (
                        SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
                        structure_type, bay_count, room_count, bathroom_count,
                        compliance_grade, ventilation_grade, has_special_space, has_etc_space,
                        (1 - (embedding <=> %s::vector)) AS vector_similarity,
                        0.0::double precision AS text_score
                        FROM FP_Analysis
                        WHERE {where_sql}
                    )
                    SELECT document_id, document, windowless_ratio, balcony_ratio, living_room_ratio, bathroom_ratio, kitchen_ratio,
                    structure_type, bay_count, room_count, bathroom_count,
                    compliance_grade, ventilation_grade, has_special_space, has_etc_space,
                    (%s * vector_similarity + %s * text_score) AS similarity
                    FROM scored
                    ORDER BY similarity DESC
                    LIMIT %s
                """
                with self.conn.cursor() as cur:
                    cur.execute(fallback_sql, fallback_params)
                    return cur.fetchall()
            raise

    def _count_matches(self, filters: dict[str, Any], documents: str = "") -> int:
        where_sql, params = self._build_filter_where_parts(filters)

        normalized_documents = str(documents or "").strip()
        if normalized_documents:
            where_sql = (
                f"{where_sql} AND "
                "to_tsvector('simple', COALESCE(document, '')) @@ websearch_to_tsquery('simple', %s)"
            )
            params = [*params, normalized_documents]
        sql = f"SELECT COUNT(*) FROM FP_Analysis WHERE {where_sql}"
        try:
            with self.conn.cursor() as cur:
                cur.execute(sql, params)
                matched_count = int(cur.fetchone()[0])
            if normalized_documents and matched_count == 0 and filters:
                self._log_event(
                    event="count_matches_zero_text_fallback",
                    level=logging.INFO,
                    reason="strict_text_zero_match",
                    text_query=normalized_documents,
                    filter_count=len(filters),
                )
                fallback_where_sql, fallback_params = self._build_filter_where_parts(filters)
                fallback_sql = f"SELECT COUNT(*) FROM FP_Analysis WHERE {fallback_where_sql}"
                with self.conn.cursor() as cur:
                    cur.execute(fallback_sql, fallback_params)
                    return int(cur.fetchone()[0])
            return matched_count
        except Exception as exc:
            if normalized_documents:
                self._log_event(
                    event="count_matches_text_query_fallback",
                    level=logging.WARNING,
                    reason="text_query_parse_error",
                    text_query=normalized_documents,
                    error=str(exc),
                )
                fallback_where_sql, fallback_params = self._build_filter_where_parts(filters)
                fallback_sql = f"SELECT COUNT(*) FROM FP_Analysis WHERE {fallback_where_sql}"
                with self.conn.cursor() as cur:
                    cur.execute(fallback_sql, fallback_params)
                    return int(cur.fetchone()[0])
            raise

    def _generate_answer(
        self, query: str, query_json: dict, docs: list, total_match_count: int
    ) -> str:
        """
        Format retrieved docs as documents and send to the LLM to generate the answer
        """
        if not docs:
            return self._generate_validated_no_match_answer(
                total_match_count=total_match_count
            )

        filters_json = json.dumps(query_json.get("filters", {}), ensure_ascii=False, indent=2)
        retrieved_ids = [row[0] for row in docs]
        id_list_text = ", ".join(retrieved_ids)
        top_docs = docs[:3]

        representative_ids = [row[0] for row in top_docs]
        representative_title = "ÎåÄÌëú ÎèÑÎ©¥ id(ÏÉÅÏúÑ 3Í∞ú)"
        candidates = [self._row_to_candidate(row, rank) for rank, row in enumerate(top_docs, start=1)]
        candidates_json = json.dumps(candidates, ensure_ascii=False, indent=2)

        system_prompt = """You are a **specialized sLLM for architectural floor plan retrieval**.

Your role is to, for each retrieved floor plan:

1. Explain **why this floor plan was selected**,
2. Describe the **metadata of the floor plan in a neutral manner**, and
3. Summarize each floor plan‚Äôs **document content clearly and concisely**, without interpretation.

You must **never perform judgment, evaluation, recommendation, or interpretation**.

**Absolute Prohibitions**
- Do not judge the suitability, quality, or problems of the floor plan.
- Do not provide design advice or suggestions for improvement.
- Do not interpret legal regulations or permit/approval feasibility.
- Do not repeat evaluation results already present in the metadata within the document summary.

========================
Output Format (Must Be Preserved, Repeated for Each Floor Plan)
- All content must be written in Korean.
========================

Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî ÎèÑÎ©¥ Ï¥ù Í∞úÏàò: {total_count}
Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: {id_list}

Repeat the format below **for each representative floor plan**.
[ÎèÑÎ©¥ #{rank}] {document_id}

1. ÎèÑÎ©¥ ÏÑ†ÌÉù Í∑ºÍ±∞ üîç
This section outputs **only the correspondence between the user‚Äôs search conditions and the floor plan information**.

**[General Rules]**
* All item labels must be written in **Korean**.
* **Internal field names** (e.g., `bay_count`) must **never** be output.
* Do **not** abbreviate or summarize values.
* Do **not** use meta expressions such as ‚Äúrequest,‚Äù ‚Äúpreference,‚Äù or ‚Äútreated as a condition.‚Äù
* Do **not** generate any additional explanatory sentences.

**[Rules for Writing ‚ÄúSearch Conditions‚Äù]**
* ‚ÄúSearch Conditions‚Äù must list the user‚Äôs input query, refined while preserving its original meaning.
* Conditions that are not explicitly stated in the user‚Äôs query must **never** be added to ‚ÄúSearch Conditions.‚Äù

**[Rules for Generating ‚ÄúMatched Conditions‚Äù]**
* ‚ÄúMatched Conditions‚Äù must include each user-specified condition that satisfies **at least one** of the following:
  1. It can be directly verified from the floor plan metadata.
  2. An identical or semantically equivalent expression is explicitly stated in the document description.
* Conditions supported by the document may be included **even if no corresponding metadata field exists**.

* Examples of **document-based conditions**:
  ‚Ä¢ "Î∞úÏΩîÎãà ÌôúÏö© Í∞ÄÎä•" ‚Üî "Ïô∏Î∂Ä Í≥µÍ∞ÑÏúºÎ°ú ÌôúÏö©", "ÌôúÏö©ÎèÑÍ∞Ä ÎÜíÏùå"
  ‚Ä¢ "Ï£ºÎ∞© ÌôòÍ∏∞Ï∞Ω Ï°¥Ïû¨" ‚Üî "Ï£ºÎ∞©/ÏãùÎãπÏóê ÌôòÍ∏∞Ï∞ΩÏù¥ ÏûàÏùå"

Ï∂úÎ†• ÌòïÏãù(Í≥†Ï†ï):
- Ï∞æÎäî Ï°∞Í±¥: {ÏÇ¨Ïö©Ïûê Ï°∞Í±¥ÏùÑ ÌïúÍµ≠Ïñ¥ ÌëúÌòÑÏúºÎ°ú ÎÇòÏó¥}
- ÏùºÏπò Ï°∞Í±¥: {ÎèÑÎ©¥ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î∞è documentÏóêÏÑú ÌôïÏù∏Îêú ÏùºÏπò Ìï≠Î™©ÏùÑ ÌïúÍµ≠Ïñ¥ Ìï≠Î™©Î™Ö=Í∞í ÌòïÌÉúÎ°ú ÎÇòÏó¥}

2. ÎèÑÎ©¥ Í∏∞Î≥∏ Ï†ïÎ≥¥ üìä
‚ñ† Í≥µÍ∞Ñ Íµ¨ÏÑ± Ïó¨Î∂ÄÏùò Í∞íÏùÄ Îã§Ïùå ÌëúÌòÑÏúºÎ°ú Í≥†Ï†ïÌïúÎã§.
- true ‚Üí Ï°¥Ïû¨
- false ‚Üí ÏóÜÏùå

Ï∂úÎ†• ÌòïÏãù(Í≥†Ï†ï):
‚ñ† Í≥µÍ∞Ñ Í∞úÏàò
    - Î∞© Í∞úÏàò: {room_count}
    - ÌôîÏû•Ïã§ Í∞úÏàò: {bathroom_count}
    - Bay Í∞úÏàò: {bay_count}
‚ñ† Ï†ÑÏ≤¥ Î©¥Ï†Å ÎåÄÎπÑ Í≥µÍ∞Ñ ÎπÑÏú® (%)
    - Í±∞Ïã§ Í≥µÍ∞Ñ: {living_room_ratio}
    - Ï£ºÎ∞© Í≥µÍ∞Ñ: {kitchen_ratio}
    - ÏöïÏã§ Í≥µÍ∞Ñ: {bathroom_ratio}
    - Î∞úÏΩîÎãà Í≥µÍ∞Ñ: {balcony_ratio}
    - Ï∞ΩÎ¨∏Ïù¥ ÏóÜÎäî Í≥µÍ∞Ñ: {windowless_ratio}
‚ñ† Íµ¨Ï°∞ Î∞è ÏÑ±Îä•
    - Í±¥Î¨º Íµ¨Ï°∞ Ïú†Ìòï: {structure_type}
    - ÌôòÍ∏∞: {ventilation_quality}
‚ñ† Í≥µÍ∞Ñ Íµ¨ÏÑ± Ïó¨Î∂Ä
    - ÌäπÌôî Í≥µÍ∞Ñ: {has_special_space}
    - Í∏∞ÌÉÄ Í≥µÍ∞Ñ: {has_etc_space}
‚ñ† Ï¢ÖÌï© ÌèâÍ∞Ä
    - ÌèâÍ∞Ä Í≤∞Í≥º: {compliance_grade}

3. ÎèÑÎ©¥ Í≥µÍ∞Ñ Íµ¨ÏÑ± ÏÑ§Î™Ö üß©
Since the document is **internal evaluation text**,
it must be restructured into a form that is easy for users to read according to the rules below.

**Organization Rules:**
* Use **only factual information** contained in the original text.
* Remove document-meta expressions such as *‚Äúis stated,‚Äù ‚Äúis mentioned,‚Äù* or *‚Äúis described.‚Äù*
* Do not use Korean meta expressions like "Í∏∞Ïû¨ÎêòÏñ¥ ÏûàÏäµÎãàÎã§", "Ïñ∏Í∏âÎêòÏñ¥ ÏûàÏäµÎãàÎã§", "ÏÑúÏà†ÎêòÏñ¥ ÏûàÏäµÎãàÎã§".
* Remove **only** result-oriented judgment expressions such as internal criteria, suitability determinations, or pass/fail statements.
* Sentences that describe a **state or condition**, such as *‚Äúinsufficient‚Äù* or *‚Äúimprovement is needed,‚Äù* are considered factual descriptions and are **allowed**.
* Merge sentences with the same meaning into one.
* Sentences may be rephrased into natural English **without changing their meaning**.
* Do **not** include advice, criteria comparisons, or design suggestions.
* If the original document contains content related to the following items, that content **must be included in the overall summary sentence*.
  ‚Ä¢ storage -> ÏàòÎÇ©Í≥µÍ∞Ñ
  ‚Ä¢ lighting -> Ï±ÑÍ¥ë
  ‚Ä¢ family_harmony -> Í∞ÄÏ°± ÏúµÌôî
* If `document_signals` exist for each floor plan, include all of them in the first overall summary sentence for that floor plan.
* Do not drop value polarity. Keep positive/negative wording from `document_signals` (e.g., Ïö∞Ïàò, Ï†ÅÏ†ï, Î∂ÄÏ°±, ÎØ∏Ìù°, Î∂ÄÏ†ÅÌï©, Î∂àÌï©Í≤©).
* Prefer `display_value` for user-facing wording (e.g., Ï±ÑÍ¥ë: Ï¢ãÏùå, ÏàòÎÇ©Í≥µÍ∞Ñ: ÎÑâÎÑâÌï®).
* The overall summary must start with these two fixed lines:
  {bay_count}Bay {structure_type} Íµ¨Ï°∞ÏûÖÎãàÎã§.
  Ï±ÑÍ¥ë: {display_value}{(Í∑ºÍ±∞)}, ÌôòÍ∏∞: {display_value}{(Í∑ºÍ±∞)}, Í∞ÄÏ°± ÏúµÌôî: {display_value}, ÏàòÎÇ©Í≥µÍ∞Ñ: {display_value}{(Í∑ºÍ±∞)}ÏúºÎ°ú Ï†ïÎ¶¨Îê©ÎãàÎã§.
* Add evidence parentheses only when explicit evidence exists in the original document. If no explicit evidence exists, omit parentheses.
* Never output placeholder evidence text such as "Í∑ºÍ±∞ ÏóÜÏùå" or "ÌôïÏù∏ ÌïÑÏöî".
* In each evidence parentheses, write only concise evidence text (e.g., ÏïàÎ∞© Ïô∏Í∏∞Ï∞Ω ÎØ∏ÌôïÎ≥¥). Do not include prefixes like "Ï†ÅÌï©:" or "Î∂ÄÏ†ÅÌï©:".
* Do not repeat the same fact twice. If the same evidence appears in the summary sentence, do not repeat it in later sentences.
* The second summary sentence should include only additional non-duplicate facts that are not already stated in the first summary sentence.

**Output Format:**
* Overall summary: 1‚Äì2 sentences (describing overall spatial characteristics only)
* Followed by space-by-space descriptions
* One sentence per space
* If multiple spaces have exactly the same description, merge them into one line using slash-joined labels.
* When merged labels share the same base name, keep the base only once.
  Example: `Ïπ®Ïã§1/Ïπ®Ïã§2` -> `Ïπ®Ïã§1/2`, `Í∏∞ÌÉÄ1/Í∏∞ÌÉÄ2/Í∏∞ÌÉÄ3` -> `Í∏∞ÌÉÄ1/2/3`.
  Example: `Í∏∞ÌÉÄ1/2/3/4/5/6: Í∏∞ÌÉÄ Í≥µÍ∞ÑÏùÄ Í∏∞Îä•Ïù¥ Î™ÖÌôïÌïòÏßÄ ÏïäÏúºÎ©∞, Ï∞ΩÎ¨∏Ïù¥ ÏóÜÏñ¥ Ï±ÑÍ¥ëÏù¥ Î∂ÄÏ°±Ìï©ÎãàÎã§.`

Ï∂úÎ†• ÏòàÏãú ÌòïÏãù:
3Bay ÌåêÏÉÅÌòï Íµ¨Ï°∞ÏûÖÎãàÎã§.
Ï±ÑÍ¥ë: Î∂ÄÏ°±Ìï®(ÏïàÎ∞© Ïô∏Í∏∞Ï∞Ω ÎØ∏ÌôïÎ≥¥), ÌôòÍ∏∞: Ï¢ãÏùå(Ï£ºÎ∞© ÌôòÍ∏∞Ï∞Ω ÌôïÎ≥¥), Í∞ÄÏ°± ÏúµÌôî: Ï†ÅÌï©, ÏàòÎÇ©Í≥µÍ∞Ñ: Î∂ÄÏ°±Ìï®(ÏàòÎÇ©Í≥µÍ∞Ñ ÎπÑÏú® 10% ÎØ∏Îßå)ÏúºÎ°ú Ï†ïÎ¶¨Îê©ÎãàÎã§.
ÏïàÎ∞© Ïô∏Í∏∞Ï∞ΩÏù¥ ÏóÜÍ≥†, ÏöïÏã§ ÌôòÍ∏∞Ï∞ΩÏù¥ ÏóÜÏäµÎãàÎã§.
‚ñ† Í±∞Ïã§: Ï§ëÏïôÏóê ÏúÑÏπòÌïòÏó¨ Í∞ÄÏ°±Ïù¥ Î™®Ïùº Ïàò ÏûàÎäî Í≥µÍ∞ÑÏúºÎ°ú Ï†ÅÌï©Ìï©ÎãàÎã§.
‚ñ† Ïπ®Ïã§: Í∞úÏù∏Ï†ÅÏù∏ Í≥µÍ∞ÑÏúºÎ°ú Î∂ÑÎ¶¨ÎêòÏñ¥ Ï†ÅÏ†àÌïòÍ≤å Î∞∞ÏπòÎêòÏñ¥ ÏûàÏäµÎãàÎã§.
‚ñ† Ï£ºÎ∞©/ÏãùÎãπ: ÌôòÍ∏∞Ï∞ΩÏù¥ ÏûàÏñ¥ ÌôòÍ∏∞Í∞Ä Ïö∞ÏàòÌï©ÎãàÎã§.
‚ñ† ÌôîÏû•Ïã§: ÌôòÍ∏∞Ï∞ΩÏù¥ ÏóÜÏñ¥ ÌôòÍ∏∞ Ï∏°Î©¥ÏóêÏÑú Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§. 
‚ñ† Î∞úÏΩîÎãà: Ïô∏Î∂Ä Í≥µÍ∞ÑÏúºÎ°úÏùò ÌôúÏö©ÎèÑÍ∞Ä ÎÜíÏäµÎãàÎã§.
"""

        user_content = (
            f"Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id(Ï°∞Ìöå Í≤∞Í≥º Î™©Î°ù):\n{id_list_text}\n\n"
            f"{representative_title}:\n{', '.join(representative_ids)}\n\n"
            f"Ï°∞Í±¥ ÏùºÏπò Ï†ÑÏ≤¥ Í±¥Ïàò(total_count):\n{total_match_count}\n\n"
            f"ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ§Ï†ïÌïú Í≤ÄÏÉâ Ï°∞Í±¥:\n{filters_json}\n\n"
            f"ÎåÄÌëú ÎèÑÎ©¥ Îç∞Ïù¥ÌÑ∞(ÏàúÏúÑ/Î©îÌÉÄÎç∞Ïù¥ÌÑ∞/document/similarity):\n{candidates_json}\n\n"
            "Í∞Å ÎèÑÎ©¥Ïùò `document_signals`Îäî 3Î≤àÏùò Ï†ÑÏ≤¥ ÏöîÏïΩ Î¨∏Ïû•Ïóê Î∞òÎìúÏãú Î™®Îëê Î∞òÏòÅÌïòÏÑ∏Ïöî.\n\n"
            "Ïã†Ìò∏ Í∞íÏùÄ `display_value`Î•º Ïö∞ÏÑ† ÏÇ¨Ïö©Ìï¥ ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏúºÎ°ú ÌëúÌòÑÌïòÏÑ∏Ïöî.\n\n"
            "ÏöîÏïΩ ÏãúÏûëÏùÄ `NBay Íµ¨Ï°∞ÏûÖÎãàÎã§.` Îã§Ïùå Ï§Ñ `Ï±ÑÍ¥ë/ÌôòÍ∏∞/Í∞ÄÏ°± ÏúµÌôî/ÏàòÎÇ©Í≥µÍ∞Ñ` Í≥†Ï†ï ÌÖúÌîåÎ¶øÏùÑ Îî∞Î•¥ÏÑ∏Ïöî.\n\n"
            "`Í∑ºÍ±∞ ÏóÜÏùå`, `ÌôïÏù∏ ÌïÑÏöî` Í∞ôÏùÄ ÏûêÎ¶¨ÌëúÏãúÏûê ÌëúÌòÑÏùÄ Ï†àÎåÄ ÏÇ¨Ïö©ÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n\n"
            "ÏöîÏïΩ 2Î≤àÏß∏ Ï§ÑÏóêÏÑú Ïñ∏Í∏âÌïú Í∑ºÍ±∞Îäî Îã§Ïùå Î¨∏Ïû•ÏóêÏÑú Ï§ëÎ≥µÌï¥ÏÑú Î∞òÎ≥µÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n\n"
            f"ÏÇ¨Ïö©Ïûê ÏßàÏùò ÏõêÎ¨∏:\n{query}"
        )

        def _call_llm() -> str:
            response = self.client.chat.completions.create(
                model="gpt-5.2-2025-12-11",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.0,
            )
            return (response.choices[0].message.content or "").strip()

        return self._run_validated_generation(mode="general", generate_fn=_call_llm)

    def _generate_no_match_answer(self, total_match_count: int = 0) -> str:
        return (
            f"Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî ÎèÑÎ©¥ Ï¥ù Í∞úÏàò: {int(total_match_count)}\n"
            "Í≤ÄÏÉâÎêú ÎèÑÎ©¥ id: ÏóÜÏùå\n"
            "ÏöîÏ≤≠ Ï°∞Í±¥Í≥º ÏùºÏπòÌïòÎäî ÎèÑÎ©¥Ïù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§."
        )

    def _generate_validated_no_match_answer(self, total_match_count: int = 0) -> str:
        answer = self._generate_no_match_answer(total_match_count=total_match_count)
        if not self.answer_validation_enabled:
            return answer
        try:
            result = self._validate_answer_format(answer=answer, mode="no_match")
        except Exception:
            self.logger.exception("answer_validation_exception mode=no_match attempt=0")
            return answer
        if result.ok:
            self.logger.info("answer_validation_pass mode=no_match attempt=0 latency_ms=0")
            return answer
        self.logger.warning(
            "answer_validation_fail mode=no_match attempt=0 missing_fields=%s latency_ms=0",
            ",".join(result.missing_fields) or "none",
        )
        if self.answer_validation_safe_fallback:
            fallback = self._build_safe_default_answer(mode="no_match")
            self.logger.warning("answer_validation_fallback mode=no_match retries=0")
            return fallback
        return answer


# ----------------------------------------------------------------------------------------------
    def run(self, query: str) -> str:
        request_start = time.perf_counter()
        query_id = uuid.uuid4().hex[:12]
        normalized_query = query.strip()
        self._log_event(
            event="query_received",
            query_id=query_id,
            query_len=len(normalized_query),
            query_preview=normalized_query[:120],
        )
        if not normalized_query:
            self._log_event(
                event="query_completed",
                query_id=query_id,
                result="empty_query",
                latency_ms=int((time.perf_counter() - request_start) * 1000),
            )
            return "Try searching again."

        try:
            if self._is_floorplan_image_name(normalized_query):
                doc_lookup_start = time.perf_counter()
                doc = self._retrieve_by_document_id(normalized_query)
                self._log_event(
                    event="doc_lookup_complete",
                    query_id=query_id,
                    latency_ms=int((time.perf_counter() - doc_lookup_start) * 1000),
                    found=bool(doc),
                )
                if not doc:
                    answer = f"ÏöîÏ≤≠Ìïú ÎèÑÎ©¥ idÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§: {normalized_query}"
                    self._log_event(
                        event="query_completed",
                        query_id=query_id,
                        mode="document_id",
                        result="not_found",
                        latency_ms=int((time.perf_counter() - request_start) * 1000),
                    )
                    return answer
                generate_start = time.perf_counter()
                answer = self._generate_document_id_answer(normalized_query, doc)
                self._log_event(
                    event="generate_complete",
                    query_id=query_id,
                    mode="document_id",
                    latency_ms=int((time.perf_counter() - generate_start) * 1000),
                )
                self._log_event(
                    event="query_completed",
                    query_id=query_id,
                    mode="document_id",
                    result="ok",
                    latency_ms=int((time.perf_counter() - request_start) * 1000),
                )
                return answer

            analyze_start = time.perf_counter()
            query_json = self._analyze_query(normalized_query)
            self._log_event(
                event="analyze_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - analyze_start) * 1000),
                filter_count=len(query_json.get("filters", {}) or {}),
                documents_len=len(str(query_json.get("documents", "") or "")),
            )

            count_start = time.perf_counter()
            total_match_count = self._count_matches(
                query_json.get("filters", {}) or {},
                query_json.get("documents", "") or "",
            )
            self._log_event(
                event="count_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - count_start) * 1000),
                total_match_count=total_match_count,
            )
            if total_match_count <= 0:
                answer = self._generate_validated_no_match_answer(total_match_count=0)
                self._log_event(
                    event="query_completed",
                    query_id=query_id,
                    mode="general",
                    result="no_match",
                    latency_ms=int((time.perf_counter() - request_start) * 1000),
                )
                return answer
            retrieve_k = min(max(total_match_count, 3), 50)

            retrieve_start = time.perf_counter()
            docs = self._retrieve_hybrid(query_json, top_k=retrieve_k)
            self._log_event(
                event="retrieve_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - retrieve_start) * 1000),
                retrieve_k=retrieve_k,
                retrieved_count=len(docs),
            )

            rerank_start = time.perf_counter()
            docs = self._rerank_by_query_signal_preferences(docs, normalized_query)
            self._log_event(
                event="rerank_complete",
                query_id=query_id,
                latency_ms=int((time.perf_counter() - rerank_start) * 1000),
                reranked_count=len(docs),
            )

            generate_start = time.perf_counter()
            answer = self._generate_answer(
                normalized_query, query_json, docs, total_match_count
            )
            self._log_event(
                event="generate_complete",
                query_id=query_id,
                mode="general",
                latency_ms=int((time.perf_counter() - generate_start) * 1000),
            )
            self._log_event(
                event="query_completed",
                query_id=query_id,
                mode="general",
                result="ok",
                total_match_count=total_match_count,
                latency_ms=int((time.perf_counter() - request_start) * 1000),
            )
            return answer
        except Exception as exc:
            self._log_event(
                event="query_failed",
                level=logging.ERROR,
                query_id=query_id,
                error=str(exc),
                latency_ms=int((time.perf_counter() - request_start) * 1000),
            )
            raise
