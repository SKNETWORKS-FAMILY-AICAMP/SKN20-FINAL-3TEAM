# Qwen3 íŒŒì¸íŠœë‹ìš© í•™ìŠµ ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ v2

## Context

ARAE ì‹œìŠ¤í…œì€ ë„ë©´ ë¶„ì„ ì‹œ GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ topology_graph.json â†’ FloorPlanAnalysis(llm_analysis.json)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
ì´ë¥¼ ë¡œì»¬ Qwen3 ëª¨ë¸ë¡œ ëŒ€ì²´í•˜ê¸° ìœ„í•´, **Dual-Model Teacher ë°©ì‹**ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  í’ˆì§ˆ ë¹„êµ í›„ ìµœì  ë°ì´í„°ì…‹ìœ¼ë¡œ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.

**í•µì‹¬ ë³€ê²½ì‚¬í•­ (v1 ëŒ€ë¹„)**:
- 9,991ì¥ ì „ì²´ â†’ **2,000ì¥ ëŒ€í‘œ ìƒ˜í”Œ** (ëª¨ë¸ë‹¹)
- ë‹¨ì¼ ëª¨ë¸(GPT-4o-mini) â†’ **OpenAI GPT-4o + Gemini 3 Pro ë“€ì–¼ ëª¨ë¸**
- í’ˆì§ˆ ë¹„êµ í›„ ìš°ìˆ˜ ë°ì´í„°ì…‹ ì„ íƒ
- ì‹¤í–‰ í™˜ê²½ ë¶„ë¦¬: **ë¡œì»¬ GPU (Phase 0-1) + RunPod A100 (Phase 2-6)**
- ì„ë² ë”© ëª¨ë¸: OpenAI â†’ **Qwen3-Embedding-0.6B** (í•™ìŠµ-ì¶”ë¡  ì¼ê´€ì„±)
- Qwen3 íŒŒì¸íŠœë‹ ë‹¨ê³„ í†µí•© (Phase 6)

## ì „ëµ

```
=== ë¡œì»¬ í™˜ê²½ (Phase 0-1) ===
Phase 0: ë°ì´í„° ìƒ˜í”Œë§ (ë¡œì»¬ CPU, ~1ë¶„)
  9,991ì¥ ì¤‘ 2,000ì¥ ëŒ€í‘œ ìƒ˜í”Œ ì„ ì • â†’ sampled_images.json

Phase 1: CV ì¶”ë¡  (ë¡œì»¬ GPU, ~6-12ì‹œê°„)
  2,000ì¥ â†’ InferencePipeline â†’ topology_graph.json

Phase 1.5: RunPod ì—…ë¡œë“œ (~10-30ë¶„)
  sampled_images.json + topology_graph.json 2,000ê°œ â†’ RunPod Volume

=== RunPod A100 í™˜ê²½ (Phase 2-6) ===
Phase 2: RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± (A100 GPU, ~15ì´ˆ)
  ì‚¬ë‚´_í‰ê°€_ë¬¸ì„œ 15ê°œ chunk â†’ Qwen3-Embedding-0.6B (768ì°¨ì›) â†’ cosine similarity â†’ rag_context

Phase 3A: OpenAI GPT-4o ë¼ë²¨ë§ (API, ~4-8ì‹œê°„, ~$40-60)
  topology + rag_context â†’ GPT-4o â†’ llm_analysis_openai.json (2,000ê°œ)

Phase 3B: Gemini 3 Pro ë¼ë²¨ë§ (API, ~4-8ì‹œê°„, ~$15-30)
  topology + rag_context â†’ Gemini 3 Pro â†’ llm_analysis_gemini.json (2,000ê°œ)

Phase 4: í’ˆì§ˆ ë¹„êµ í‰ê°€ (~30ë¶„)
  100ê°œ ìƒ˜í”Œ ìë™ + ìˆ˜ë™ í‰ê°€ â†’ ìµœì  ë°ì´í„°ì…‹ ì„ íƒ

Phase 5: JSONL ë³€í™˜ (~2ë¶„)
  ì„ íƒëœ ë°ì´í„°ì…‹ â†’ train.jsonl (90%) + val.jsonl (10%)

Phase 6: Qwen3 íŒŒì¸íŠœë‹ (RunPod A100, ~2-4ì‹œê°„)
  Unsloth + LoRAë¡œ Qwen3-8B íŒŒì¸íŠœë‹ â†’ ëª¨ë¸ ì €ì¥
```

## íŒŒì¼ êµ¬ì¡°

```
python/CV/llm_finetuning/              # ì‹ ê·œ ìƒì„±
â”œâ”€â”€ config.py                          # í†µí•© ì„¤ì • (ê²½ë¡œ, ëª¨ë¸, API í‚¤)
â”œâ”€â”€ step0_sample_images.py             # Phase 0: ëŒ€í‘œ ìƒ˜í”Œ 2,000ì¥ ì„ ì •
â”œâ”€â”€ step1_cv_batch.py                  # Phase 1: CV ë°°ì¹˜ ì¶”ë¡ 
â”œâ”€â”€ step2_rag_context.py               # Phase 2: RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±
â”œâ”€â”€ step3a_openai_labeling.py          # Phase 3A: OpenAI GPT-4o ë¼ë²¨ë§
â”œâ”€â”€ step3b_gemini_labeling.py          # Phase 3B: Gemini 3 Pro ë¼ë²¨ë§
â”œâ”€â”€ step4_quality_compare.py           # Phase 4: í’ˆì§ˆ ë¹„êµ í‰ê°€
â”œâ”€â”€ step5_build_jsonl.py               # Phase 5: JSONL ë³€í™˜
â”œâ”€â”€ step6_qwen3_finetune.py            # Phase 6: Qwen3 íŒŒì¸íŠœë‹
â”œâ”€â”€ run_all.py                         # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (ë‹¨ê³„ë³„/ì „ì²´ ì‹¤í–‰)
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ progress_tracker.py            # ì¤‘ë‹¨/ì¬ê°œ ì§€ì›
    â”œâ”€â”€ local_vector_search.py         # numpy ê¸°ë°˜ ë¡œì»¬ ë²¡í„° ê²€ìƒ‰
    â”œâ”€â”€ retry.py                       # API ì¬ì‹œë„ (exponential backoff)
    â””â”€â”€ quality_metrics.py             # í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜
```

ì¶œë ¥ ë””ë ‰í† ë¦¬:
```
python/training_data/                  # ì‹ ê·œ ìƒì„±
â”œâ”€â”€ progress/                          # ë‹¨ê³„ë³„ ì§„í–‰ë¥  JSON
â”œâ”€â”€ sampled_images.json                # ì„ ì •ëœ 2,000ì¥ ì´ë¯¸ì§€ ëª©ë¡
â”œâ”€â”€ output/{image_stem}/               # ì´ë¯¸ì§€ë³„ ì¤‘ê°„ ì‚°ì¶œë¬¼
â”‚   â”œâ”€â”€ topology_graph.json            # Phase 1
â”‚   â”œâ”€â”€ rag_context.json               # Phase 2
â”‚   â”œâ”€â”€ llm_analysis_openai.json       # Phase 3A
â”‚   â””â”€â”€ llm_analysis_gemini.json       # Phase 3B
â”œâ”€â”€ embedding_cache.npy                # chunk ì„ë² ë”© ìºì‹œ
â”œâ”€â”€ quality_report.json                # Phase 4 í’ˆì§ˆ ë¹„êµ ë¦¬í¬íŠ¸
â”œâ”€â”€ selected_model.txt                 # ì„ íƒëœ ëª¨ë¸ ("openai" ë˜ëŠ” "gemini")
â”œâ”€â”€ train.jsonl                        # ìµœì¢… í•™ìŠµ ë°ì´í„°
â”œâ”€â”€ val.jsonl                          # ìµœì¢… ê²€ì¦ ë°ì´í„°
â”œâ”€â”€ stats_report.json                  # í†µê³„ ë¦¬í¬íŠ¸
â””â”€â”€ qwen3_finetuned/                   # Phase 6 ëª¨ë¸ ì¶œë ¥
    â”œâ”€â”€ adapter_model/                 # LoRA ì–´ëŒ‘í„°
    â””â”€â”€ merged_model/                  # ë¨¸ì§€ëœ ì „ì²´ ëª¨ë¸ (ì„ íƒì‚¬í•­)
```

---

## ìƒì„¸ êµ¬í˜„ ê³„íš

### 0. `CV/llm_finetuning/config.py` - í†µí•© ì„¤ì •

```python
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

@dataclass(frozen=True)
class PipelineConfig:
    # === ê²½ë¡œ ì„¤ì • (RunPod í™˜ê²½) ===
    IMAGE_DIR: Path = Path("/workspace/data/APT_FP_Cleaned/training")
    OUTPUT_DIR: Path = Path("/workspace/training_data/output")
    RAG_DOC_PATH: Path = Path("/workspace/python/CV/rag_data/ì‚¬ë‚´_í‰ê°€_ë¬¸ì„œ.json")
    PROJECT_ROOT: Path = Path("/workspace/python")

    # === ìƒ˜í”Œë§ ì„¤ì • ===
    TOTAL_IMAGES: int = 9991
    SAMPLE_SIZE: int = 2000
    RANDOM_SEED: int = 42
    STRATIFY_BY: str = "filename_prefix"  # íŒŒì¼ëª… ì ‘ë‘ì‚¬ë¡œ ì¸µí™” ìƒ˜í”Œë§

    # === CV ì¶”ë¡  ì„¤ì • (ë¡œì»¬ GPU) ===
    SAVE_VISUALIZATION: bool = False
    CUDA_CACHE_CLEAR_INTERVAL: int = 50  # ë§¤ 50ê±´ë§ˆë‹¤ ìºì‹œ ì •ë¦¬

    # === RAG ì„ë² ë”© ì„¤ì • (Qwen3-Embedding) ===
    EMBEDDING_MODEL: str = "Qwen/Qwen3-Embedding-0.6B"
    EMBEDDING_DIM: int = 768              # 768 ë˜ëŠ” 1024 (768 ê¶Œì¥)
    EMBEDDING_BATCH_SIZE: int = 32
    EMBEDDING_MAX_LENGTH: int = 512
    TOP_K: int = 5

    # === OpenAI API ì„¤ì • ===
    OPENAI_API_KEY: Optional[str] = None  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
    OPENAI_MODEL: str = "gpt-4o"          # ìµœê³  í’ˆì§ˆ ëª¨ë¸
    OPENAI_TEMPERATURE: float = 0.1
    OPENAI_MAX_RETRIES: int = 3
    OPENAI_CONCURRENT_REQUESTS: int = 5   # ë™ì‹œ ìš”ì²­ ìˆ˜

    # === Gemini API ì„¤ì • ===
    GOOGLE_API_KEY: Optional[str] = None  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
    GEMINI_MODEL: str = "gemini-3-pro"    # Gemini 3 Pro
    GEMINI_TEMPERATURE: float = 0.1
    GEMINI_MAX_RETRIES: int = 3
    GEMINI_CONCURRENT_REQUESTS: int = 5

    # === í’ˆì§ˆ ë¹„êµ ì„¤ì • ===
    QUALITY_SAMPLE_SIZE: int = 100        # í’ˆì§ˆ ë¹„êµìš© ìƒ˜í”Œ ìˆ˜
    MIN_SCHEMA_COMPLIANCE: float = 0.95   # ìµœì†Œ ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ìœ¨

    # === JSONL ì„¤ì • ===
    TRAIN_RATIO: float = 0.9

    # === Qwen3 íŒŒì¸íŠœë‹ ì„¤ì • ===
    QWEN3_BASE_MODEL: str = "Qwen/Qwen3-8B"
    LORA_R: int = 64
    LORA_ALPHA: int = 128
    LORA_DROPOUT: float = 0.05
    LEARNING_RATE: float = 2e-4
    NUM_EPOCHS: int = 3
    BATCH_SIZE: int = 2                   # A100 80GB ê¸°ì¤€
    GRADIENT_ACCUMULATION: int = 8        # effective batch = 16
    MAX_SEQ_LENGTH: int = 4096
    WARMUP_RATIO: float = 0.03
    SAVE_STEPS: int = 100
    LOGGING_STEPS: int = 10
```

### 1. `CV/llm_finetuning/step0_sample_images.py` - ëŒ€í‘œ ìƒ˜í”Œ 2,000ì¥ ì„ ì •

**ëª©ì **: 9,991ì¥ì—ì„œ ë‹¤ì–‘ì„±ì„ ë³´ì¥í•˜ëŠ” 2,000ì¥ ì„ ì •

**ë¡œì§**:
- íŒŒì¼ëª… ì ‘ë‘ì‚¬ ê¸°ë°˜ ì¸µí™” ìƒ˜í”Œë§ (ì•„íŒŒíŠ¸ ë‹¨ì§€/ë™ë³„ ê· ë“± ë¶„í¬)
- íŒŒì¼ í¬ê¸° ë¶„í¬ ìœ ì§€ (ê·¹ë‹¨ì  í¬ê¸° ì œì™¸)
- ê²°ê³¼ë¥¼ `sampled_images.json`ì— ì €ì¥ (ì¬í˜„ ê°€ëŠ¥)

```python
def sample_images(config: PipelineConfig) -> List[Path]:
    """
    ì¸µí™” ìƒ˜í”Œë§ìœ¼ë¡œ 2,000ì¥ ì„ ì •

    ì „ëµ:
    1. íŒŒì¼ëª… ì ‘ë‘ì‚¬(ì•„íŒŒíŠ¸ ë‹¨ì§€)ë³„ ê·¸ë£¹í™”
    2. ê° ê·¸ë£¹ì—ì„œ ë¹„ë¡€ í• ë‹¹
    3. ê·¸ë£¹ ìˆ˜ < ë¹„ë¡€ í• ë‹¹ë¶„ì¸ ê²½ìš° ì „ìˆ˜ í¬í•¨
    4. ì”ì—¬ë¶„ì€ ê°€ì¥ í° ê·¸ë£¹ì—ì„œ ëœë¤ ì¶”ì¶œ
    """
    all_images = sorted(config.IMAGE_DIR.glob("*.PNG"))
    # ... ì¸µí™” ìƒ˜í”Œë§ ë¡œì§
    # ê²°ê³¼ë¥¼ sampled_images.jsonì— ì €ì¥
    return sampled_images
```

### 2. `CV/llm_finetuning/step1_cv_batch.py` - CV ë°°ì¹˜ ì¶”ë¡  (ë¡œì»¬ GPU)

**ì‹¤í–‰ í™˜ê²½**: ë¡œì»¬ GPU (RTX 3090, 4090, A6000 ë“±)

**ë¡œì§**:
- ê¸°ì¡´ `InferencePipeline` ì¬ì‚¬ìš© (`python/CV/cv_inference/pipeline.py`)
- `save_visualization=False`ë¡œ ì‹œê°í™” ê±´ë„ˆë›°ê¸° (ì†ë„ 2-3ë°° í–¥ìƒ)
- ì¤‘ë‹¨/ì¬ê°œ: `progress/cv_batch_progress.json`ì— ì™„ë£Œ ëª©ë¡ ê´€ë¦¬
- ë§¤ 50ê±´ë§ˆë‹¤ `torch.cuda.empty_cache()` í˜¸ì¶œ
- ì‹¤íŒ¨ ì´ë¯¸ì§€ëŠ” `failed_images` ëª©ë¡ì— ê¸°ë¡ í›„ continue
- topology_graph.jsonë§Œ `training_data/output/{stem}/`ì— ì €ì¥
- **2,000ì¥ ëŒ€ìƒ** (sampled_images.json ì°¸ì¡°)

**GPU ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­**:
- RTX 3090 (24GB): ë°°ì¹˜ í¬ê¸° 1, ë©”ëª¨ë¦¬ ì‚¬ìš© ~18-20GB
- RTX 4090 (24GB): ë°°ì¹˜ í¬ê¸° 1, ë©”ëª¨ë¦¬ ì‚¬ìš© ~18-20GB
- A6000 (48GB): ë°°ì¹˜ í¬ê¸° 2 ê°€ëŠ¥

**ì˜ˆìƒ ì‹œê°„** (ë¡œì»¬ GPU ê¸°ì¤€):
- RTX 3090/4090: ~6-12ì‹œê°„ (ì´ë¯¸ì§€ë‹¹ ~10-20ì´ˆ)
- A6000: ~4-8ì‹œê°„ (ì´ë¯¸ì§€ë‹¹ ~7-15ì´ˆ)

**ì•¼ê°„ ì‹¤í–‰ ê¶Œì¥**:
```bash
# tmux ì„¸ì…˜ì—ì„œ ì‹¤í–‰
tmux new-session -s cv_batch
python CV/llm_finetuning/step1_cv_batch.py
# Ctrl+B, Dë¡œ detach
```

### 3. `CV/llm_finetuning/step2_rag_context.py` - RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±

**í•µì‹¬ ë³€ê²½**: OpenAI embedding â†’ **Qwen3-Embedding-0.6B** (í•™ìŠµ-ì¶”ë¡  ì¼ê´€ì„± í™•ë³´)

**ë¡œì§**:
- `ì‚¬ë‚´_í‰ê°€_ë¬¸ì„œ.json`ì˜ 15ê°œ chunk ë¡œë“œ
- **Qwen3-Embedding-0.6B**ë¡œ 1íšŒ ì„ë² ë”© â†’ `embedding_cache.npy` ìºì‹œ (768ì°¨ì›)
- 2,000ê°œ topologyë³„ ì¿¼ë¦¬ ìƒì„± â†’ numpy cosine similarity â†’ TOP_K=5
- `rag_context.json` ì €ì¥

**í•µì‹¬ êµ¬í˜„**:
```python
from transformers import AutoModel, AutoTokenizer
import torch
import torch.nn.functional as F
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class Qwen3EmbeddingManager:
    """Qwen3-Embedding-0.6B ì„ë² ë”© ë§¤ë‹ˆì € (768ì°¨ì›)"""

    def __init__(self, model_name: str = "Qwen/Qwen3-Embedding-0.6B"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        self.model.eval()

    def embed_text(self, text: str) -> np.ndarray:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        with torch.no_grad():
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=512
            ).to(self.device)

            outputs = self.model(**inputs)
            # Mean pooling
            embeddings = outputs.last_hidden_state.mean(dim=1)
            embeddings = F.normalize(embeddings, p=2, dim=1)

            return embeddings.cpu().numpy()[0]

    def embed_batch(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """ë°°ì¹˜ ì„ë² ë”© (íš¨ìœ¨ì )"""
        all_embeddings = []

        for i in tqdm(range(0, len(texts), batch_size), desc="ì„ë² ë”© ìƒì„±"):
            batch_texts = texts[i:i+batch_size]

            with torch.no_grad():
                inputs = self.tokenizer(
                    batch_texts,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=512
                ).to(self.device)

                outputs = self.model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
                embeddings = F.normalize(embeddings, p=2, dim=1)

                all_embeddings.append(embeddings.cpu().numpy())

        return np.vstack(all_embeddings)

def run_rag_context_generation(config: PipelineConfig):
    """2,000ê°œ topologyì— ëŒ€í•´ RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""

    print("=" * 60)
    print("Phase 2: RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± (Qwen3-Embedding-0.6B)")
    print("=" * 60)

    # 1. ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™”
    embedding_mgr = Qwen3EmbeddingManager(model_name=config.EMBEDDING_MODEL)
    print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {config.EMBEDDING_MODEL} (ì°¨ì›: {config.EMBEDDING_DIM})")

    # 2. ì‚¬ë‚´ ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© (1íšŒë§Œ)
    cache_path = config.OUTPUT_DIR.parent / "embedding_cache.npy"
    doc_metadata_path = config.OUTPUT_DIR.parent / "doc_metadata.json"

    if cache_path.exists() and doc_metadata_path.exists():
        print("ğŸ“¦ ìºì‹œëœ ì„ë² ë”© ë¡œë“œ ì¤‘...")
        chunk_embeddings = np.load(cache_path)
        chunks = json.loads(doc_metadata_path.read_text(encoding='utf-8'))
        print(f"âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(chunks)}ê°œ chunk")
    else:
        print("ğŸ“„ ì‚¬ë‚´ í‰ê°€ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
        chunks = load_internal_eval_docs(config.RAG_DOC_PATH)  # 15ê°œ chunk
        print(f"âœ… {len(chunks)}ê°œ chunk ë¡œë“œ ì™„ë£Œ")

        print("ğŸ”„ Qwen3-Embeddingìœ¼ë¡œ ì„ë² ë”© ìƒì„± ì¤‘...")
        chunk_texts = [c['content'] for c in chunks]
        chunk_embeddings = embedding_mgr.embed_batch(
            chunk_texts,
            batch_size=config.EMBEDDING_BATCH_SIZE
        )

        # ìºì‹œ ì €ì¥
        np.save(cache_path, chunk_embeddings)
        doc_metadata_path.write_text(
            json.dumps(chunks, ensure_ascii=False, indent=2),
            encoding='utf-8'
        )
        print(f"âœ… ì„ë² ë”© ìºì‹œ ì €ì¥: {cache_path}")
        print(f"   Shape: {chunk_embeddings.shape}")

    # 3. sampled_images.json ë¡œë“œ
    sampled_images_path = config.OUTPUT_DIR.parent / "sampled_images.json"
    sampled_images = json.loads(sampled_images_path.read_text())
    print(f"âœ… {len(sampled_images)}ê°œ ì´ë¯¸ì§€ì— ëŒ€í•´ RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")

    # 4. ê° topologyë³„ RAG ê²€ìƒ‰
    success_count = 0
    failed_count = 0

    for image_stem in tqdm(sampled_images, desc="RAG ê²€ìƒ‰"):
        try:
            topology_path = config.OUTPUT_DIR / image_stem / "topology_graph.json"
            if not topology_path.exists():
                failed_count += 1
                continue

            topology = json.loads(topology_path.read_text(encoding='utf-8'))

            # ì¿¼ë¦¬ ìƒì„±
            stats = topology.get('statistics', {})
            query_text = (
                f"{stats.get('structure_type', 'í˜¼í•©í˜•')} ê±´ì¶•ë¬¼ "
                f"{stats.get('bay_count', 0)}Bay "
                f"ì¹¨ì‹¤ {stats.get('room_count', 0)}ê°œ"
            )

            # ì¿¼ë¦¬ ì„ë² ë”©
            query_emb = embedding_mgr.embed_text(query_text)

            # Cosine similarity ê³„ì‚°
            similarities = cosine_similarity([query_emb], chunk_embeddings)[0]
            top_k_idx = np.argsort(similarities)[-config.TOP_K:][::-1]

            # RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            rag_context = {
                "query": query_text,
                "retrieved_chunks": [
                    {
                        "rank": i+1,
                        "content": chunks[idx]['content'],
                        "similarity": float(similarities[idx]),
                        "source": chunks[idx].get('source', 'unknown')
                    }
                    for i, idx in enumerate(top_k_idx)
                ]
            }

            # ì €ì¥
            rag_path = config.OUTPUT_DIR / image_stem / "rag_context.json"
            rag_path.parent.mkdir(parents=True, exist_ok=True)
            rag_path.write_text(
                json.dumps(rag_context, ensure_ascii=False, indent=2),
                encoding='utf-8'
            )

            success_count += 1

        except Exception as e:
            print(f"âš ï¸  {image_stem} ì‹¤íŒ¨: {e}")
            failed_count += 1

    print("\n" + "=" * 60)
    print(f"âœ… RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"   ì„±ê³µ: {success_count}ê°œ")
    print(f"   ì‹¤íŒ¨: {failed_count}ê°œ")
    print("=" * 60)

def load_internal_eval_docs(doc_path: Path) -> List[dict]:
    """ì‚¬ë‚´_í‰ê°€_ë¬¸ì„œ.json ë¡œë“œ"""
    data = json.loads(doc_path.read_text(encoding='utf-8'))
    # 15ê°œ chunkë¡œ êµ¬ì¡°í™” (ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
    return data.get('chunks', data)
```

**ì˜ˆìƒ ì‹œê°„** (A100 ê¸°ì¤€):
- 15ê°œ chunk ì„ë² ë”©: **~0.5ì´ˆ** (1íšŒë§Œ)
- 2,000ê°œ ì¿¼ë¦¬ ì„ë² ë”©: **~10ì´ˆ** (batch=32)
- 2,000ê°œ ê²€ìƒ‰ (numpy): **~3ì´ˆ**
- **ì´: ~15ì´ˆ** (ê¸°ì¡´ 5ë¶„ â†’ 20ë°° ë‹¨ì¶•!)

**ë©”ëª¨ë¦¬ ì‚¬ìš©** (A100 80GB ê¸°ì¤€):
- Qwen3-Embedding-0.6B: **~1.2GB**
- ì„ë² ë”© ìºì‹œ (15 + 2000) Ã— 768 Ã— 4bytes: **~6MB**
- **ì´: ~1.5GB** (ë§¤ìš° ì—¬ìœ )

### 4. `CV/llm_finetuning/step3a_openai_labeling.py` - OpenAI GPT-4o ë¼ë²¨ë§

**ëª¨ë¸ ì„ íƒ ê·¼ê±°**: GPT-4oëŠ” GPT-4o-mini ëŒ€ë¹„ ~3ë°° ë¹„ì‹¸ì§€ë§Œ êµ¬ì¡°í™” ì¶œë ¥ í’ˆì§ˆì´ í˜„ì €íˆ ë†’ìŒ. 2,000ê°œë¡œ ìˆ˜ëŸ‰ì„ ì¤„ì˜€ìœ¼ë¯€ë¡œ ë¹„ìš© í—ˆìš© ë²”ìœ„.

**í•µì‹¬ êµ¬í˜„**:
```python
class OpenAILabeler:
    def __init__(self, config: PipelineConfig):
        self.client = OpenAI(api_key=config.OPENAI_API_KEY)
        self.model = config.OPENAI_MODEL  # "gpt-4o"

    async def label_single(self, topology_data: dict, rag_context: str) -> FloorPlanAnalysis:
        """
        ë‹¨ì¼ topologyì— ëŒ€í•´ GPT-4oë¡œ FloorPlanAnalysis ìƒì„±

        ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©:
        - SYSTEM_PROMPT (python/CV/rag_system/prompts.py)
        - build_analysis_prompt() (python/CV/rag_system/prompts.py)
        - FloorPlanAnalysis (python/CV/rag_system/schemas.py)
        """
        prompt = build_analysis_prompt(topology_data, rag_context)
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ]

        response = self.client.beta.chat.completions.parse(
            model=self.model,
            messages=messages,
            response_format=FloorPlanAnalysis,
            temperature=0.1
        )
        return response.choices[0].message.parsed

    async def label_batch(self, items: List[dict]) -> List[FloorPlanAnalysis]:
        """
        asyncio.Semaphoreë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (5ê°œ)
        ì¬ì‹œë„: exponential backoff (2â†’4â†’8ì´ˆ), 429 ì‹œ 60ì´ˆ ëŒ€ê¸°
        """
```

**ë¹„ìš© ì¶”ì •**:
- ì…ë ¥: topology(~1.5K tokens) + rag_context(~1K tokens) + system_prompt(~500 tokens) = ~3K tokens
- ì¶œë ¥: FloorPlanAnalysis JSON ~1.5K tokens
- GPT-4o: ì…ë ¥ $2.50/1M, ì¶œë ¥ $10.00/1M
- 2,000ê±´: (3K * 2000 * $2.50 + 1.5K * 2000 * $10.00) / 1M = **~$45**

### 5. `CV/llm_finetuning/step3b_gemini_labeling.py` - Gemini 3 Pro ë¼ë²¨ë§

**í•µì‹¬ ì°¨ì´ì **:
- Google AI SDK (`google-generativeai`) ì‚¬ìš©
- Gemini 3 ProëŠ” `response_schema` íŒŒë¼ë¯¸í„°ë¡œ êµ¬ì¡°í™” ì¶œë ¥ ì§€ì›
- Pydantic ìŠ¤í‚¤ë§ˆë¥¼ JSON Schemaë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
- í”„ë¡¬í”„íŠ¸ëŠ” OpenAIì™€ **ë™ì¼** (ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´)

**í•µì‹¬ êµ¬í˜„**:
```python
import google.generativeai as genai

class GeminiLabeler:
    def __init__(self, config: PipelineConfig):
        genai.configure(api_key=config.GOOGLE_API_KEY)
        self.model = genai.GenerativeModel(
            model_name=config.GEMINI_MODEL,  # "gemini-3-pro"
            generation_config=genai.GenerationConfig(
                temperature=0.1,
                response_mime_type="application/json",
                response_schema=self._build_schema()
            )
        )

    def _build_schema(self) -> dict:
        """FloorPlanAnalysis Pydantic ìŠ¤í‚¤ë§ˆ â†’ Gemini JSON Schema ë³€í™˜"""
        return FloorPlanAnalysis.model_json_schema()

    async def label_single(self, topology_data: dict, rag_context: str) -> FloorPlanAnalysis:
        """
        ë™ì¼í•œ SYSTEM_PROMPT + build_analysis_prompt() ì‚¬ìš©
        Gemini 3 Pro APIë¡œ êµ¬ì¡°í™” ì¶œë ¥ ìƒì„±
        """
        prompt = build_analysis_prompt(topology_data, rag_context)
        full_prompt = f"{SYSTEM_PROMPT}\n\n{prompt}"

        response = self.model.generate_content(full_prompt)
        result_dict = json.loads(response.text)
        return FloorPlanAnalysis(**result_dict)

    async def label_batch(self, items: List[dict]) -> List[FloorPlanAnalysis]:
        """
        asyncio.Semaphoreë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (5ê°œ)
        Gemini API rate limit ëŒ€ì‘
        """
```

**ë¹„ìš© ì¶”ì •**:
- Gemini 3 Pro: ê°€ê²©ì€ ê³µê°œëœ ì‹œì ì˜ ìµœì‹  ìš”ê¸ˆ ì°¸ì¡°
- ì˜ˆìƒ: ì…ë ¥ ~$1-2/1M, ì¶œë ¥ ~$5-10/1M
- 2,000ê±´ ì˜ˆìƒ: **~$20-40**

### 6. `CV/llm_finetuning/step4_quality_compare.py` - í’ˆì§ˆ ë¹„êµ í‰ê°€

**í‰ê°€ ë°©ë²•ë¡ **: 100ê°œ ëœë¤ ìƒ˜í”Œì— ëŒ€í•´ ìë™ + ìˆ˜ë™ í‰ê°€

**ìë™ í‰ê°€ ë©”íŠ¸ë¦­** (8ê°œ):

| ë©”íŠ¸ë¦­ | ì„¤ëª… | ì¸¡ì • ë°©ë²• |
|--------|------|----------|
| schema_compliance | Pydantic ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ìœ¨ | FloorPlanAnalysis íŒŒì‹± ì„±ê³µë¥  |
| field_completeness | í•„ìˆ˜ í•„ë“œ ì™„ì„±ë¥  | None/ë¹ˆê°’ì´ ì•„ë‹Œ í•„ë“œ ë¹„ìœ¨ |
| space_count_accuracy | ê³µê°„ ìˆ˜ ì •í•©ì„± | topologyì˜ nodes ìˆ˜ì™€ spaces ìˆ˜ ë¹„êµ |
| bay_count_consistency | Bay ìˆ˜ ì¼ê´€ì„± | topology í†µê³„ì™€ ë¶„ì„ ê²°ê³¼ ì¼ì¹˜ ì—¬ë¶€ |
| compliance_reasoning | ì í•©ì„± í‰ê°€ ë…¼ë¦¬ì„± | compliant_items + non_compliant_items ìˆ˜ > 0 |
| analysis_depth | ë¶„ì„ ê¹Šì´ | spaces[].evaluation_comment í‰ê·  ê¸¸ì´ |
| recommendation_quality | ê°œì„  ì œì•ˆ í’ˆì§ˆ | recommendations ìˆ˜ ë° êµ¬ì²´ì„± (ê¸¸ì´) |
| json_validity | JSON ìœ íš¨ì„± | íŒŒì‹± ì˜¤ë¥˜ ì—†ëŠ” ë¹„ìœ¨ |

**ë¹„êµ ì•Œê³ ë¦¬ì¦˜**:
```python
def compare_quality(openai_results: List, gemini_results: List, sample_ids: List[str]) -> QualityReport:
    """
    100ê°œ ìƒ˜í”Œì— ëŒ€í•´ 8ê°œ ë©”íŠ¸ë¦­ìœ¼ë¡œ ë¹„êµ

    ë°˜í™˜:
    - ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ (OpenAI vs Gemini)
    - ê°€ì¤‘ í‰ê·  ì¢…í•© ì ìˆ˜
    - ìŠ¹ì ê²°ì • (ì°¨ì´ê°€ 5% ì´ë‚´ë©´ ë¹„ìš© íš¨ìœ¨ ë†’ì€ ìª½ ì„ íƒ)
    """
    metrics = {}
    for metric_fn in [schema_compliance, field_completeness, space_count_accuracy,
                      bay_count_consistency, compliance_reasoning, analysis_depth,
                      recommendation_quality, json_validity]:
        openai_score = metric_fn(openai_results, sample_ids)
        gemini_score = metric_fn(gemini_results, sample_ids)
        metrics[metric_fn.__name__] = {
            "openai": openai_score,
            "gemini": gemini_score
        }

    # ê°€ì¤‘ í‰ê·  (schema_compliance 30%, field_completeness 20%, ë‚˜ë¨¸ì§€ ê° ~7%)
    weights = {
        "schema_compliance": 0.30,
        "field_completeness": 0.20,
        "space_count_accuracy": 0.10,
        "bay_count_consistency": 0.10,
        "compliance_reasoning": 0.10,
        "analysis_depth": 0.07,
        "recommendation_quality": 0.06,
        "json_validity": 0.07
    }

    openai_total = sum(metrics[k]["openai"] * w for k, w in weights.items())
    gemini_total = sum(metrics[k]["gemini"] * w for k, w in weights.items())

    # 5% ì´ë‚´ ì°¨ì´ â†’ ë¹„ìš© íš¨ìœ¨ ë†’ì€ ìª½ ì„ íƒ
    if abs(openai_total - gemini_total) < 0.05:
        winner = "gemini"  # ë¹„ìš© íš¨ìœ¨
    else:
        winner = "openai" if openai_total > gemini_total else "gemini"

    return QualityReport(metrics=metrics, winner=winner, ...)
```

**ì¶œë ¥**: `quality_report.json` + `selected_model.txt`

### 7. `CV/llm_finetuning/step5_build_jsonl.py` - JSONL ë³€í™˜

ì„ íƒëœ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜:

```jsonl
{
  "messages": [
    {"role": "system", "content": "<SYSTEM_PROMPT>"},
    {"role": "user", "content": "<build_analysis_prompt(topology, rag_context)>"},
    {"role": "assistant", "content": "<llm_analysis JSON>"}
  ]
}
```

- `selected_model.txt`ì—ì„œ ì„ íƒëœ ëª¨ë¸ í™•ì¸
- í•´ë‹¹ ëª¨ë¸ì˜ llm_analysis íŒŒì¼ë§Œ ìˆ˜ì§‘
- 3ê°œ íŒŒì¼(topology, rag_context, llm_analysis) ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ë§Œ ìˆ˜ì§‘
- FloorPlanAnalysis ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦
- ì…”í”Œ + train/val ë¶„í•  (90:10, seed=42)
- í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±

### 8. `CV/llm_finetuning/step6_qwen3_finetune.py` - Qwen3 íŒŒì¸íŠœë‹

**RunPod A100 80GB í™˜ê²½ì—ì„œ ì‹¤í–‰**

**í”„ë ˆì„ì›Œí¬**: Unsloth (LoRA ìµœì í™”, 2ë°° ë¹ ë¥¸ í•™ìŠµ, ë©”ëª¨ë¦¬ 60% ì ˆê°)

```python
from unsloth import FastLanguageModel
from trl import SFTTrainer
from transformers import TrainingArguments
from datasets import load_dataset

def run_finetune(config: PipelineConfig):
    # 1. ëª¨ë¸ ë¡œë“œ (4-bit ì–‘ìí™” + LoRA)
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=config.QWEN3_BASE_MODEL,  # "Qwen/Qwen3-8B"
        max_seq_length=config.MAX_SEQ_LENGTH,  # 4096
        load_in_4bit=True,
        dtype=None,  # auto-detect
    )

    # 2. LoRA ì–´ëŒ‘í„° ì¶”ê°€
    model = FastLanguageModel.get_peft_model(
        model,
        r=config.LORA_R,                      # 64
        lora_alpha=config.LORA_ALPHA,          # 128
        lora_dropout=config.LORA_DROPOUT,      # 0.05
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                        "gate_proj", "up_proj", "down_proj"],
        bias="none",
        use_gradient_checkpointing="unsloth",
    )

    # 3. ë°ì´í„° ë¡œë“œ
    dataset = load_dataset("json", data_files={
        "train": str(config.OUTPUT_DIR.parent / "train.jsonl"),
        "validation": str(config.OUTPUT_DIR.parent / "val.jsonl"),
    })

    # 4. ì±„íŒ… í…œí”Œë¦¿ ì ìš©
    def apply_chat_template(example):
        text = tokenizer.apply_chat_template(
            example["messages"],
            tokenize=False,
            add_generation_prompt=False
        )
        return {"text": text}

    dataset = dataset.map(apply_chat_template)

    # 5. í•™ìŠµ ì„¤ì •
    training_args = TrainingArguments(
        output_dir=str(config.OUTPUT_DIR.parent / "qwen3_finetuned" / "checkpoints"),
        num_train_epochs=config.NUM_EPOCHS,              # 3
        per_device_train_batch_size=config.BATCH_SIZE,    # 2
        gradient_accumulation_steps=config.GRADIENT_ACCUMULATION,  # 8
        learning_rate=config.LEARNING_RATE,               # 2e-4
        warmup_ratio=config.WARMUP_RATIO,                 # 0.03
        lr_scheduler_type="cosine",
        logging_steps=config.LOGGING_STEPS,               # 10
        save_steps=config.SAVE_STEPS,                     # 100
        save_total_limit=3,
        fp16=True,
        optim="adamw_8bit",
        seed=42,
        report_to="none",
        evaluation_strategy="steps",
        eval_steps=100,
    )

    # 6. SFTTrainerë¡œ í•™ìŠµ
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset["train"],
        eval_dataset=dataset["validation"],
        args=training_args,
        dataset_text_field="text",
        max_seq_length=config.MAX_SEQ_LENGTH,
        packing=True,  # ì§§ì€ ì‹œí€€ìŠ¤ íŒ¨í‚¹ìœ¼ë¡œ íš¨ìœ¨ ê·¹ëŒ€í™”
    )

    trainer.train()

    # 7. LoRA ì–´ëŒ‘í„° ì €ì¥
    model.save_pretrained(str(config.OUTPUT_DIR.parent / "qwen3_finetuned" / "adapter_model"))
    tokenizer.save_pretrained(str(config.OUTPUT_DIR.parent / "qwen3_finetuned" / "adapter_model"))

    # 8. (ì„ íƒ) ë¨¸ì§€ëœ ì „ì²´ ëª¨ë¸ ì €ì¥
    # merged_model = model.merge_and_unload()
    # merged_model.save_pretrained(str(config.OUTPUT_DIR.parent / "qwen3_finetuned" / "merged_model"))
```

**A100 80GB ë©”ëª¨ë¦¬ ì¶”ì •**:
- Qwen3-8B 4-bit: ~5GB
- LoRA ì–´ëŒ‘í„°: ~0.5GB
- í™œì„±í™” ë©”ëª¨ë¦¬ (batch=2, seq=4096): ~15GB
- ì˜µí‹°ë§ˆì´ì € ìƒíƒœ: ~5GB
- **ì´ ì‚¬ìš©ëŸ‰: ~25-30GB** (A100 80GB ì¶©ë¶„)

### 9. `CV/llm_finetuning/run_all.py` - ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

```bash
# ì „ì²´ ì‹¤í–‰
python CV/llm_finetuning/run_all.py

# íŠ¹ì • Phaseë§Œ ì‹¤í–‰
python CV/llm_finetuning/run_all.py --step 0        # ìƒ˜í”Œë§ë§Œ
python CV/llm_finetuning/run_all.py --step 1        # CVë§Œ
python CV/llm_finetuning/run_all.py --step 2        # RAGë§Œ
python CV/llm_finetuning/run_all.py --step 3a       # OpenAIë§Œ
python CV/llm_finetuning/run_all.py --step 3b       # Geminië§Œ
python CV/llm_finetuning/run_all.py --step 3a,3b    # ë‘ ëª¨ë¸ ë™ì‹œ (ë³‘ë ¬)
python CV/llm_finetuning/run_all.py --step 4        # í’ˆì§ˆ ë¹„êµë§Œ
python CV/llm_finetuning/run_all.py --step 5        # JSONLë§Œ
python CV/llm_finetuning/run_all.py --step 6        # Qwen3 í•™ìŠµë§Œ
python CV/llm_finetuning/run_all.py --step 1,2,3a,3b,4,5,6  # ì „ì²´
```

### 10. `CV/llm_finetuning/utils/` - ìœ í‹¸ë¦¬í‹°

**progress_tracker.py**: JSON ê¸°ë°˜ ì§„í–‰ë¥  ì¶”ì , ì¤‘ë‹¨ ì‹œ ì¬ê°œ ê°€ëŠ¥
**local_vector_search.py**: numpy cosine similarity ê¸°ë°˜ TOP-K ê²€ìƒ‰
**retry.py**: API ì¬ì‹œë„ ë°ì½”ë ˆì´í„° (exponential backoff + rate limit ì²˜ë¦¬)
**quality_metrics.py**: 8ê°œ í’ˆì§ˆ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜

---

## ë¡œì»¬ â†’ RunPod ì›Œí¬í”Œë¡œìš°

### ë¡œì»¬ í™˜ê²½ (Phase 0-1)

**í•„ìš” ì‚¬í•­**:
- GPU: RTX 3090/4090 (24GB) ì´ìƒ
- ë””ìŠ¤í¬: ~50GB (ì´ë¯¸ì§€ + ì¤‘ê°„ ì‚°ì¶œë¬¼)
- Python 3.11

**ë¡œì»¬ ì„¤ì •**:
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
cd python

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# Phase 0-1 ì‹¤í–‰
python CV/llm_finetuning/step0_sample_images.py
python CV/llm_finetuning/step1_cv_batch.py  # ì•¼ê°„ ì‹¤í–‰ ê¶Œì¥ (6-12ì‹œê°„)
```

**ì‚°ì¶œë¬¼**:
```
python/training_data/
â”œâ”€â”€ sampled_images.json           # 2,000ê°œ ì´ë¯¸ì§€ ëª©ë¡
â””â”€â”€ output/{image_stem}/
    â””â”€â”€ topology_graph.json       # 2,000ê°œ íŒŒì¼
```

### Phase 1.5: RunPod ì—…ë¡œë“œ

**ì—…ë¡œë“œ ëŒ€ìƒ** (~500MB):
```bash
# ë¡œì»¬ì—ì„œ ì‹¤í–‰
# ë°©ë²• 1: rsync (SSH)
rsync -avz --progress \
  python/training_data/sampled_images.json \
  python/training_data/output/ \
  python/CV/rag_data/ì‚¬ë‚´_í‰ê°€_ë¬¸ì„œ.json \
  root@runpod-xxx:/workspace/training_data/

# ë°©ë²• 2: RunPod CLI (ì¶”ì²œ)
runpod send python/training_data/ /workspace/training_data/

# ë°©ë²• 3: ìˆ˜ë™ ì—…ë¡œë“œ (RunPod Web UI)
# 1. training_data í´ë”ë¥¼ zip ì••ì¶•
# 2. RunPod Volumeì— ì—…ë¡œë“œ
# 3. Podì—ì„œ ì••ì¶• í•´ì œ
```

**ì˜ˆìƒ ì‹œê°„**: ~10-30ë¶„ (ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼)

---

## RunPod A100 í™˜ê²½ ì„¤ì • (Phase 2-6)

### Pod ì„¤ì •
```
GPU: NVIDIA A100 80GB SXM
ì´ë¯¸ì§€: runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04
ë””ìŠ¤í¬: Volume 100GB (/workspace)
ë„¤íŠ¸ì›Œí¬ ë³¼ë¥¨: ë¡œì»¬ ì—…ë¡œë“œ íŒŒì¼ ì ‘ê·¼
```

### ì´ˆê¸° í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# RunPod ì´ˆê¸° ì„¤ì • (Phase 2-6ë§Œ ì‹¤í–‰)

# 1. í”„ë¡œì íŠ¸ í´ë¡ 
cd /workspace
git clone https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN20-FINAL-3TEAM.git
cd SKN20-FINAL-3TEAM/python

# 2. Python í™˜ê²½
pip install -r requirements.txt

# 3. ì¶”ê°€ ì˜ì¡´ì„± (í•™ìŠµìš©)
pip install transformers>=4.40.0      # Qwen3-Embedding
pip install torch>=2.0.0              # PyTorch
pip install scikit-learn>=1.3.0       # cosine_similarity
pip install google-generativeai>=0.8.0
pip install unsloth
pip install trl>=0.12.0
pip install datasets>=3.0.0
pip install accelerate>=1.0.0
pip install bitsandbytes>=0.44.0
pip install tqdm>=4.66.0

# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cat > .env << 'EOF'
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=AIza...
EOF

# 5. ì—…ë¡œë“œëœ ë°ì´í„° í™•ì¸
ls -lh /workspace/training_data/sampled_images.json
ls -lh /workspace/training_data/output/ | head -10
ls -lh /workspace/python/CV/rag_data/ì‚¬ë‚´_í‰ê°€_ë¬¸ì„œ.json

# 6. Phase 2ë¶€í„° ì‹¤í–‰
python CV/llm_finetuning/run_all.py --step 2,3a,3b,4,5,6
```

**ì£¼ì˜ì‚¬í•­**:
- âŒ Phase 0-1ì€ ë¡œì»¬ì—ì„œ ì´ë¯¸ ì™„ë£Œ
- âœ… Phase 2-6ë§Œ RunPodì—ì„œ ì‹¤í–‰
- ğŸ’¾ Volumeì— ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸ í•„ìˆ˜

---

## ì¬ì‚¬ìš©í•˜ëŠ” ê¸°ì¡´ ì½”ë“œ

| ê¸°ì¡´ ì½”ë“œ | ìš©ë„ | ë³€ê²½ì‚¬í•­ |
|-----------|------|----------|
| `python/CV/cv_inference/pipeline.py` â†’ `InferencePipeline` | CV ì¶”ë¡  | ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| `python/CV/cv_inference/config.py` â†’ `InferenceConfig` | CV ì„¤ì • | OUTPUT_PATH ì˜¤ë²„ë¼ì´ë“œ |
| `python/CV/rag_system/llm_client.py` â†’ `OpenAIClient` | OpenAI LLM í˜¸ì¶œ | ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| `python/CV/rag_system/schemas.py` â†’ `FloorPlanAnalysis` | êµ¬ì¡°í™” ì¶œë ¥ ìŠ¤í‚¤ë§ˆ | ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| `python/CV/rag_system/prompts.py` â†’ `SYSTEM_PROMPT`, `build_analysis_prompt` | í”„ë¡¬í”„íŠ¸ | ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| `python/CV/rag_system/config.py` â†’ `RAGConfig` | API í‚¤ ë“± ì„¤ì • | ê·¸ëŒ€ë¡œ ì‚¬ìš© |

**ì œê±°ëœ ì˜ì¡´ì„±**:
- ~~`python/CV/rag_system/embeddings.py` â†’ `EmbeddingManager`~~ â†’ **Qwen3EmbeddingManager**ë¡œ ëŒ€ì²´ (step2ì— ì§ì ‘ êµ¬í˜„)

---

## ì¶”ê°€ ì˜ì¡´ì„± (requirements-training.txt)

```
# Gemini API
google-generativeai>=0.8.0

# Qwen3 ìƒíƒœê³„ (ì„ë² ë”© + íŒŒì¸íŠœë‹)
transformers>=4.40.0              # Qwen3-Embedding ë¡œë“œ
torch>=2.0.0                      # PyTorch
scikit-learn>=1.3.0               # cosine_similarity
unsloth                           # Qwen3 íŒŒì¸íŠœë‹ ìµœì í™”
trl>=0.12.0                       # SFTTrainer
datasets>=3.0.0                   # JSONL ë¡œë“œ
accelerate>=1.0.0                 # ë¶„ì‚° í•™ìŠµ
bitsandbytes>=0.44.0              # 4-bit ì–‘ìí™”
peft>=0.13.0                      # LoRA ì–´ëŒ‘í„°

# ë¹„ë™ê¸° API í˜¸ì¶œ
aiohttp>=3.9.0
asyncio

# ìœ í‹¸ë¦¬í‹°
tqdm>=4.66.0                      # ì§„í–‰ë¥  í‘œì‹œ
```

---

## ì˜ˆìƒ ë¹„ìš© ë° ì‹œê°„

| Phase | í™˜ê²½ | ì†Œìš”ì‹œê°„ | ë¹„ìš© | ë¹„ê³  |
|-------|------|---------|------|------|
| **ë¡œì»¬ ì‘ì—…** | | | | |
| 0. ìƒ˜í”Œë§ | ë¡œì»¬ CPU | ~1ë¶„ | $0 | ì¸µí™” ìƒ˜í”Œë§ |
| 1. CV ì¶”ë¡  | **ë¡œì»¬ GPU** | **~6-12ì‹œê°„** | **$0** | ì•¼ê°„ ì‹¤í–‰ ê¶Œì¥ |
| 1.5. ì—…ë¡œë“œ | ë„¤íŠ¸ì›Œí¬ | ~10-30ë¶„ | $0 | ~500MB |
| **RunPod ì‘ì—…** | | | | |
| 2. RAG ì»¨í…ìŠ¤íŠ¸ | A100 GPU | **~15ì´ˆ** | $0 | Qwen3-Embedding |
| 3A. OpenAI GPT-4o | A100 CPU | ~4-8ì‹œê°„ | **~$40-60** | API ë³‘ëª© |
| 3B. Gemini 3 Pro | A100 CPU | ~4-8ì‹œê°„ | **~$20-40** | API ë³‘ëª© |
| 4. í’ˆì§ˆ ë¹„êµ | A100 CPU | ~30ë¶„ | $0 | ë©”íŠ¸ë¦­ ê³„ì‚° |
| 5. JSONL ë³€í™˜ | A100 CPU | ~2ë¶„ | $0 | ë°ì´í„° ë³€í™˜ |
| 6. Qwen3 í•™ìŠµ | A100 GPU | ~2-4ì‹œê°„ | RunPod ë¹„ìš© | GPU ë³‘ëª© |
| **í•©ê³„** | | **~17-33ì‹œê°„** | **API: ~$60-100 + RunPod: ~$3-10** | - |

**RunPod A100 ë¹„ìš©**: ~$1.64/hr (spot) ~ $2.49/hr (on-demand)
- Phase 2-6 GPU ì‹œê°„: ~2-4ì‹œê°„ (Phase 1 ì œì™¸!) â†’ **~$3-10**
- ë¡œì»¬ GPUë¡œ Phase 1 ì‹¤í–‰ â†’ **RunPod ë¹„ìš© 50-70% ì ˆê°** ğŸ‰

**ì´ ë¹„ìš©: ~$63-110** (ê¸°ì¡´ ~$68-125 ëŒ€ë¹„ ì ˆê°)

**ë¹„ìš© ë¶„ì„**:
- ë¡œì»¬ GPU ì „ë ¥ë¹„: ~0.5kWh Ã— 10ì‹œê°„ Ã— $0.15/kWh = **~$0.75** (ë¬´ì‹œ ê°€ëŠ¥)
- RunPod ë¹„ìš© ì ˆê°: ~$5-15 (Phase 1ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰)
- **ìˆœì ˆê°ì•¡: ~$4-14**

**ì„±ëŠ¥ ê°œì„ **:
- Phase 2 ì†ë„: 5ë¶„ â†’ **15ì´ˆ** (20ë°° ë‹¨ì¶•) ğŸš€
- ì„ë² ë”© ë¹„ìš©: $0.01 â†’ **$0** (ì™„ì „ ë¬´ë£Œ) ğŸ’°
- RunPod ë¹„ìš©: $8-25 â†’ **$3-10** (50-70% ì ˆê°) ğŸ’¸
- í•™ìŠµ-ì¶”ë¡  ì¼ê´€ì„±: **100% ë³´ì¥** âœ…

---

## Phase 3A/3B ë³‘ë ¬ ì‹¤í–‰ ì „ëµ

3A(OpenAI)ì™€ 3B(Gemini)ëŠ” **ì™„ì „ ë…ë¦½ì **ì´ë¯€ë¡œ ë³‘ë ¬ ì‹¤í–‰:

```bash
# ë°©ë²• 1: tmux ë¶„í• 
tmux new-session -s labeling
# Pane 1:
python CV/llm_finetuning/step3a_openai_labeling.py
# Pane 2:
python CV/llm_finetuning/step3b_gemini_labeling.py

# ë°©ë²• 2: nohup ë°±ê·¸ë¼ìš´ë“œ
nohup python CV/llm_finetuning/step3a_openai_labeling.py > logs/openai.log 2>&1 &
nohup python CV/llm_finetuning/step3b_gemini_labeling.py > logs/gemini.log 2>&1 &
```

ì´ë ‡ê²Œ í•˜ë©´ Phase 3 ì „ì²´ ì‹œê°„ì´ ~4-8ì‹œê°„ (ë³‘ë ¬)ìœ¼ë¡œ ë‹¨ì¶•ë©ë‹ˆë‹¤.

---

## ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘

| ìœ„í—˜ | ëŒ€ì‘ |
|------|------|
| GPU OOM (CV ì¶”ë¡ ) | ì´ë¯¸ì§€ë³„ ê°œë³„ ì²˜ë¦¬ + ë§¤ 50ê±´ `torch.cuda.empty_cache()` |
| ì¥ì‹œê°„ ì‹¤í–‰ ì¤‘ RunPod ì¤‘ë‹¨ | progress.json ê¸°ë°˜ ì¤‘ë‹¨/ì¬ê°œ + Volume ì˜êµ¬ ìŠ¤í† ë¦¬ì§€ |
| OpenAI Rate Limit | exponential backoff + 429 ì‹œ 60ì´ˆ ëŒ€ê¸° + Semaphore(5) |
| Gemini Rate Limit | ë™ì¼ ì „ëµ + Gemini ê³ ìœ  quota í™•ì¸ |
| Structured output íŒŒì‹± ì‹¤íŒ¨ | í…ìŠ¤íŠ¸ ì‘ë‹µ â†’ JSON ìˆ˜ë™ íŒŒì‹± fallback |
| ì¼ë¶€ ì´ë¯¸ì§€ CV ì‹¤íŒ¨ | try/except ê²©ë¦¬ + failed_images ê¸°ë¡ |
| ë‘ ëª¨ë¸ í’ˆì§ˆì´ ê±°ì˜ ë™ì¼ | 5% ì´ë‚´ ì°¨ì´ ì‹œ ë¹„ìš© íš¨ìœ¨ ë†’ì€ ìª½ ì„ íƒ |
| Qwen3 í•™ìŠµ ì¤‘ OOM | gradient checkpointing + batch=2 + accumulation=8 |
| Qwen3 ê³¼ì í•© | val loss ëª¨ë‹ˆí„°ë§ + early stopping ê³ ë ¤ |
| RunPod Volume ìš©ëŸ‰ ë¶€ì¡± | ì¤‘ê°„ ì‚°ì¶œë¬¼ ì •ë¦¬ + 100GB Volume í™•ë³´ |

---

## ê²€ì¦ ë°©ë²•

### Phaseë³„ ê²€ì¦

**ë¡œì»¬ í™˜ê²½**:
1. **Phase 0**:
   - sampled_images.jsonì´ ì •í™•íˆ 2,000ê°œì¸ì§€ í™•ì¸
   - ì¸µí™” ìƒ˜í”Œë§ ë¶„í¬ ê²€ì¦ (ì•„íŒŒíŠ¸ ë‹¨ì§€ë³„ ê· ë“± ë¶„í¬)
2. **Phase 1**:
   - 10ì¥ ìƒ˜í”Œë¡œ CV íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ â†’ topology_graph.json ìƒì„± í™•ì¸
   - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (nvidia-smi)
   - 2,000ê°œ ì „ì²´ ì™„ë£Œ í›„ ì‹¤íŒ¨ ì´ë¯¸ì§€ í™•ì¸
3. **Phase 1.5**:
   - ì—…ë¡œë“œ ì „ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸ (íŒŒì¼ ìˆ˜, í¬ê¸°)
   - ì••ì¶• ì‹œ ì†ìƒ ì—¬ë¶€ í™•ì¸

**RunPod í™˜ê²½**:
3. **Phase 2**:
   - Qwen3-Embedding ì •ìƒ ë¡œë“œ í™•ì¸ (768ì°¨ì›)
   - ì„ë² ë”© ìºì‹œ ìƒì„± í™•ì¸ (embedding_cache.npy)
   - RAG ì»¨í…ìŠ¤íŠ¸ 5ê°œ ìˆ˜ë™ ê²€í†  â†’ ê´€ë ¨ì„± í™•ì¸
   - ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬ í™•ì¸ (TOP-5 í‰ê·  > 0.7 ê¶Œì¥)
4. **Phase 3A/3B**: ê° 10ì¥ ìƒ˜í”Œë¡œ ë¼ë²¨ë§ í…ŒìŠ¤íŠ¸ â†’ FloorPlanAnalysis íŒŒì‹± í™•ì¸
5. **Phase 4**: quality_report.json ë©”íŠ¸ë¦­ í™•ì¸ â†’ ìŠ¹ì ê²°ì • ê·¼ê±° ê²€í† 
6. **Phase 5**: train.jsonl ëœë¤ 10ê°œ ìƒ˜í”Œ ìˆ˜ë™ ê²€í†  + ìŠ¤í‚¤ë§ˆ ì „ìˆ˜ ê²€ì‚¬
7. **Phase 6**: val loss ìˆ˜ë ´ í™•ì¸ + 10ê°œ ìƒ˜í”Œ ì¶”ë¡  í’ˆì§ˆ ìˆ˜ë™ í‰ê°€

### ìµœì¢… ê²€ì¦

- íŒŒì¸íŠœë‹ëœ Qwen3 ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ì…‹ ì¶”ë¡  ì‹¤í–‰
- GPT-4o/Gemini 3 Pro ì›ë³¸ ì¶œë ¥ê³¼ Qwen3 ì¶œë ¥ ë¹„êµ (BLEU, ROUGE, ë˜ëŠ” ìˆ˜ë™ í‰ê°€)
- FloorPlanAnalysis ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ìœ¨ 95%+ í™•ì¸

---

## êµ¬í˜„ ìˆœì„œ

### ë¡œì»¬ í™˜ê²½ (Day 1-2)
```
Day 1 (ë¡œì»¬):
1. config.py + utils/ (ì¸í”„ë¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2-3ì‹œê°„
2. step0_sample_images.py â†’ ì‹¤í–‰ â†’ sampled_images.json â”€â”€ 1ì‹œê°„
3. step1_cv_batch.py â†’ 10ì¥ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„
4. step1_cv_batch.py â†’ ì „ì²´ ì‹¤í–‰ (ì•¼ê°„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œì‘

Day 2 (ë¡œì»¬):
5. step1_cv_batch.py ì™„ë£Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì˜¤ì „
6. ê²°ê³¼ ê²€ì¦ (topology_graph.json 10ê°œ ìƒ˜í”Œ í™•ì¸) â”€â”€â”€â”€â”€â”€â”€ 30ë¶„
7. RunPod ì—…ë¡œë“œ ì¤€ë¹„ (ì••ì¶• ë˜ëŠ” rsync) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„
```

### RunPod í™˜ê²½ (Day 2-3)
```
Day 2 (RunPod):
8. RunPod Pod ìƒì„± + í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„
9. ë¡œì»¬ ë°ì´í„° ì—…ë¡œë“œ (sampled_images.json + output/) â”€â”€ 10-30ë¶„
10. step2_rag_context.py â†’ í…ŒìŠ¤íŠ¸ + ì „ì²´ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 30ë¶„
11. step3a + step3b 10ì¥ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„
12. step3a + step3b ë³‘ë ¬ ì „ì²´ ì‹¤í–‰ (ì•¼ê°„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œì‘

Day 3 (RunPod):
13. step3a/3b ì™„ë£Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì˜¤ì „
14. step4_quality_compare.py â†’ ì‹¤í–‰ â†’ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„
15. step5_build_jsonl.py â†’ ì‹¤í–‰ + ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„
16. step6_qwen3_finetune.py â†’ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2-4ì‹œê°„
17. ëª¨ë¸ í‰ê°€ + ê²°ê³¼ ë‹¤ìš´ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ì‹œê°„

Day 4 (ì„ íƒ):
18. run_all.py (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°) ê°œì„  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•„ìš” ì‹œ
```

**ì´ ì˜ˆìƒ ì†Œìš”: 2-3ì¼**
- ë¡œì»¬ ì‘ì—…: 1-2ì¼ (ì•¼ê°„ ì‹¤í–‰ í™œìš©)
- RunPod ì‘ì—…: 1-2ì¼ (ì•¼ê°„ ì‹¤í–‰ í™œìš©)
- RunPod ì´ ì‚¬ìš© ì‹œê°„: **~8-16ì‹œê°„** (ëŒ€ê¸° ì‹œê°„ í¬í•¨)

---

## v1 â†’ v2 ë³€ê²½ ìš”ì•½

| í•­ëª© | v1 | v2 |
|------|-----|-----|
| ì´ë¯¸ì§€ ìˆ˜ | 9,991ì¥ | **2,000ì¥** (ëŒ€í‘œ ìƒ˜í”Œ) |
| ë¼ë²¨ë§ ëª¨ë¸ | GPT-4o-mini 1ê°œ | **GPT-4o + Gemini 3 Pro** 2ê°œ |
| ì„ë² ë”© ëª¨ë¸ | OpenAI text-embedding-3-small | **Qwen3-Embedding-0.6B** (768ì°¨ì›) |
| ë°ì´í„° í’ˆì§ˆ ë³´ì¦ | ì—†ìŒ | **8ê°œ ë©”íŠ¸ë¦­ ìë™ ë¹„êµ** |
| CV ì¶”ë¡  í™˜ê²½ | ë¡œì»¬ | **ë¡œì»¬ GPU** (Phase 0-1) |
| í•™ìŠµ í™˜ê²½ | ë¡œì»¬ | **RunPod A100 80GB** (Phase 2-6) |
| Qwen3 í•™ìŠµ | ë³„ë„ ê³„íš | **í†µí•© (Phase 6)** |
| í•™ìŠµ-ì¶”ë¡  ì¼ê´€ì„± | ì—†ìŒ (ë¶ˆì¼ì¹˜) | **ì™„ë²½ ì¼ê´€ì„±** (ë™ì¼ ì„ë² ë”©) |
| ì´ API ë¹„ìš© | ~$25-30 | ~$60-100 |
| ì´ RunPod ë¹„ìš© | ~$8-25 | **~$3-10** (50-70% ì ˆê°) |
| ì´ ì†Œìš” ì‹œê°„ | ~22-50ì‹œê°„ | **~17-33ì‹œê°„** (ë³‘ë ¬í™” + ë¡œì»¬ ë¶„ì‚°) |
| Phase 1 ì‹œê°„ | ~3-6ì‹œê°„ (A100) | **~6-12ì‹œê°„** (ë¡œì»¬ GPU, ì•¼ê°„ ì‹¤í–‰) |
| Phase 2 ì‹œê°„ | ~5ë¶„ | **~15ì´ˆ** (20ë°° ë‹¨ì¶•) |
| ë°ì´í„° í’ˆì§ˆ | ì¤‘ (4o-mini) | **ìƒ (4o + Gemini 3 Pro ë¹„êµ ê²€ì¦)** |
| ì´ ë¹„ìš© | ~$33-55 | **~$63-110** (ê³ í’ˆì§ˆ ë¼ë²¨ë§)
