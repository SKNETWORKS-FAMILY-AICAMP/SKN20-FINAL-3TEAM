# 챗봇 서비스 개발 기록 & 아키텍처 백과사전

---

## 1. 개발 과정 (V1 → V2 진화)

### V1 (초기 버전)

- 기본 RAG 파이프라인: 질문 → 임베딩 → pgvector 검색(k=2) → GPT 답변
- regex 기반 주소/용도지역/행위 추출
- 단순 케이스 분기 (CASE1/2/3)
- DB 직접 매칭만 사용

### V2 (현재 버전 - RAG 성능 개선)

**임베딩 캐시**
- V1: 없음
- V2: LRU Cache (500개)
- 효과: 중복 API 호출 제거

**벡터 검색 k값**
- V1: k=2
- V2: k=10~15 (케이스별 차등)
- 효과: 후보군 확대

**Reranker**
- V1: 없음
- V2: Cross-encoder ms-marco-MiniLM-L-6-v2
- 효과: 관련성 재정렬

**추출 방식**
- V1: regex 6개 메서드
- V2: gpt-4o-mini 1회 JSON 추출 + regex fallback
- 효과: 정확도 향상

**검색 전략**
- V1: 단순 쿼리
- V2: 동 단위 샘플링 (depth<=2)
- 효과: 지역 균형 결과

**문서 필터링**
- V1: 최소
- V2: 의미없는 문서 제거 (<50자, 중복)
- 효과: 컨텍스트 품질 향상

**오타 보정**
- V1: 없음
- V2: normalize_query (건페율→건폐율 등)
- 효과: 입력 오류 대응

**키워드 매핑**
- V1: 없음
- V2: GPT에 "카페=휴게음식점" 매핑 설명 전달
- 효과: 법적 분류 이해도 향상

### V2 추가 기능들

- CASE3-4: 법조문 기반 검색
- CASE3-5: 용도지역 비교 (비교표 포맷)
- 특수쿼리: 건폐율/용적률 조회, 건축법 vs 조례 비교
- query_fields: 사용자 관심 정보 자동 감지 (도로접면, 면적 등)
- 대화 히스토리 참조 (최근 2건)

---

## 2. 전체 아키텍처 (5단계 파이프라인)

```
사용자 질문
    │
    ▼
[1단계] 구조화 추출 ─── gpt-4o-mini (JSON) ──→ 실패 시 regex fallback
    │                    temperature=0
    │                    max_tokens=300
    ▼
    ┌─ address_info (주소)
    ├─ zone_names (용도지역)
    ├─ activities (행위)
    ├─ law_reference (법조문)
    ├─ special_queries (건폐율/비교 등)
    ├─ query_fields (관심 정보)
    ├─ is_comparison (비교 여부)
    └─ intent (CASE 분류)
    │
    ▼
[2단계] 의도 분류 (classify_intent)
    │
    ▼
[3-4단계] 데이터 검색 + 법규 검토
    ├─ CASE1 → process_case1 (주소 기반 필지 조회)
    ├─ CASE2 → process_case2 (주소+용도지역 매칭)
    └─ CASE3 → process_case3 (용도지역/행위/법조문/비교)
    │
    ▼
[컨텍스트 조립] _build_context
    ├─ 케이스별 분석 결과
    ├─ 특수쿼리 결과 (건폐율, 법률비교)
    ├─ 이전 대화 히스토리
    ├─ RAG 벡터 검색 (k=10~15)
    │   └─ Reranker 재정렬 (top 3~5)
    └─ 키워드 매핑 설명
    │
    ▼
[5단계] LLM 리포트 생성
    ├─ system_prompt (규칙 + 예시 + 포맷 지시)
    ├─ [ANALYSIS DATA] = 조립된 컨텍스트
    └─ GPT 호출 → 최종 답변
```

---

## 3. CASE 분류 체계

### CASE1: 주소만 있음 (용도지역 없음)

**1-1: 지번까지 입력 (depth=4)**
- 예시: "종로구 청운동 1-2"
- 동작: 필지 직접 조회 → 법규 매칭

**1-3: 동까지만 입력 (depth=3)**
- 예시: "종로구 청운동"
- 동작: 동 내 필지 샘플링 조회

**1-0: 주소 불충분 (depth<3)**
- 예시: "서울시"
- 동작: 정보 부족 안내

### CASE2: 주소 + 용도지역 모두 있음

**2-1: 용도지역 일치**
- 조건: 실제 = 입력
- 동작: 정상 법규 검토

**2-2: 용도지역 불일치**
- 조건: 실제 ≠ 입력
- 동작: 경고 + 실제 기준 답변

**2-3: 부분일치**
- 조건: 일부만 일치
- 동작: 경고 + 실제 기준 답변

### CASE3: 주소 없이 질문

**3-1: 용도지역 + 행위**
- 예시: "제1종주거에서 카페 가능?"
- 동작: DB에서 해당 zone+activity 검색 → 허용여부 판정

**3-2: 용도지역만**
- 예시: "제1종주거에서 뭘 지을 수 있어?"
- 동작: 해당 zone 전체 법규 검색

**3-3: 행위만**
- 예시: "카페는 어디서 가능해?"
- 동작: 해당 activity 허용 zone 역검색

**3-4: 법조문만**
- 예시: "건축법 제2조 알려줘"
- 동작: law_name 컬럼 LIKE 검색

**3-5: 용도지역 비교 (2개 이상)**
- 예시: "1종 vs 2종 차이?"
- 동작: 각 zone 규제 + DB 통계 비교표

---

## 4. 백과사전 (정적 딕셔너리) 역할

### 4-1. ZONE_DISTRICT_DICTIONARY (~22개 항목)

**역할: 사용자 약칭 → DB 정식 용도지역명 확장**

- "주거지역" → 제1종전용주거지역, 제2종전용주거지역, 제1종일반주거지역, 제2종일반주거지역, 제3종일반주거지역, 준주거지역 (6종 전부)
- "상업지역" → 중심상업지역, 일반상업지역, 근린상업지역, 유통상업지역
- "1종주거" → 제1종전용주거지역, 제1종일반주거지역

없으면? "주거지역이랑 상업지역 비교해줘" → zone 추출 실패, CASE 분류 불가

### 4-2. LAND_USE_DICTIONARY (~130개 항목)

**역할: 일상어 → DB 법적 분류명 매핑**

- 카페, 커피숍, 커피전문점 → 휴게음식점, 제과점
- 식당, 밥집, 레스토랑 → 일반음식점
- 헬스장, 피트니스, 짐 → 체육관
- 미용실, 헤어샵, 뷰티샵 → 미용원
- PC방, 피씨방 → 인터넷컴퓨터게임시설제공업소
- 노래방, 코인노래 → 노래연습장

없으면? "카페 가능해?" → activity 추출 실패 → DB 검색 불가. DB에는 "카페"가 아닌 "휴게음식점"으로 저장되어 있기 때문

### 4-3. ZONE_REGULATIONS (21종 전체)

**역할: 용도지역별 법정 규제 기준값 제공 (DB 조회 없이 즉시)**

- 제1종전용주거지역: 건폐율 50%, 용적률 50~100%, 높이 없음, 단독주택 중심
- 중심상업지역: 건폐율 90%, 용적률 400~1500%, 높이 없음, 도심 상업·업무
- 보전녹지지역: 건폐율 20%, 용적률 50~80%, 높이 4층 이하, 자연환경 보전

사용처:
- 건폐율/용적률 질문 → 즉시 응답 (DB 조회 불필요)
- CASE3-5 비교표 생성 → 각 zone의 규제값 비교
- get_zone_regulations() → 정적값 + DB 추가 조건 병합

### 4-4. SPECIAL_QUERY_KEYWORDS (~12개)

**역할: 특수 질문 유형 감지**

- "건폐율", "건페율" → coverage_ratio → get_zone_regulations() 호출
- "용적률", "용적율" → floor_area_ratio → get_zone_regulations() 호출
- "조례", "법과조례" → law_comparison → compare_laws() 호출
- "높이제한" → height_limit
- "건축가능", "신축" → building_permit

---

## 5. 핵심 기술 상세

### 5-1. LRU Cache (임베딩 캐시)

**LRU = Least Recently Used (가장 오래 안 쓴 거 버리기)**

임베딩이란 텍스트를 숫자 벡터(예: [0.12, -0.34, 0.56, ...])로 변환하는 것. 변환할 때마다 OpenAI API를 호출해야 하고, API 호출 = 돈 + 시간.

같은 질문이 또 오면 또 API 호출하면 낭비. 그래서 한번 변환한 결과를 메모리에 저장(캐시)해둔다.

```
1번째 질문: "카페 가능?" → API 호출 → 결과 저장 (miss)
2번째 질문: "카페 가능?" → 저장된 거 꺼냄 (hit) → API 호출 안 함!
```

500개 제한 이유: 무한히 저장하면 메모리 터짐. 500개 넘으면 가장 오래 안 쓴 것부터 삭제.

**저장 위치:** 파일이 아닌 Python 프로세스 메모리(RAM). 서버 종료 시 전부 사라짐 (휘발성). 서버 재시작 → 빈 캐시에서 다시 시작.

**쓰는 이유:** API 비용 절감 + 응답 속도 향상

### 5-2. 벡터 검색 k=10~15

pgvector(PostgreSQL 벡터 DB)에서 질문과 비슷한 문서를 검색할 때 몇 개를 가져올지가 k값.

```
V1: k=2  → 2개만 가져옴 → 정답이 빠질 확률 높음
V2: k=15 → 15개 가져옴 → 후보가 넓어서 정답 포함 확률 높음
    → Reranker로 그 중 top 3~5만 골라 사용
```

비유: 시험 공부할 때
- k=2: 교과서 2페이지만 읽기 → 시험 범위 놓칠 수 있음
- k=15: 15페이지 훑고 → 중요한 3~5페이지만 정독

케이스별 차등:
- CASE3 (단순 질문): k=10, top=3 → 적게 가져와도 충분
- CASE1/2 (복합 질문): k=15, top=5 → 넓게 봐야 함

### 5-3. Cross-encoder (Reranker)

**Bi-encoder (벡터 검색):**
질문과 문서를 각각 따로 벡터로 만들어서 코사인 유사도로 비교. 빠르지만 부정확할 수 있음.

**Cross-encoder (Reranker):**
질문과 문서를 같이 하나의 모델에 넣어서 관련성 점수(0.0~1.0)를 매김. 느리지만 정확함.

왜 둘 다 쓰나?

```
1단계: Bi-encoder (벡터검색) → 빠르게 15개 후보 추림
2단계: Cross-encoder (Reranker) → 15개를 정밀하게 재정렬 → top 3~5 선택
```

15개 전부를 Cross-encoder로 검색하면 너무 느려서, 벡터검색으로 빠르게 좁히고 → Reranker로 정밀 재정렬하는 2단계 전략.

ms-marco-MiniLM-L-6-v2: Microsoft가 만든 경량 Cross-encoder 모델. 작고 빨라서 실시간 서비스에 적합.

### 5-4. gpt-4o-mini 1회 JSON 추출

사용자 질문에서 주소/용도지역/행위/법조문 등을 한번에 구조화 추출하는 것.

```
입력: "수원시 영통구 매탄동 제1종일반주거지역에서 카페 가능해?"

→ gpt-4o-mini 1회 호출 →

출력 (JSON):
{
  "address": {"sido": "경기도", "sigungu": "수원시 영통구", "dong": "매탄동"},
  "zones": ["제1종일반주거지역"],
  "activities": ["휴게음식점"],    ← 카페를 법적 분류로 자동 변환!
  "intent": "CASE2"
}
```

왜 gpt-4o-mini?
- 빠르고 저렴 (추출용이니까 똑똑할 필요 없음)
- temperature=0 (매번 같은 결과 보장)
- JSON 포맷 강제 (response_format=json_object)

### 5-5. regex fallback

**regex = Regular Expression (정규표현식)**

텍스트에서 특정 패턴을 찾는 규칙.

```
지번 찾기:  \d+-\d+  →  "1-1040" 매칭
법조문 찾기: 건축법제\d+조  →  "건축법제2조" 매칭
용도지역 찾기: "제1종일반주거지역" in question  →  True/False
```

**fallback = 대비책**

```
1순위: gpt-4o-mini로 추출 시도
         │
         ├─ 성공 → 결과 사용
         │
         └─ 실패 (API 에러, 타임아웃 등)
              │
              ▼
2순위: regex 6종으로 추출 (fallback)
       ├─ parse_address()              → 주소 추출
       ├─ extract_zone_district_name() → 용도지역 추출
       ├─ extract_land_use_activity()  → 행위 추출
       ├─ extract_region_codes()       → 지역코드 추출
       ├─ extract_special_queries()    → 특수쿼리 추출
       └─ law_reference regex          → 법조문 추출
```

왜 fallback이 필요?
- OpenAI API가 죽을 수 있음 (장애, 타임아웃)
- API 키 만료될 수 있음
- 네트워크 끊길 수 있음
- 이때도 서비스가 동작해야 하니까 regex로 최소한의 추출 보장

### 5-6. RAG 벡터 검색

- 임베딩 모델: text-embedding-3-small (OpenAI)
- 벡터 DB: pgvector (PostgreSQL 확장)
- k값 차등: CASE3(단순)=k10/top3, CASE1/2(복합)=k15/top5
- 저장 대상: 건축 도면 평면도 분석 결과

### 5-7. 개발 성적표 (analyze_feasibility)

법규 매칭 결과를 종합 판정:

- 허용(가능)만 있음 → **가능**
- 조건부허용만 있음 → **조건부가능**
- 불허 존재 → **불가**
- 혼합 → **검토필요**
- 데이터 없음 → **정보부족**

### 5-8. 동 단위 샘플링 (V2)

주소 depth가 2 이하(시/군/구까지만)일 때:

```sql
ROW_NUMBER() OVER(PARTITION BY legal_dong_name ORDER BY lot_number)
```

각 동에서 균등하게 필지를 뽑아 편향 방지

---

## 6. DB 테이블 구조

**land_char (필지 특성 정보)**
- legal_dong_name, lot_number, region_code, zone1, zone2, land_category, land_use, land_area, terrain_height, terrain_shape, road_access

**law (용도지역별 법규)**
- region_code, zone_district_name, law_name, land_use_activity, permission_category, condition_exception

**chat_history (대화 이력)**
- question, answer, created_at

**chatroom (채팅방 관리)**
- user FK

**users (사용자 정보)**
- email

---

## 7. 파일 통계

- 전체 라인 수: 2,912줄
- 메인 클래스: ChatbotService (1개)
- 헬퍼 클래스: EmbeddingCache (1개)
- 정적 딕셔너리: 4개
- 퍼블릭 메서드: ~40개+
- LLM 모델: gpt-4o-mini (추출+답변)
- 임베딩 모델: text-embedding-3-small
- Reranker 모델: cross-encoder/ms-marco-MiniLM-L-6-v2
- CASE 유형: 3대분류, 10개 서브케이스
