# 챗봇 서비스 개발 기록 & 아키텍처 백과사전

---

## 1. 개발 과정 (V1 → V2 진화)

### V1 (초기 버전)

- 기본 RAG 파이프라인: 질문 → 임베딩 → pgvector 검색(k=2) → GPT 답변
- regex 기반 주소/용도지역/행위 추출
- 단순 케이스 분기 (CASE1/2/3)
- DB 직접 매칭만 사용

### V2 (현재 버전 - RAG 성능 개선)

**임베딩 캐시**
- V1: 없음
- V2: LRU Cache (500개)
- 효과: 중복 API 호출 제거

**벡터 검색 k값**
- V1: k=2
- V2: k=10~15 (케이스별 차등)
- 효과: 후보군 확대

**Reranker**
- V1: 없음
- V2: Cross-encoder ms-marco-MiniLM-L-6-v2
- 효과: 관련성 재정렬

**추출 방식**
- V1: regex 6개 메서드
- V2: gpt-4o-mini 1회 JSON 추출 + regex fallback
- 효과: 정확도 향상

**검색 전략**
- V1: 단순 쿼리
- V2: 동 단위 샘플링 (depth<=2)
- 효과: 지역 균형 결과

**문서 필터링**
- V1: 최소
- V2: 의미없는 문서 제거 (<50자, 중복)
- 효과: 컨텍스트 품질 향상

**오타 보정**
- V1: 없음
- V2: normalize_query (건페율→건폐율 등)
- 효과: 입력 오류 대응

**키워드 매핑**
- V1: 없음
- V2: GPT에 "카페=휴게음식점" 매핑 설명 전달
- 효과: 법적 분류 이해도 향상

### V2 추가 기능들

- CASE3-4: 법조문 기반 검색
- CASE3-5: 용도지역 비교 (비교표 포맷)
- 특수쿼리: 건폐율/용적률 조회, 건축법 vs 조례 비교
- query_fields: 사용자 관심 정보 자동 감지 (도로접면, 면적 등)
- 대화 히스토리 참조 (최근 2건)

---

## 2. 전체 아키텍처 (5단계 파이프라인)

```
사용자 질문
    │
    ▼
[1단계] 구조화 추출 ─── gpt-4o-mini (JSON) ──→ 실패 시 regex fallback
    │                    temperature=0
    │                    max_tokens=300
    ▼
    ┌─ address_info (주소)
    ├─ zone_names (용도지역)
    ├─ activities (행위)
    ├─ law_reference (법조문)
    ├─ special_queries (건폐율/비교 등)
    ├─ query_fields (관심 정보)
    ├─ is_comparison (비교 여부)
    └─ intent (CASE 분류)
    │
    ▼
[2단계] 의도 분류 (classify_intent)
    │
    ▼
[3-4단계] 데이터 검색 + 법규 검토
    ├─ CASE1 → process_case1 (주소 기반 필지 조회)
    ├─ CASE2 → process_case2 (주소+용도지역 매칭)
    └─ CASE3 → process_case3 (용도지역/행위/법조문/비교)
    │
    ▼
[컨텍스트 조립] _build_context
    ├─ 케이스별 분석 결과
    ├─ 특수쿼리 결과 (건폐율, 법률비교)
    ├─ 이전 대화 히스토리
    ├─ RAG 벡터 검색 (k=10~15)
    │   └─ Reranker 재정렬 (top 3~5)
    └─ 키워드 매핑 설명
    │
    ▼
[5단계] LLM 리포트 생성
    ├─ system_prompt (규칙 + 예시 + 포맷 지시)
    ├─ [ANALYSIS DATA] = 조립된 컨텍스트
    └─ GPT 호출 → 최종 답변
```

---

## 3. CASE 분류 체계

### CASE1: 주소만 있음 (용도지역 없음)

**1-1: 지번까지 입력 (depth=4)**
- 예시: "종로구 청운동 1-2"
- 동작: 필지 직접 조회 → 법규 매칭

**1-3: 동까지만 입력 (depth=3)**
- 예시: "종로구 청운동"
- 동작: 동 내 필지 샘플링 조회

**1-0: 주소 불충분 (depth<3)**
- 예시: "서울시"
- 동작: 정보 부족 안내

### CASE2: 주소 + 용도지역 모두 있음

**2-1: 용도지역 일치**
- 조건: 실제 = 입력
- 동작: 정상 법규 검토

**2-2: 용도지역 불일치**
- 조건: 실제 ≠ 입력
- 동작: 경고 + 실제 기준 답변

**2-3: 부분일치**
- 조건: 일부만 일치
- 동작: 경고 + 실제 기준 답변

### CASE3: 주소 없이 질문

**3-1: 용도지역 + 행위**
- 예시: "제1종주거에서 카페 가능?"
- 동작: DB에서 해당 zone+activity 검색 → 허용여부 판정

**3-2: 용도지역만**
- 예시: "제1종주거에서 뭘 지을 수 있어?"
- 동작: 해당 zone 전체 법규 검색

**3-3: 행위만**
- 예시: "카페는 어디서 가능해?"
- 동작: 해당 activity 허용 zone 역검색

**3-4: 법조문만**
- 예시: "건축법 제2조 알려줘"
- 동작: law_name 컬럼 LIKE 검색

**3-5: 용도지역 비교 (2개 이상)**
- 예시: "1종 vs 2종 차이?"
- 동작: 각 zone 규제 + DB 통계 비교표

---

## 4. 백과사전 (정적 딕셔너리) 역할

### 4-1. ZONE_DISTRICT_DICTIONARY (~22개 항목)

**역할: 사용자 약칭 → DB 정식 용도지역명 확장**

- "주거지역" → 제1종전용주거지역, 제2종전용주거지역, 제1종일반주거지역, 제2종일반주거지역, 제3종일반주거지역, 준주거지역 (6종 전부)
- "상업지역" → 중심상업지역, 일반상업지역, 근린상업지역, 유통상업지역
- "1종주거" → 제1종전용주거지역, 제1종일반주거지역

없으면? "주거지역이랑 상업지역 비교해줘" → zone 추출 실패, CASE 분류 불가

### 4-2. LAND_USE_DICTIONARY (~130개 항목)

**역할: 일상어 → DB 법적 분류명 매핑**

- 카페, 커피숍, 커피전문점 → 휴게음식점, 제과점
- 식당, 밥집, 레스토랑 → 일반음식점
- 헬스장, 피트니스, 짐 → 체육관
- 미용실, 헤어샵, 뷰티샵 → 미용원
- PC방, 피씨방 → 인터넷컴퓨터게임시설제공업소
- 노래방, 코인노래 → 노래연습장

없으면? "카페 가능해?" → activity 추출 실패 → DB 검색 불가. DB에는 "카페"가 아닌 "휴게음식점"으로 저장되어 있기 때문

### 4-3. ZONE_REGULATIONS (21종 전체)

**역할: 용도지역별 법정 규제 기준값 제공 (DB 조회 없이 즉시)**

- 제1종전용주거지역: 건폐율 50%, 용적률 50~100%, 높이 없음, 단독주택 중심
- 중심상업지역: 건폐율 90%, 용적률 400~1500%, 높이 없음, 도심 상업·업무
- 보전녹지지역: 건폐율 20%, 용적률 50~80%, 높이 4층 이하, 자연환경 보전

사용처:
- 건폐율/용적률 질문 → 즉시 응답 (DB 조회 불필요)
- CASE3-5 비교표 생성 → 각 zone의 규제값 비교
- get_zone_regulations() → 정적값 + DB 추가 조건 병합

### 4-4. SPECIAL_QUERY_KEYWORDS (~12개)

**역할: 특수 질문 유형 감지**

- "건폐율", "건페율" → coverage_ratio → get_zone_regulations() 호출
- "용적률", "용적율" → floor_area_ratio → get_zone_regulations() 호출
- "조례", "법과조례" → law_comparison → compare_laws() 호출
- "높이제한" → height_limit
- "건축가능", "신축" → building_permit

### 4-5. 사전의 이중 역할 (LLM 경로 vs regex fallback 경로)

사전(LAND_USE_DICTIONARY, ZONE_REGULATIONS 등)은 LLM 경로와 regex fallback 경로 **양쪽 모두에서** 사용되지만, 역할이 다르다.

| | LLM 경로 | regex fallback 경로 |
|---|---|---|
| **추출 주체** | LLM이 추출 | regex + 사전이 추출 |
| **사전 역할** | 추출 결과를 **검증/필터링** | 직접 **매핑/변환** |

**LLM 경로에서의 사전 사용 (검증 필터):**
```python
# LLM이 추출한 용도지역을 ZONE_REGULATIONS 사전으로 검증
valid_zones = set(ZONE_REGULATIONS.keys())
zone_names = [z for z in raw_zones if z in valid_zones]  # 사전에 있는 것만 통과

# LLM이 추출한 행위를 LAND_USE_DICTIONARY 사전으로 검증
valid_activities = set(LAND_USE_DICTIONARY.values())
activities = [a for a in raw_activities if a in valid_activities]  # 사전에 있는 것만 통과
```

**흐름 비교:**
```
[LLM 경로]
"카페" → LLM이 "휴게음식점"으로 변환 → 사전에 "휴게음식점" 있는지 확인 → ✅ 통과

[LLM 경로 - LLM이 이상한 값 뱉었을 때]
"카페" → LLM이 "커피전문점"으로 변환 → 사전에 "커피전문점" 없음 → ❌ 필터링

[regex fallback 경로]
"카페" → 사전에서 직접 "휴게음식점"으로 매핑 → 그대로 사용
```

**LLM 추출의 진짜 장점** — 사전에 없는 자유로운 표현도 이해 가능:

| 입력 | 사전(regex) | LLM |
|---|---|---|
| "카페" | 사전에 있음 → 변환 가능 | 변환 가능 |
| "커피 파는 가게" | 사전에 없음 → 추출 실패 | "휴게음식점"으로 변환 가능 |
| "고기 구워먹는 집" | 사전에 없음 → 추출 실패 | "일반음식점"으로 변환 가능 |

---

## 5. 핵심 기술 상세

### 5-1. LRU Cache (임베딩 캐시)

**LRU = Least Recently Used (가장 오래 안 쓴 거 버리기)**

임베딩이란 텍스트를 숫자 벡터(예: [0.12, -0.34, 0.56, ...])로 변환하는 것. 변환할 때마다 OpenAI API를 호출해야 하고, API 호출 = 돈 + 시간.

같은 질문이 또 오면 또 API 호출하면 낭비. 그래서 한번 변환한 결과를 메모리에 저장(캐시)해둔다.

```
1번째 질문: "카페 가능?" → API 호출 → 결과 저장 (miss)
2번째 질문: "카페 가능?" → 저장된 거 꺼냄 (hit) → API 호출 안 함!
```

500개 제한 이유: 무한히 저장하면 메모리 터짐. 500개 넘으면 가장 오래 안 쓴 것부터 삭제.

**저장 위치:** 파일이 아닌 Python 프로세스 메모리(RAM). 서버 종료 시 전부 사라짐 (휘발성). 서버 재시작 → 빈 캐시에서 다시 시작.

**쓰는 이유:** API 비용 절감 + 응답 속도 향상

### 5-2. 벡터 검색 k=10~15

pgvector(PostgreSQL 벡터 DB)에서 질문과 비슷한 문서를 검색할 때 몇 개를 가져올지가 k값.

```
V1: k=2  → 2개만 가져옴 → 정답이 빠질 확률 높음
V2: k=15 → 15개 가져옴 → 후보가 넓어서 정답 포함 확률 높음
    → Reranker로 그 중 top 3~5만 골라 사용
```

비유: 시험 공부할 때
- k=2: 교과서 2페이지만 읽기 → 시험 범위 놓칠 수 있음
- k=15: 15페이지 훑고 → 중요한 3~5페이지만 정독

케이스별 차등:
- CASE3 (단순 질문): k=10, top=3 → 적게 가져와도 충분
- CASE1/2 (복합 질문): k=15, top=5 → 넓게 봐야 함

### 5-3. Cross-encoder (Reranker)

**Bi-encoder (벡터 검색):**
질문과 문서를 각각 따로 벡터로 만들어서 코사인 유사도로 비교. 빠르지만 부정확할 수 있음.

**Cross-encoder (Reranker):**
질문과 문서를 같이 하나의 모델에 넣어서 관련성 점수(0.0~1.0)를 매김. 느리지만 정확함.

왜 둘 다 쓰나?

```
1단계: Bi-encoder (벡터검색) → 빠르게 15개 후보 추림
2단계: Cross-encoder (Reranker) → 15개를 정밀하게 재정렬 → top 3~5 선택
```

15개 전부를 Cross-encoder로 검색하면 너무 느려서, 벡터검색으로 빠르게 좁히고 → Reranker로 정밀 재정렬하는 2단계 전략.

ms-marco-MiniLM-L-6-v2: Microsoft가 만든 경량 Cross-encoder 모델. 작고 빨라서 실시간 서비스에 적합.

### 5-4. gpt-4o-mini 1회 JSON 추출

사용자 질문에서 주소/용도지역/행위/법조문 등을 한번에 구조화 추출하는 것.

```
입력: "수원시 영통구 매탄동 제1종일반주거지역에서 카페 가능해?"

→ gpt-4o-mini 1회 호출 →

출력 (JSON):
{
  "address": {"sido": "경기도", "sigungu": "수원시 영통구", "dong": "매탄동"},
  "zones": ["제1종일반주거지역"],
  "activities": ["휴게음식점"],    ← 카페를 법적 분류로 자동 변환!
  "intent": "CASE2"
}
```

왜 gpt-4o-mini?
- 빠르고 저렴 (추출용이니까 똑똑할 필요 없음)
- temperature=0 (매번 같은 결과 보장)
- JSON 포맷 강제 (response_format=json_object)

### 5-5. regex fallback

**regex = Regular Expression (정규표현식)**

텍스트에서 특정 패턴을 찾는 규칙.

```
지번 찾기:  \d+-\d+  →  "1-1040" 매칭
법조문 찾기: 건축법제\d+조  →  "건축법제2조" 매칭
용도지역 찾기: "제1종일반주거지역" in question  →  True/False
```

**fallback = 대비책**

```
1순위: gpt-4o-mini로 추출 시도
         │
         ├─ 성공 → 결과 사용
         │
         └─ 실패 (API 에러, 타임아웃 등)
              │
              ▼
2순위: regex 6종으로 추출 (fallback)
       ├─ parse_address()              → 주소 추출
       ├─ extract_zone_district_name() → 용도지역 추출
       ├─ extract_land_use_activity()  → 행위 추출
       ├─ extract_region_codes()       → 지역코드 추출
       ├─ extract_special_queries()    → 특수쿼리 추출
       └─ law_reference regex          → 법조문 추출
```

왜 fallback이 필요?
- OpenAI API가 죽을 수 있음 (장애, 타임아웃)
- API 키 만료될 수 있음
- 네트워크 끊길 수 있음
- 이때도 서비스가 동작해야 하니까 regex로 최소한의 추출 보장

**regex fallback 6종 상세:**

| # | 메서드 | 하는 일 | 추출 예시 |
|---|--------|--------|----------|
| ① | `parse_address()` | 주소 추출 | "강남구 역삼동 123-4" → `{동: "역삼동", 지번: "123-4", depth: 4}` |
| ② | `extract_zone_district_name()` | 용도지역 추출 | "제1종일반주거지역" 매칭 (정확매칭 + 정규식 `제\d종[가-힣]+지역`) |
| ③ | `extract_land_use_activity()` | 행위 추출 | "카페" → LAND_USE_DICTIONARY에서 "휴게음식점"으로 변환 |
| ④ | `extract_region_codes()` | 지역코드 추출 | 5자리 숫자 패턴 `\b\d{5}\b` → "11680" |
| ⑤ | `extract_special_queries()` | 특수쿼리 추출 | "건폐율", "용적률", "조례" 같은 키워드 감지 |
| ⑥ | law_reference regex | 법조문 추출 | `건축법제2조`, `국토계획법 시행령` 패턴 매칭 |

실제 코드 (`_extract_with_regex_fallback`):
```python
def _extract_with_regex_fallback(self, question):
    """기존 regex 메서드 6개를 감싸는 fallback wrapper"""
    question_normalized = self.normalize_query(question)

    address_info    = self.parse_address(question_normalized)             # ①
    zone_names      = self.extract_zone_district_name(question_normalized) # ②
    activities      = self.extract_land_use_activity(question_normalized)  # ③
    region_codes    = self.extract_region_codes(question_normalized)       # ④
    special_queries = self.extract_special_queries(question_normalized)    # ⑤
    law_reference   = re.search(r'(건축법|국토계획법|...)', question)      # ⑥

    return { ... }  # gpt-4o-mini 성공했을 때와 동일한 JSON 구조
```

gpt-4o-mini가 한 번에 하는 일을 regex 6개가 나눠서 수행. 결과물 형태(JSON)는 동일.

### 5-6. RAG 벡터 검색

- 임베딩 모델: text-embedding-3-small (OpenAI)
- 벡터 DB: pgvector (PostgreSQL 확장)
- k값 차등: CASE3(단순)=k10/top3, CASE1/2(복합)=k15/top5
- 저장 대상: 건축 도면 평면도 분석 결과

### 5-7. 개발 성적표 (analyze_feasibility)

법규 매칭 결과를 종합 판정:

- 허용(가능)만 있음 → **가능**
- 조건부허용만 있음 → **조건부가능**
- 불허 존재 → **불가**
- 혼합 → **검토필요**
- 데이터 없음 → **정보부족**

### 5-8. 동 단위 샘플링 (V2)

주소 depth가 2 이하(시/군/구까지만)일 때:

```sql
ROW_NUMBER() OVER(PARTITION BY legal_dong_name ORDER BY lot_number)
```

각 동에서 균등하게 필지를 뽑아 편향 방지

---

## 6. DB 테이블 구조

**land_char (필지 특성 정보)**
- legal_dong_name, lot_number, region_code, zone1, zone2, land_category, land_use, land_area, terrain_height, terrain_shape, road_access

**law (용도지역별 법규)**
- region_code, zone_district_name, law_name, land_use_activity, permission_category, condition_exception

**chat_history (대화 이력)**
- question, answer, created_at

**chatroom (채팅방 관리)**
- user FK

**users (사용자 정보)**
- email

### 6-1. DB에서 조회하는 데이터 상세

**① land_char 테이블 - 필지(토지) 정보 조회**

"이 주소의 땅이 실제로 어떤 땅인지" 확인하는 용도.

```sql
SELECT legal_dong_name, lot_number, region_code,
       zone1, zone2, land_category, land_use,
       land_area, terrain_height, terrain_shape, road_access
FROM land_char
WHERE legal_dong_name = '역삼동' AND lot_number = '123-4'
```

| 컬럼 | 의미 | 예시 |
|------|------|------|
| legal_dong_name | 법정동명 | 역삼동 |
| lot_number | 지번 | 123-4 |
| zone1, zone2 | 용도지역 | 제1종일반주거지역 |
| land_category | 지목 | 대, 전, 답 |
| land_area | 면적 | 250.5㎡ |
| road_access | 도로접면 | 소로 |

→ 주소를 넣으면 그 땅의 실제 정보(용도지역, 면적, 지목 등)를 반환

**② law 테이블 - 법규/허용행위 정보 조회**

"이 용도지역에서 뭘 할 수 있는지" 확인하는 용도.

```sql
SELECT zone_district_name, law_name,
       land_use_activity, permission_category, condition_exception
FROM law
WHERE zone_district_name LIKE '%제1종일반주거지역%'
```

| 컬럼 | 의미 | 예시 |
|------|------|------|
| zone_district_name | 용도지역 | 제1종일반주거지역 |
| law_name | 법률명 | 국토계획법 시행령 |
| land_use_activity | 허용행위 | 휴게음식점 |
| permission_category | 허용구분 | 허용/조건부/불허 |
| condition_exception | 조건/예외 | 건폐율 60% 이하 |

→ 특정 용도지역에서 어떤 행위가 가능한지, 조건은 뭔지 반환

**③ chat_history 테이블 - 이전 대화 조회**

대화 맥락 유지를 위해 이전 질문/답변을 가져오는 용도.

```sql
SELECT ch.question, ch.answer, ch.created_at
FROM chat_history ch
JOIN chatroom cr ON ch.chatroom_id = cr.id
JOIN users u ON cr.user_id = u.id
WHERE u.email = 'user@example.com'
ORDER BY ch.created_at DESC LIMIT 2
```

→ 해당 사용자의 최근 2건 대화를 가져와 컨텍스트에 포함

### 6-2. 하드코딩(ZONE_REGULATIONS) vs DB 조회 역할 분담

| 구분 | ZONE_REGULATIONS (하드코딩) | DB 조회 |
|------|---------------------------|---------|
| 데이터 | 건폐율/용적률 (법정 고정값) | 실제 필지 정보, 세부 법규, 대화기록 |
| 성격 | 법정 기준값 (거의 안 바뀜) | 실시간 데이터 (주소별, 사용자별 다름) |
| 용도 | 빠른 검증 / 기본값 즉시 제공 | 구체적 조회 / 판단 |
| 속도 | 즉시 (0.001ms 이하) | 네트워크 왕복 필요 (수십~수백ms) |
| 장애 영향 | DB 장애와 무관 | DB 다운 시 조회 불가 |
| 근거 | 국토계획법 시행령 제84조, 85조 | 실제 토지대장, 법규 DB |

하드코딩이 가능한 이유: 건폐율/용적률은 국토계획법 시행령에 정해진 법정 고정값이라 자주 바뀌지 않음. 법 개정 시에만 코드 수정 필요.

### 6-3. 답변 생성 이후 저장 흐름

답변 생성은 Python(FastAPI)이 담당하고, 저장은 Java(Spring Boot)가 담당한다.

```
[Python FastAPI] 답변 생성 완료
    │
    ▼ JSON 응답: {summaryTitle, answer}
    │
[Java Spring Boot] ChatbotController.java 에서 받음
    │
    ▼ 채팅방 존재 여부 확인
    │
    ├─ chatRoomId 없음 (첫 질문)
    │   ├─ ① ChatRoom 생성 (이름 = summaryTitle)
    │   ├─ ② chatRoomRep.save(chatRoom)  ← DB 저장
    │   ├─ ③ ChatHistory 생성 (question + answer)
    │   └─ ④ chatHistoryRep.save(chatHistory)  ← DB 저장
    │
    └─ chatRoomId 있음 (이어서 대화)
        ├─ ① 기존 ChatRoom 조회
        ├─ ② ChatHistory 생성 (question + answer)
        └─ ③ chatHistoryRep.save(chatHistory)  ← DB 저장
    │
    ▼ 프론트엔드로 응답 반환: {answer, chatRoomId}
```

**저장 위치 정리:**

| 순서 | 어디서 | 뭘 하는지 |
|------|--------|----------|
| 1 | Python (FastAPI) | 답변 생성 + 검증 |
| 2 | Python → Java | JSON으로 전달 (summaryTitle + answer) |
| 3 | Java (Spring Boot) | ChatRoom 테이블에 채팅방 저장 (첫 질문일 때만) |
| 4 | Java (Spring Boot) | ChatHistory 테이블에 질문+답변 저장 |
| 5 | Java → 프론트엔드 | answer + chatRoomId 반환 |

Python은 답변만 만들고, DB 저장은 Java(Spring Boot)가 PostgreSQL에 수행한다. summaryTitle은 채팅방 이름(ChatRoom.name)으로, question과 answer는 대화 이력(ChatHistory)으로 저장된다.

### 6-4. summaryTitle과 answer 응답 예시

**summaryTitle 생성 로직:**
```python
summary_title = question[:30] + "..." if len(question) > 30 else question
```
사용자 질문을 30자까지 잘라서 채팅방 제목으로 사용. ChatGPT 사이드바의 대화 제목과 동일한 개념.

**예시 1: 짧은 질문 (30자 이하)**
```
사용자 질문: "카페 가능해?"
```
```json
{
  "summaryTitle": "카페 가능해?",
  "answer": "## 용도지역별 카페(휴게음식점) 허용 여부\n\n카페는 법적으로 **휴게음식점**으로 분류됩니다.\n\n| 용도지역 | 허용여부 |\n|---|---|\n| 제1종일반주거지역 | 조건부 허용 (4층 이하) |\n| 제2종일반주거지역 | 허용 |\n| 근린상업지역 | 허용 |\n..."
}
```
→ 질문이 30자 이하라 summaryTitle = 질문 그대로

**예시 2: 긴 질문 (30자 초과)**
```
사용자 질문: "서울시 강남구 역삼동 제1종일반주거지역에서 휴게음식점 영업이 가능한지 알려주세요"
```
```json
{
  "summaryTitle": "서울시 강남구 역삼동 제1종일반주거지역에서 휴게음식점...",
  "answer": "## 역삼동 제1종일반주거지역 휴게음식점 허용 여부\n\n### 결론: 조건부 허용\n\n해당 필지는 제1종일반주거지역으로 확인되며, 휴게음식점은 **4층 이하 건축물**에서 조건부 허용됩니다.\n\n### 관련 법규\n- 국토계획법 시행령 제71조 별표...\n\n### 규제 기준\n- 건폐율: 60%\n- 용적률: 100~200%\n- 높이: 4층 이하\n..."
}
```
→ 질문이 30자 초과라 30자에서 잘리고 `...` 붙음

- **summaryTitle**: 채팅방 목록에 보이는 제목 (질문을 30자로 자른 것)
- **answer**: GPT가 생성한 실제 답변 본문 (마크다운 형식)

---

## 7. 파일 통계

- 전체 라인 수: 2,912줄
- 메인 클래스: ChatbotService (1개)
- 헬퍼 클래스: EmbeddingCache (1개)
- 정적 딕셔너리: 4개
- 퍼블릭 메서드: ~40개+
- LLM 모델: gpt-4o-mini (추출+답변)
- 임베딩 모델: text-embedding-3-small
- Reranker 모델: cross-encoder/ms-marco-MiniLM-L-6-v2
- CASE 유형: 3대분류, 10개 서브케이스
